<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Docker之seccomp]]></title>
    <url>%2F2019%2F03%2F11%2FDocker%E4%B9%8Bseccomp%2F</url>
    <content type="text"><![CDATA[什么是seccompseccomp（全称securecomputing mode）是linux kernel从2.6.23版本开始所支持的一种安全机制。 在Linux系统里，大量的系统调用（systemcall）直接暴露给用户态程序。但是，并不是所有的系统调用都被需要，而且不安全的代码滥用系统调用会对系统造成安全威胁。通过seccomp，我们限制程序使用某些系统调用，这样可以减少系统的暴露面，同时是程序进入一种“安全”的状态。 如何使用seccompseccomp可以通过系统调用ptrctl(2)或者通过系统调用seccomp(2)开启，前提是内核配置中开启了CONFIG_SECCOMP和CONFIG_SECCOMP_FILTER。 seccomp支持两种模式：SECCOMP_MODE_STRICT和SECCOMP_MODE_FILTER。 在SECCOMP_MODE_STRICT模式下，进程不能使用read(2)，write(2)，_exit(2)和sigreturn(2)以外的其他系统调用。 在SECCOMP_MODE_FILTER模式下，可以利用BerkeleyPacket Filter配置哪些系统调用及它们的参数可以被进程使用。 如何查看是否使用了seccomp通常有两种方法： 利用prctl(2)的PR_GET_SECCOMP的参数获取当前进程的seccomp状态。返回值0表示没有使用seccomp;返回值2表示使用了seccomp并处于SECCOMP_MODE_FILTER模式；其他情况进程会被SIGKILL信号杀死。 从Linux3.8开始，可以利用/proc/[pid]/status中的Seccomp字段查看。如果没有seccomp字段，说明内核不支持seccomp。 下面这个是docker守护进程的status123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Name: dockerdState: S (sleeping)Tgid: 1345Ngid: 0Pid: 1345PPid: 1TracerPid: 0Uid: 0 0 0 0Gid: 0 0 0 0FDSize: 256Groups: NStgid: 1345NSpid: 1345NSpgid: 1345NSsid: 1345VmPeak: 1150756 kBVmSize: 1150628 kBVmLck: 0 kBVmPin: 0 kBVmHWM: 102020 kBVmRSS: 87212 kBVmData: 1049204 kBVmStk: 132 kBVmExe: 46768 kBVmLib: 4612 kBVmPTE: 484 kBVmPMD: 24 kBVmSwap: 0 kBHugetlbPages: 0 kBThreads: 36SigQ: 0/62554SigPnd: 0000000000000000ShdPnd: 0000000000000000SigBlk: fffffffe3bfa2800SigIgn: 0000000000000000SigCgt: ffffffffffc1feffCapInh: 0000000000000000CapPrm: 0000003fffffffffCapEff: 0000003fffffffffCapBnd: 0000003fffffffffCapAmb: 0000000000000000Seccomp: 0 //这是0，表示没有使用seccompCpus_allowed: ffCpus_allowed_list: 0-7Mems_allowed: 00000000,00000001Mems_allowed_list: 0voluntary_ctxt_switches: 2334nonvoluntary_ctxt_switches: 4 在docker中使用只有在使用 seccomp 构建 Docker 并且内核配置了 CONFIG_SECCOMP 的情况下，此功能才可用。要检查你的内核是否支持 seccomp：12$ cat /boot/config-`uname -r` | grep CONFIG_SECCOMP=CONFIG_SECCOMP=y 为容器传递配置文件默认的 seccomp 配置文件为使用 seccomp 运行容器提供了一个合理的设置，并禁用了大约 44 个超过 300+ 的系统调用。它具有适度的保护性，同时提供广泛的应用兼容性。默认的 Docker 配置文件可以在 这里 找到。https://github.com/moby/moby/blob/master/profiles/seccomp/default.json 实际上，该配置文件是白名单，默认情况下阻止访问所有的系统调用，然后将特定的系统调用列入白名单。该配置文件工作时需要定义 SCMP_ACT_ERRNO 的 defaultAction 并仅针对特定的系统调用覆盖该 action。SCMP_ACT_ERRNO 的影响是触发 Permission Denied 错误。接下来，配置文件中通过将 action 被覆盖为 SCMP_ACT_ALLOW，定义一个完全允许的系统调用的特定列表。最后，一些特定规则适用于个别的系统调用，如 personality，socket，socketcall 等，以允许具有特定参数的那些系统调用的变体（to allow variants of those system calls with specific arguments）。 seccomp 有助于以最小权限运行 Docker 容器。不建议更改默认的 seccomp 配置文件。 运行容器时，如果没有通过 –security-opt 选项覆盖容器，则会使用默认配置。例如，以下显式指定了一个策略：1234docker run --rm \ -it \ --security-opt seccomp=/path/to/seccomp/profile.json \ hello-world 不使用默认的 seccomp 配置文件可以传递 unconfined 以运行没有默认 seccomp 配置文件的容器。 12docker run --rm -it --security-opt seccomp=unconfined debian:jessie \ unshare --map-root-user --user sh -c whoami 参考https://blog.csdn.net/mashimiao/article/details/73607485https://blog.csdn.net/kikajack/article/details/79596843]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用户态与内核态]]></title>
    <url>%2F2019%2F03%2F11%2F%E7%94%A8%E6%88%B7%E6%80%81%E4%B8%8E%E5%86%85%E6%A0%B8%E6%80%81%2F</url>
    <content type="text"><![CDATA[内核态与用户态当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。即此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。这与处于内核态的进程的状态有些类似。 用系统调用时进入核心态。Linux对硬件的操作只能在核心态，这可以通过写驱动程序来控制。在用户态操作硬件会造成core dump。 要注意区分系统调用和一般的函数。系统调用由内核提供，如read()、write()、open()等。而一般的函数由软件包中的函数库提供，如sin()、cos()等。在语法上两者没有区别。 一般情况：系统调用运行在核心态，函数运行在用户态。但也有一些函数在内部使用了系统调用（如fopen），这样的函数在调用系统调用是进入核心态，其他时候运行在用户态。 大概是当用户程序调用系统的API时，就产生中断，进入内核态的API,处理完成后，用中断再退出，返回用户态的调用函数。 user api --&gt; interrupt --&gt; kernel api --&gt; interrupt 简单来讲一个进程由于执行系统调用而开始执行内核代码,我们称该进程处于内核态中. 一个进程执行应用程序自身代码则称该进程处于用户态. CPU运行级别intel x86 架构的 CPU 分为好几个运行级别,从 0–3 , 0 为最高级别, 3 为最低级别针对不同的级别,有很多的限制,比如说传统的 in ,out 指令,就是端口的输入输出指令,在 0 级下是可以用的,但在 3 级下就不能用,你用就产生陷阱,告诉你出错了,当然限制还有很多了,不只是这一点。操作系统下是利用这个特点,当操作系统自己的代码运行时, CPU 就切成 0 级,当用户的程序运行是就只让它在 3 级运行,这样如果用户的程序想做什么破坏系统的事情的话,也没办法做到当然,低级别的程序是没法把自己升到高级别的,也就是说 用户程序运行在 3 级,他想把自己变成 0 级自己是做不到的,除非是操作系统帮忙,利用这个特性,操作系统就可以控制所有的程序的运行,确保系统的安全了. 平时把操作系统运行时的级别就叫内核态(因为是操作系统内核运行时的状态),而且普通用户程序运行时的那个级别叫用户态…当操作系统刚引导时, CPU 处于实模式,这时就相当于是 0 级,于是操作系统就自动得到最高权限,然后切到保护模式时就是0级,这时操作系统就占了先机,成为了最高级别的运行者,由于你的程序都是由操作系统来加载的,所以当它把你加载上来后,就把你的运行状态设为 3 级,即最低级,然后才让你运行,所以没办法,你只能在最低级运行了,因为没办法把自己从低级上升到高级, 这就是操作系统在内核态可以管理用户程序,杀死用户程序的原因。 用户态和内核态的概念区别 究竟什么是用户态，什么是内核态，这两个基本概念以前一直理解得不是很清楚，根本原因个人觉得是在于因为大部分时候我们在写程序时关注的重点和着眼的角度放在了实现的功能和代码的逻辑性上，先看一个例子： 1）例子12345678910111213 void testfork()&#123; if(0 = = fork())&#123; printf(“create new process success!\n”); &#125; printf(“testfork ok\n”); &#125;这段代码很简单，从功能的角度来看，就是实际执行了一个fork()，生成一个新的进程，从逻辑的角度看，就是判断了如果fork()返回的是0则打印相关语句，然后函数最后再打印一句表示执行完整个testfork()函数。代码的执行逻辑和功能上看就是如此简单，一共四行代码，从上到下一句一句执行而已，完全看不出来哪里有体现出用户态和进程态的概念。 如果说前面两种是静态观察的角度看的话，我们还可以从动态的角度来看这段代码，即它被转换成CPU执行的指令后加载执行的过程，这时这段程序就是一个动态执行的指令序列。而究竟加载了哪些代码，如何加载就是和操作系统密切相关了。 2）特权级 熟悉Unix/Linux系统的人都知道，fork的工作实际上是以系统调用的方式完成相应功能的，具体的工作是由sys_fork负责实施。其实无论是不是Unix或者Linux，对于任何操作系统来说，创建一个新的进程都是属于核心功能，因为它要做很多底层细致地工作，消耗系统的物理资源，比如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录页表等等，这些显然不能随便让哪个程序就能去做，于是就自然引出特权级别的概念，显然，最关键性的权力必须由高特权级的程序来执行，这样才可以做到集中管理，减少有限资源的访问和使用冲突。 特权级显然是非常有效的管理和控制程序执行的手段，因此在硬件上对特权级做了很多支持，就Intel x86架构的CPU来说一共有0~3四个特权级，0级最高，3级最低，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查，相关的概念有CPL、DPL和RPL，这里不再过多阐述。硬件已经提供了一套特权级使用的相关机制，软件自然就是好好利用的问题，这属于操作系统要做的事情，对于Unix/Linux来说，只使用了0级特权级和3级特权级。也就是说在Unix/Linux系统中，一条工作在0级特权级的指令具有了CPU能提供的最高权力，而一条工作在3级特权级的指令具有CPU提供的最低或者说最基本权力。 3）用户态和内核态 现在我们从特权级的调度来理解用户态和内核态就比较好理解了，当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。 虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序，比如上面例子中的testfork()就不能直接调用sys_fork()，因为前者是工作在用户态，属于用户态程序，而sys_fork()是工作在内核态，属于内核态程序。 当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态，比如testfork()最初运行在用户态进程下，当它调用fork()最终触发sys_fork()的执行时，就切换到了内核态。 用户态和内核态的转换 1）用户态切换到内核态的3种方式 a. 系统调用 这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。 b. 异常 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 c. 外围设备的中断 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。 参考https://www.cnblogs.com/cyjaysun/p/4422508.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2F2019%2F03%2F11%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[什么场景下会使用分布式锁？单机应用架构中，秒杀案例使用ReentrantLcok或者synchronized来达到秒杀商品互斥的目的。然而在分布式系统中，会存在多台机器并行去实现同一个功能。也就是说，在多进程中，如果还使用以上JDK提供的进程锁，来并发访问数据库资源就可能会出现商品超卖的情况。因此，需要我们来实现自己的分布式锁。 实现一个分布式锁应该具备的特性： 高可用、高性能的获取锁与释放锁 在分布式系统环境下，一个方法或者变量同一时间只能被一个线程操作 具备锁失效机制，网络中断或宕机无法释放锁时，锁必须被删除，防止死锁 具备阻塞锁特性，即没有获取到锁，则继续等待获取锁 具备非阻塞锁特性，即没有获取到锁，则直接返回获取锁失败 具备可重入特性，一个线程中可以多次获取同一把锁，比如一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁 关于分布式锁几种实现方式： 基于数据库实现分布式锁 基于 Redis 实现分布式锁 基于 Zookeeper 实现分布式锁 Zookeeper实现分布式锁前两种对于分布式生产环境来说并不是特别推荐，高并发下数据库锁性能太差，Redis在锁时间限制和缓存一致性存在一定问题。这里我们重点介绍一下 Zookeeper 如何实现分布式锁。 实现原理ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能存在唯一文件名。 ZooKeeper数据模型与文件系统目录树(源自网络) 数据模型PERSISTENT 持久化节点，节点创建后，不会因为会话失效而消失EPHEMERAL 临时节点， 客户端session超时此类节点就会被自动删除EPHEMERAL_SEQUENTIAL 临时自动编号节点PERSISTENT_SEQUENTIAL 顺序自动编号持久化节点，这种节点会根据当前已存在的节点数自动加 1 监视器（watcher）当创建一个节点时，可以注册一个该节点的监视器，当节点状态发生改变时，watch被触发时，ZooKeeper将会向客户端发送且仅发送一条通知，因为watch只能被触发一次。根据zookeeper的这些特性，我们来看看如何利用这些特性来实现分布式锁： 创建一个锁目录lock 线程A获取锁会在lock目录下，创建临时顺序节点 获取锁目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁 线程B创建临时节点并获取所有兄弟节点，判断自己不是最小节点，设置监听(watcher)比自己次小的节点 线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是最小的节点，获得锁 代码分析尽管ZooKeeper已经封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。但是如果让一个普通开发者去手撸一个分布式锁还是比较困难的，在秒杀案例中我们直接使用 Apache 开源的curator 开实现 Zookeeper 分布式锁。这里我们使用以下版本，截止目前最新版4.0.1：123456&lt;!-- zookeeper 分布式锁、注意zookeeper版本 这里对应的是3.4.6--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.10.0&lt;/version&gt;&lt;/dependency&gt; 首先，我们看下InterProcessLock接口中的几个方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217/*** 获取锁、阻塞等待、可重入*/public void acquire() throws Exception;/*** 获取锁、阻塞等待、可重入、超时则获取失败*/public boolean acquire(long time, TimeUnit unit) throws Exception;/*** 释放锁*/public void release() throws Exception;/*** Returns true if the mutex is acquired by a thread in this JVM*/boolean isAcquiredInThisProcess();获取锁：//获取锁public void acquire() throws Exception &#123; if ( !internalLock(-1, null) ) &#123; throw new IOException("Lost connection while trying to acquire lock: " + basePath); &#125; &#125;具体实现：private boolean internalLock(long time, TimeUnit unit) throws Exception &#123; /* 实现同一个线程可重入性，如果当前线程已经获得锁， 则增加锁数据中lockCount的数量(重入次数)，直接返回成功 */ //获取当前线程 Thread currentThread = Thread.currentThread(); //获取当前线程重入锁相关数据 LockData lockData = threadData.get(currentThread); if ( lockData != null ) &#123; //原子递增一个当前值，记录重入次数，后面锁释放会用到 lockData.lockCount.incrementAndGet(); return true; &#125; //尝试连接zookeeper获取锁 String lockPath = internals.attemptLock(time, unit, getLockNodeBytes()); if ( lockPath != null ) &#123; //创建可重入锁数据，用于记录当前线程重入次数 LockData newLockData = new LockData(currentThread, lockPath); threadData.put(currentThread, newLockData); return true; &#125; //获取锁超时或者zk通信异常返回失败 return false; &#125;Zookeeper获取锁实现： String attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception &#123; //获取当前时间戳 final long startMillis = System.currentTimeMillis(); //如果unit不为空(非阻塞锁)，把当前传入time转为毫秒 final Long millisToWait = (unit != null) ? unit.toMillis(time) : null; //子节点标识 final byte[] localLockNodeBytes = (revocable.get() != null) ? new byte[0] : lockNodeBytes; //尝试次数 int retryCount = 0; String ourPath = null; boolean hasTheLock = false; boolean isDone = false; //自旋锁，循环获取锁 while ( !isDone ) &#123; isDone = true; try &#123; //在锁节点下创建临时且有序的子节点，例如:_c_008c1b07-d577-4e5f-8699-8f0f98a013b4-lock-000000001 ourPath = driver.createsTheLock(client, path, localLockNodeBytes); //如果当前子节点序号最小，获得锁则直接返回，否则阻塞等待前一个子节点删除通知(release释放锁) hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath); &#125; catch ( KeeperException.NoNodeException e ) &#123; //异常处理，如果找不到节点，这可能发生在session过期等时，因此，如果重试允许，只需重试一次即可 if ( client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper()) ) &#123; isDone = false; &#125; else &#123; throw e; &#125; &#125; &#125; //如果获取锁则返回当前锁子节点路径 if ( hasTheLock ) &#123; return ourPath; &#125; return null; &#125;判断是否为最小节点： private boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception &#123; boolean haveTheLock = false; boolean doDelete = false; try &#123; if ( revocable.get() != null ) &#123; client.getData().usingWatcher(revocableWatcher).forPath(ourPath); &#125; //自旋获取锁 while ( (client.getState() == CuratorFrameworkState.STARTED) &amp;&amp; !haveTheLock ) &#123; //获取所有子节点集合 List&lt;String&gt; children = getSortedChildren(); //判断当前子节点是否为最小子节点 String sequenceNodeName = ourPath.substring(basePath.length() + 1); // +1 to include the slash PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); //如果是最小节点则获取锁 if ( predicateResults.getsTheLock() ) &#123; haveTheLock = true; &#125; else &#123; //获取前一个节点，用于监听 String previousSequencePath = basePath + "/" + predicateResults.getPathToWatch(); synchronized(this) &#123; try &#123; //这里使用getData()接口而不是checkExists()是因为，如果前一个子节点已经被删除了那么会抛出异常而且不会设置事件监听器，而checkExists虽然也可以获取到节点是否存在的信息但是同时设置了监听器，这个监听器其实永远不会触发，对于Zookeeper来说属于资源泄露 client.getData().usingWatcher(watcher).forPath(previousSequencePath); if ( millisToWait != null ) &#123; millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); //如果设置了获取锁等待时间 if ( millisToWait &lt;= 0 ) &#123; doDelete = true; // 超时则删除子节点 break; &#125; //等待超时时间 wait(millisToWait); &#125; else &#123; wait();//一直等待 &#125; &#125; catch ( KeeperException.NoNodeException e ) &#123; // it has been deleted (i.e. lock released). Try to acquire again //如果前一个子节点已经被删除则deException，只需要自旋获取一次即可 &#125; &#125; &#125; &#125; &#125; catch ( Exception e ) &#123; ThreadUtils.checkInterrupted(e); doDelete = true; throw e; &#125; finally &#123; if ( doDelete ) &#123; deleteOurPath(ourPath);//获取锁超时则删除节点 &#125; &#125; return haveTheLock; &#125;释放锁： public void release() throws Exception &#123; Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); //没有获取锁，你释放个球球，如果为空抛出异常 if ( lockData == null ) &#123; throw new IllegalMonitorStateException("You do not own the lock: " + basePath); &#125; //获取重入数量 int newLockCount = lockData.lockCount.decrementAndGet(); //如果重入锁次数大于0，直接返回 if ( newLockCount &gt; 0 ) &#123; return; &#125; //如果重入锁次数小于0，抛出异常 if ( newLockCount &lt; 0 ) &#123; throw new IllegalMonitorStateException("Lock count has gone negative for lock: " + basePath); &#125; try &#123; //释放锁 internals.releaseLock(lockData.lockPath); &#125; finally &#123; //移除当前线程锁数据 threadData.remove(currentThread); &#125; &#125; 测试案例为了更好的理解其原理和代码分析中获取锁的过程，这里我们实现一个简单的Demo：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 基于curator的zookeeper分布式锁 */public class CuratorUtil &#123; private static String address = "192.168.1.180:2181"; public static void main(String[] args) &#123; //1、重试策略：初试时间为1s 重试3次 RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); //2、通过工厂创建连接 CuratorFramework client = CuratorFrameworkFactory.newClient(address, retryPolicy); //3、开启连接 client.start(); //4 分布式锁 final InterProcessMutex mutex = new InterProcessMutex(client, "/curator/lock"); //读写锁 //InterProcessReadWriteLock readWriteLock = new InterProcessReadWriteLock(client, "/readwriter"); ExecutorService fixedThreadPool = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; fixedThreadPool.submit(new Runnable() &#123; @Override public void run() &#123; boolean flag = false; try &#123; //尝试获取锁，最多等待5秒 flag = mutex.acquire(5, TimeUnit.SECONDS); Thread currentThread = Thread.currentThread(); if(flag)&#123; System.out.println("线程"+currentThread.getId()+"获取锁成功"); &#125;else&#123; System.out.println("线程"+currentThread.getId()+"获取锁失败"); &#125; //模拟业务逻辑，延时4秒 Thread.sleep(4000); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally&#123; if(flag)&#123; try &#123; mutex.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;); &#125; &#125;&#125; 这里我们开启5个线程，每个线程获取锁的最大等待时间为5秒，为了模拟具体业务场景，方法中设置4秒等待时间。开始执行main方法，通过ZooInspector监控/curator/lock下的节点如下图： 对，没错，设置4秒的业务处理时长就是为了观察生成了几个顺序节点。果然如案例中所述，每个线程都会生成一个节点并且还是有序的。观察控制台，我们会发现只有两个线程获取锁成功，另外三个线程超时获取锁失败会自动删除节点。线程执行完毕我们刷新一下/curator/lock节点，发现刚才创建的五个子节点已经不存在了。 基于数据库的分布式锁实现方式数据库的乐观锁(通过版本号)或者悲观锁(通过for update) 基于数据库分布式锁注意的地方 基于数据库表的方式需要集群中多个节点的服务器时钟同步。 基于mysql数据库时需要在JDBC连接地址中增加时区配置，serverTimezone=GMT%2b8。关于脑裂问题： 由于网络、进程假死、中间件可能导致的脑裂问题在一定程度上不可避免，所以我们需要做一种权衡，即脑裂发生时是否可以避免问题进一步扩大。基于JDBC的分布式锁住要避免多个节点同时对事务表进行扫描，两者都是进行数据库操作，因为它们都基于数据库所以能够在一定程度上避免脑裂导致的集群处理问题，但是基于zookeeper,redis的方式可能会导致真实的脑裂发生 基于 Redis 的分布式锁（可以单机也可以集群）首先说明一下setnx()命令，setnx的含义就是SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果key不存在，则设置当前key成功，返回1；如果当前key已经存在，则设置当前key失败，返回0。value是System.currentTimeMillis() (获取锁的时间)+锁持有的时间。但是要注意的是setnx命令不能设置key的超时时间，只能通过expire()来对key设置。 具体的使用步骤如下: setnx(lockkey, 1) 如果返回0，则说明占位失败；如果返回1，则说明占位成功 expire()命令对lockkey设置超时时间，为的是避免死锁问题。 执行完业务代码后，可以通过delete命令删除key。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(timeOut)，它要远小于锁的有效时间（几十毫秒量级）上边的解决方案可能存在的问题这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。比如，如果在第一步setnx执行成功后，在expire()命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用redis的setnx()、get()和getset()方法来实现分布式锁。 getSet(key,value)的命令会返回key对应的value，然后再把key原来的值更新为value。也就是说getSet()返回的是已过期的时间戳。如果这个已过期的时间戳等于currentValue，说明获取锁成功。 假设客户端A一开始持有锁，保存在redis中的value(时间戳)等于T1。 这时候客户端A的锁已经过期，那么C，D客户端就可以开始争抢锁了。currentValue是T1，C客户端的value是T2，D客户端的value是T3。首先C客户端进入到String oldValue = jedis.getSet(realKey, value);这行代码，获得的oldValue是T1，同时也会把realKey对应的value更新为T2。再执行后续的代码，oldValue等于currentValue，那么客户端C获取锁成功。接着D客户端也执行到了String oldValue = jedis.getSet(realKey, value);这行代码，获取的oldValue是T2，同时也会把realKey对应的value更新为T3。由于oldValue不等于currentValue，那么客户端D获取锁失败。12345678910111213141516171819202122232425262728293031323334353637public boolean lock(KeyPrefix prefix, String key, String value) &#123; Jedis jedis = null; Long lockWaitTimeOut = 200L; Long deadTimeLine = System.currentTimeMillis() + lockWaitTimeOut; try &#123; jedis = jedisPool.getResource(); String realKey = prefix.getPrefix() + key; for (;;) &#123; if (jedis.setnx(realKey, value) == 1) &#123; return true; &#125; String currentValue = jedis.get(realKey); // if lock is expired if (!StringUtils.isEmpty(currentValue) &amp;&amp; Long.valueOf(currentValue) &lt; System.currentTimeMillis()) &#123; // gets last lock time String oldValue = jedis.getSet(realKey, value); if (!StringUtils.isEmpty(oldValue) &amp;&amp; oldValue.equals(currentValue)) &#123; return true; &#125; &#125; lockWaitTimeOut = deadTimeLine - System.currentTimeMillis(); if (lockWaitTimeOut &lt;= 0L) &#123; return false; &#125; &#125; &#125; finally &#123; returnToPool(jedis); &#125;&#125; 单机Redis分布式锁不同的客户端通过生成随机字符串对制定的Key进行set if not exists + ttl 操作来进行抢占,通过key的TTL时间来决定持有锁的时间. 然后通过LUA脚本执行事务操作进行Compare and delete进行释放锁.其中的TTL和本机时钟有关. 释放锁示例lua脚本内容如下12345if redis.call("get",KEYS[1]) == ARGV[1] then return redis.call("del",KEYS[1])else return 0end 这段Lua脚本在执行的时候要把的lockValue作为ARGV[1]的值传进去，把lockKey作为KEYS[1]的值传进去。现在来看看解锁的java代码123456789public void unlock() &#123; // 使用lua脚本进行原子删除操作 String checkAndDelScript = "if redis.call('get', KEYS[1]) == ARGV[1] then " + "return redis.call('del', KEYS[1]) " + "else " + "return 0 " + "end"; jedis.eval(checkAndDelScript, 1, lockKey, lockValue);&#125; 。 集群Redis分布式锁Redis 的作者提供了RedLock 的算法来实现一个分布式锁。 加锁RedLock算法加锁步骤如下: 获取当前Unix时间，以毫秒为单位。 依次尝试从N个实例，使用相同的key和随机值获取锁。在步骤2，当向Redis设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。 如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。 如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。 解锁向所有的Redis实例发送释放锁命令即可，不用关心之前有没有从Redis实例成功获取到锁. 实际秒杀场景中的应用实际上抢购，好像不用分布式锁，？？？？而是直接将库存放入到redis，是否结束标记放入到内存中，通过内存标记和redis中的decr()预减库存，然后将秒杀消息入队到消息队列中，最后消费消息并落地到DB中 分布式锁的重入该如何实现？待补充 如何确保过期时间大于业务执行时间可以加一个定时线程增加过期时间 codis待补充 参考https://juejin.im/post/5b737b9b518825613d3894f4]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你知道CoreDump吗？]]></title>
    <url>%2F2019%2F03%2F11%2F%E4%BD%A0%E7%9F%A5%E9%81%93CoreDump%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[什么是core dump文件Core dump文件是当一个进程在收到某些信号后终止时产生的文件，其中包含进程终止时刻进程内存的镜像。我们可以使用gdb从该镜像中观察进程终止时处于什么状态，用于追踪排查定位问题。 产生core dump的可能原因 内存访问越界 a) 由于使用错误的下标，导致数组访问越界 b) 搜索字符串时，依靠字符串结束符来判断字符串是否结束，但是字符串没有正常的使用结束符 c) 使用strcpy, strcat, sprintf, strcmp, strcasecmp等字符串操作函数，将目标字符串读/写爆。应该使用strncpy, strlcpy, strncat, strlcat, snprintf, strncmp, strncasecmp等函数防止读写越界。 多线程程序使用了线程不安全的函数。 多线程读写的数据未加锁保护。对于会被多个线程同时访问的全局数据，应该注意加锁保护，否则很容易造成core dump 非法指针 a) 使用空指针 b) 随意使用指针转换。一个指向一段内存的指针，除非确定这段内存原先就分配为某种结构或类型，或者这种结构或类型的数组，否则不要将它转换为这种结构或类型的指针，而应该将这段内存拷贝到一个这种结构或类型中，再访问这个结构或类型。这是因为如果这段内存的开始地址不是按照这种结构或类型对齐的，那么访问它时就很容易因为bus error而core dump. 堆栈溢出.不要使用大的局部变量（因为局部变量都分配在栈上），这样容易造成堆栈溢出，破坏系统的栈和堆结构，导致出现莫名其妙的错误。如何判断一个文件是coredump文件？在类unix系统下，coredump文件本身主要的格式也是ELF格式，因此，我们可以通过readelf命令进行判断。123456789101112131415161718192021root@ubuntu16-desktop:~# readelf -h core ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2&apos;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: CORE (Core file) //这里可以看出来 Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 64 (bytes into file) Start of section headers: 0 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 19 Size of section headers: 0 (bytes) Number of section headers: 0 Section header string table index: 0 或者通过file命令12root@ubuntu16-desktop:~# file corecore: ELF 64-bit LSB core file x86-64, version 1 (SYSV), SVR4-style, from &apos;./test&apos; 如何分析core dump文件使用调试器，如gdbhttps://www.gnu.org/software/gdb/举个栗子：写了个空指针栗子12345#include &lt;stdio.h&gt;int main()&#123; int *p = NULL; printf("hello world! \n"); printf("this will cause core dump p %d", *p);&#125; 执行该可执行文件会产生一个core文件（必须先通过参数打开该功能，要不即使有core dump，也不会产生core文件），如何分析呢？123456789101112131415161718192021222324gdb ./test core GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1Copyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word"...Reading symbols from ./test...done.[New LWP 18173]Core was generated by `./test'.Program terminated with signal SIGSEGV, Segmentation fault.#0 0x0000000000400584 in main () at main.c:44 printf("this will cause core dump p %d", *p);(gdb) bt //一般就可以看到出错的代码是哪一句了，还可以打印出相应变量的数值，进行进一步分析。#0 0x0000000000400584 in main () at main.c:4(gdb) 对于结构复杂的程序，如涉及模板类及复杂的调用，gdb得出了出错位置，似乎这还不够，这时候要使用更为专业的工具——valgrind。下载地址：http://valgrind.org/downloads/current.html 进入下载文件夹，分别执行(需要root权限，且必须按默认路径安装，否则有加载错误)：12345./configuremakemake install 安装成功后，使用类似如下命令启动程序： valgrind --tool=memcheck --leak-check=full --track-origins=yes --leak-resolution=high --show-reachable=yes --log-file=memchecklog ./controller_test 其中，–log-file=memchecklog指记录日志文件，名字为memchecklog；–tool=memcheck和–leak-check=full用于内存检测。 可以得到类似的记录：123456789==23735====23735== Thread 1:==23735== Invalid read of size 4==23735== at 0x804F327: ResourceHandler&lt;HBMessage&gt;::~ResourceHandler() (ResourceHandler.cpp:48)==23735== by 0x804FDBE: ConnectionManager&lt;HBMessage&gt;::~ConnectionManager() (ConnectionManager.cpp:74)==23735== by 0×8057288: MainThread::~MainThread() (MainThread.cpp:73)==23735== by 0x8077B2F: main (Main.cpp:177)==23735== Address 0×0 is not stack’d, malloc’d or (recently) free’d==23735== 可以看到说明为无法访问Address 0x0，明显为一处错误。 这样valgrind直接给出了出错原因以及程序中所有的内存调用、释放记录，非常智能，在得知错误原因的情况下，找出错误就效率高多了。再说一句，valgrind同时给出了程序的Memory Leak情况的报告，给出了new-delete对应情况，所有泄漏点位置给出，这一点在其他工具很难做到，十分好用。 与core dump有关的内核参数 kernel.core_pattern设置core文件保存位置或文件名,只有文件名时，则保存在应用程序运行的目录下 /proc/sys/kernel/core_pipe_limit定义了可以有多少个并发的崩溃程序可以通过管道模式传递给指定的core信息收集程序。如果超过了指定数，则后续的程序将不会处理，只在内核日志中做记录。0是个特殊的值，当设置为0时，不限制并行捕捉崩溃的进程，但不会等待用户程序搜集完毕方才回收/proc/pid目录（就是说，崩溃程序的相关信息可能随时被回收，搜集的信息可能不全）。 kernel.core_uses_pidCore文件的文件名是否添加应用程序pid做为扩展。0：不添加，1：添加 设置Core文件大小上限 123456 # ulimit -c 0 // 0表示不产生core文件# ulimit -c 100 // 100表示设置core文件最大为100k，当然可以根据自己需要设置，注意设置单位是KB# ulimit -c unlimited // 不限制core文件大小使用上述命令设置core文件大小只对当前shell环境有效，系统重启或者退出当前shell设置就会失效，恢复默认设置。若想永久生效可以把该shell放到/etc/profile文件中，系统重新启动初始化环境时会执行其中的命令，该设置就会在全局范围内生效，达到永久生效的效果。也可以使用 source /etc/profile命令立即全局生效。# echo "unlimit -c unlimited" &gt;&gt; /etc/profile // 配置添加到/etc/profile中# source /etc/profile // 立即生效 设置Core文件存储目录 1234567891011121314# echo "/var/core-dir/core-%e-%p-%t" &gt; /proc/sys/kernel/core_pattern该命令可以控制core文件保存位置和文件名格式。注意需要使用root权限执行，并且存储路径必须是绝对路径，不能是相对路径其中%e表示添加用户程序名称，%p表示添加程序进程PID，%t表示添加产生core文件时的时间戳，还有其他一些非常有用的格式，可以参阅CORE(5)文档。这样修改后系统重启后也会消失，同样也有永久生效的办法修改/etc/sysctl.conf文件在其中修改或者添加/etc/sysctl.confkernel.core_pattern = /var/core-dir/core-%e-%p-%t然后执行下面命令配置立即生效，这样系统重启后配置依然有效# sysctl –p /etc/sysctl.conf core dump文件产生流程大概说一下从进程出现异常到生成core文件的流程，不会涉及太多Linux系统实现细节，具体细节可以参考相关文档和linux内核源码。 进程运行时发生一个异常，比如非法内存地址访问（即段错误），相应硬件会上报该异常，CPU检测到该异常时会进入异常处理流程,包括保存当前上下文，跳转到对应的中断向量执行入口等 在异常处理流程中如果判断该异常发生时是处于用户态，则该异常只会影响当前进程，此时向用户态进程发送相应的信号，如段错误就会发送SIGSEGV信号 当用户态进程被调度时会检查pending的信号，如果发现pending的信号是SIG_KERNEL_COREDUMP_MASK中的一个，就会进入core文件内容收集存储流程，然后根据配置(core_pattern等)生成core文件。 处理docker容器进程Core Dump的方法 使用ulimit -c和/proc/sys/kernel/core_pattern设置Core Dump文件大小限制和存储位置 使用管道程序增强Core Dump文件处理能力 使用管道程序和容器内进程结合的方式完成内核态转到用户态，在容器内处理Core文件存储 简单来说就是，因为有关core dump的设置容器并没有隔离，所以在主机上所有的设置，容器也是一样的。但是我们想针对容器进行特殊处理，那么我们可以使用linux的piping技术转储core文件。但是管道程序是作为内核线程在运行的，运行在内核态，并且在宿主机Initial Namespace中以root用户身份运行，不在任何容器内。我们想在容器内运行这么一个程序，可以使用socket activation技术，简单来说，就是由系统init进程（对于目前大多数linux系统来说是systemd）来为普通应用进程监听特定socket，此时应用进程并未启动，当有连接到达该socket后，由init进程接管该连接并跟进配置文件启动相应的应用进程，然后把连接传递给应用进程来处理，主要好处是当没有连接到达时，应用进程无需常驻后台空跑耗费系统资源。非常适合像Core Dump这种低频服务。我们可以设置一个unix socket来把管道程序的文件描述符传递到容器内进程，完成传递后， 管道程序就可以退出，由容器内进程处理core文件的存储。 参考小米运维https://blog.csdn.net/pengzhouzhou/article/details/88313891https://www.cnblogs.com/bodhitree/p/5850212.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-compose的问题]]></title>
    <url>%2F2019%2F02%2F22%2Fdocker-compose%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天我启动docker-compose的时候，出现了如下问题 经过查询得知https://blog.csdn.net/tianshuhao521/article/details/84782309，原因是关闭防火墙之后docker需要重启，执行以下命令重启docker即可：service docker restart 但是我重启不行，journalctl -xe查看日志，发现 原来有访问控制了，可能是因为我们实验室对该服务器的内核进行了白名单。lsmod命令一输，结果如下，发现确实有一个操作系统安全module。 通过rmmod卸载掉之后就可以 了。 通过dmesg查看信息发现， 进一步思考：他的这个原理是什么？有待补充]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跳表]]></title>
    <url>%2F2019%2F02%2F22%2F%E8%B7%B3%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[这是一个基本的跳表数据结构,简单的代码实现:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;//跳表的最大层级为32级#define ZSKIPLIST_MAXLEVEL 32#define ZSKIPLIST_P 0.25#include&lt;math.h&gt;//跳表节点typedef struct zskiplistNode &#123; int key; int value; struct zskiplistLevel &#123; struct zskiplistNode *forward; &#125; level[1];&#125; zskiplistNode;//跳表typedef struct zskiplist &#123; struct zskiplistNode *header; int level;&#125; zskiplist;//创建跳表的节点zskiplistNode *zslCreateNode(int level, int key, int value) &#123; zskiplistNode *zn = (zskiplistNode *)malloc(sizeof(*zn)+level*sizeof(zn-&gt;level)); zn-&gt;key = key; zn-&gt;value = value; return zn;&#125;//初始化跳表zskiplist *zslCreate(void) &#123; int j; zskiplist *zsl; zsl = (zskiplist *) malloc(sizeof(*zsl)); zsl-&gt;level = 1;//将层级设置为1 zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,NULL,NULL); for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123; zsl-&gt;header-&gt;level[j].forward = NULL; &#125; return zsl;&#125;//向跳表中插入元素时，通过随机函数获取一个层级，表示插入在哪一层,ZSKIPLIST_P为何设置为0.25？int zslRandomLevel(void) &#123; int level = 1; while ((rand()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125;//向跳表中插入元素zskiplistNode *zslInsert(zskiplist *zsl, int key, int value) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i, level; x = zsl-&gt;header; //在跳表中寻找合适的位置并插入元素 for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;key &lt; key || (x-&gt;level[i].forward-&gt;key == key &amp;&amp; x-&gt;level[i].forward-&gt;value &lt; value))) &#123; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; //获取元素所在的随机层数 level = zslRandomLevel(); if (level &gt; zsl-&gt;level) &#123; for (i = zsl-&gt;level; i &lt; level; i++) &#123; update[i] = zsl-&gt;header; &#125; zsl-&gt;level = level; &#125; //为新创建的元素创建数据节点 x = zslCreateNode(level,key,value); for (i = 0; i &lt; level; i++) &#123; x-&gt;level[i].forward = update[i]-&gt;level[i].forward; update[i]-&gt;level[i].forward = x; &#125; return x;&#125;//跳表中删除节点的操作void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) &#123; int i; for (i = 0; i &lt; zsl-&gt;level; i++) &#123; if (update[i]-&gt;level[i].forward == x) &#123; update[i]-&gt;level[i].forward = x-&gt;level[i].forward; &#125; &#125; //如果层数变了，相应的将层数进行减1操作 while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL) zsl-&gt;level--;&#125;//从跳表中删除元素int zslDelete(zskiplist *zsl, int key, int value) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; x = zsl-&gt;header; //寻找待删除元素 for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;key &lt; key || (x-&gt;level[i].forward-&gt;key == key &amp;&amp; x-&gt;level[i].forward-&gt;value &lt; value))) &#123; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; x = x-&gt;level[0].forward; if (x &amp;&amp; key == x-&gt;key &amp;&amp; x-&gt;value == value) &#123; zslDeleteNode(zsl, x, update); //别忘了释放节点所占用的存储空间 free(x); return 1; &#125; else &#123; //未找到相应的元素 return 0; &#125; return 0;&#125;//将链表中的元素打印出来void printZslList(zskiplist *zsl) &#123; zskiplistNode *x; x = zsl-&gt;header; for (int i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; zskiplistNode *p = x-&gt;level[i].forward; while (p) &#123; printf(" %d|%d ",p-&gt;key,p-&gt;value); p = p-&gt;level[i].forward; &#125; printf("\n"); &#125;&#125;int main() &#123; zskiplist *list = zslCreate(); zslInsert(list,1,2); zslInsert(list,4,5); zslInsert(list,2,2); zslInsert(list,7,2); zslInsert(list,7,3); zslInsert(list,7,3); printZslList(list); zslDelete(list,7,2); printZslList(list);&#125;/* 4|5 1|2 2|2 4|5 7|2 7|3 7|3 4|5 1|2 2|2 4|5 7|3 7|3 */ 我们都知道redis中zset有序集，内部实现用了跳表，那么又有哪些优化呢？ Redis中跳表的基本数据结构定义如下，与基本跳表数据结构相比，在Redis中实现的跳表其特点是不仅有前向指针，也存在后向指针，而且在前向指针的结构中存在span跨度字段，这个跨度字段的出现有助于快速计算元素在整个集合中的排名。 12345678910111213141516171819202122//定义跳表的基本数据节点typedef struct zskiplistNode &#123; robj *obj; // zset value double score;// zset score struct zskiplistNode *backward;//后向指针 struct zskiplistLevel &#123;//前向指针 struct zskiplistNode *forward; unsigned int span; &#125; level[];&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; unsigned long length; int level;&#125; zskiplist;//有序集数据结构typedef struct zset &#123; dict *dict;//字典存放value,以value为key zskiplist *zsl;&#125; zset; 将如上数据结构转化成更形式化的图形表示，如下图所示 可以看到header指针指向的是一个具有固定层级(32层)的表头节点,为什么定义成32,是因为定义成32层理论上对于2^32-1个元素的查询最优，而2^32=4294967296个元素，对于绝大多数的应用来说，已经足够了，所以就定义成了32层,到于为什么查询最优，你可以将其想像成一个32层的完全二叉排序树，算算这个树中节点的数量。 Redis中有序集另一个值得注意的地方就是当Score相同的时候，是如何存储的，当集合中两个值的Score相同，这时在跳表中存储会比较这两个值，对这两个值按字典排序存储在跳表结构中 下面来看看Redis对zskiplist/zskiplistNode的相关操作,源码如下所示(源码均出自t_zset.c) 创建跳表结构的源码123456789101112131415161718192021//#define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^32 elements */zskiplist *zslCreate(void) &#123; int j; zskiplist *zsl; //分配内存 zsl = zmalloc(sizeof(*zsl)); zsl-&gt;level = 1;//默认层级为1 zsl-&gt;length = 0;//跳表长度设置为0 zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123; //因为没有任何元素，将表头节点的前向指针均设置为0 zsl-&gt;header-&gt;level[j].forward = NULL; //将表头节点前向指针结构中的跨度字段均设为0 zsl-&gt;header-&gt;level[j].span = 0; &#125; //表头后向指针设置成0 zsl-&gt;header-&gt;backward = NULL; //表尾节点设置成NULL zsl-&gt;tail = NULL; return zsl;&#125; 在上述代码中调用了zslCreateNode这个函数,函数的源码如下所示。 123456zskiplistNode *zslCreateNode(int level, double score, robj *obj) &#123; zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel)); zn-&gt;score = score; zn-&gt;obj = obj; return zn;&#125; 执行完上述代码之后会创建如下图所示的跳表结构 创建了跳表的基本结构，下面就是插入操作了，Redis中源码如下所示1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950zskiplistNode *zslInsert(zskiplist *zsl, double score, robj *obj) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; //update[32] unsigned int rank[ZSKIPLIST_MAXLEVEL];//rank[32] int i, level; redisAssert(!isnan(score)); x = zsl-&gt;header; //寻找元素插入的位置 for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* store rank that is crossed to reach the insert position */ rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || //以下是得分相同的情况下，比较value的字典排序 (x-&gt;level[i].forward-&gt;score == score &amp;&amp;compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) &#123; rank[i] += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; //产生随机层数 level = zslRandomLevel(); if (level &gt; zsl-&gt;level) &#123; for (i = zsl-&gt;level; i &lt; level; i++) &#123; rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; &#125; //记录最大层数 zsl-&gt;level = level; &#125; //产生跳表节点 x = zslCreateNode(level,score,obj); for (i = 0; i &lt; level; i++) &#123; x-&gt;level[i].forward = update[i]-&gt;level[i].forward; update[i]-&gt;level[i].forward = x; //更新跨度 x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1; &#125; //此种情况只会出现在随机出来的层数小于最大层数时 for (i = level; i &lt; zsl-&gt;level; i++) &#123; update[i]-&gt;level[i].span++; &#125; x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0]; if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x; else zsl-&gt;tail = x; zsl-&gt;length++; return x;&#125; 上述源码中，有一个产生随机层数的函数，源代码如下所示: 12345678int zslRandomLevel(void) &#123; int level = 1; //#define ZSKIPLIST_P 0.25 while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; //#ZSKIPLIST_MAXLEVEL 32 return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125; 图形化的形式描述如下图所示: 参考https://www.cnblogs.com/WJ5888/p/4595306.html]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[当你在浏览器输入google.com之后]]></title>
    <url>%2F2019%2F02%2F22%2F%E5%BD%93%E4%BD%A0%E5%9C%A8%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5google-com%E4%B9%8B%E5%90%8E%2F</url>
    <content type="text"><![CDATA[按下”g”键当你按下“g”键，浏览器接收到这个消息之后，会触发自动完成机制。浏览器根据自己的算法，以及你是否处于隐私浏览模式，会在浏览器的地址框下方给出输入建议。大部分算法会优先考虑根据你的搜索历史和书签等内容给出建议。你打算输入 “google.com”，因此给出的建议并不匹配。但是输入过程中仍然有大量的代码在后台运行，你的每一次按键都会使得给出的建议更加准确。甚至有可能在你输入之前，浏览器就将 “google.com” 建议给你。 回车键按下为了从零开始，我们选择键盘上的回车键被按到最低处作为起点。在这个时刻，一个专用于回车键的电流回路被直接地或者通过电容器间接地闭合了，使得少量的电流进入了键盘的逻辑电路系统。这个系统会扫描每个键的状态，对于按键开关的电位弹跳变化进行噪音消除(debounce)，并将其转化为键盘码值。在这里，回车的码值是13。键盘控制器在得到码值之后，将其编码，用于之后的传输。现在这个传输过程几乎都是通过通用串行总线(USB)或者蓝牙(Bluetooth)来进行的，以前是通过PS/2或者ADB连接进行。 USB键盘：键盘的USB元件通过计算机上的USB接口与USB控制器相连接，USB接口中的第一号针为它提供了5V的电压键码值存储在键盘内部电路一个叫做”endpoint”的寄存器内USB控制器大概每隔10ms便查询一次”endpoint”以得到存储的键码值数据，这个最短时间间隔由键盘提供键值码值通过USB串行接口引擎被转换成一个或者多个遵循低层USB协议的USB数据包这些数据包通过D+针或者D-针(中间的两个针)，以最高1.5Mb/s的速度从键盘传输至计算机。速度限制是因为人机交互设备总是被声明成”低速设备”（USB 2.0 compliance）这个串行信号在计算机的USB控制器处被解码，然后被人机交互设备通用键盘驱动进行进一步解释。之后按键的码值被传输到操作系统的硬件抽象层 虚拟键盘（触屏设备）：在现代电容屏上，当用户把手指放在屏幕上时，一小部分电流从传导层的静电域经过手指传导，形成了一个回路，使得屏幕上触控的那一点电压下降，屏幕控制器产生一个中断，报告这次“点击”的坐标然后移动操作系统通知当前活跃的应用，有一个点击事件发生在它的某个GUI部件上了，现在这个部件是虚拟键盘的按钮虚拟键盘引发一个软中断，返回给OS一个“按键按下”消息这个消息又返回来向当前活跃的应用通知一个“按键按下”事件 解析URL浏览器通过 URL 能够知道下面的信息：Protocol “http”使用HTTP协议Resource “/“请求的资源是主页(index) 输入的是 URL 还是搜索的关键字？当协议或主机名不合法时，浏览器会将地址栏中输入的文字传给默认的搜索引擎。大部分情况下，在把文字传递给搜索引擎的时候，URL会带有特定的一串字符，用来告诉搜索引擎这次搜索来自这个特定浏览器。 转换非 ASCII 的 Unicode 字符浏览器检查输入是否含有不是 a-z， A-Z，0-9， - 或者 . 的字符这里主机名是 google.com ，所以没有非ASCII的字符；如果有的话，浏览器会对主机名部分使用 Punycode 编码 检查 HSTS 列表 浏览器检查自带的“预加载 HSTS（HTTP严格传输安全）”列表，这个列表里包含了那些请求浏览器只使用HTTPS进行连接的网站 如果网站在这个列表里，浏览器会使用 HTTPS 而不是 HTTP 协议，否则，最初的请求会使用HTTP协议发送 注意，一个网站哪怕不在 HSTS 列表里，也可以要求浏览器对自己使用 HSTS 政策进行访问。浏览器向网站发出第一个 HTTP 请求之后，网站会返回浏览器一个响应，请求浏览器只使用 HTTPS 发送请求。然而，就是这第一个 HTTP 请求，却可能会使用户受到 downgrade attack 的威胁，这也是为什么现代浏览器都预置了 HSTS 列表。 DNS查询浏览器检查域名是否在缓存当中（要查看 Chrome 当中的缓存， 打开 chrome://net-internals/#dns）。如图如果缓存中没有，就去调用 gethostbyname 库函数（操作系统不同函数也不同）进行查询。gethostbyname 函数在试图进行DNS解析之前首先检查域名是否在本地 Hosts 里，Hosts 的位置 不同的操作系统有所不同如果 gethostbyname 没有这个域名的缓存记录，也没有在 hosts 里找到，它将会向 DNS 服务器发送一条 DNS 查询请求。DNS 服务器是由网络通信栈提供的，通常是本地路由器或者 ISP 的缓存 DNS 服务器。查询本地 DNS 服务器如果 DNS 服务器和我们的主机在同一个子网内，系统会按照下面的 ARP 过程对 DNS 服务器进行 ARP查询如果 DNS 服务器和我们的主机在不同的子网，系统会按照下面的 ARP 过程对默认网关进行查询 ARP 过程要想发送 ARP（地址解析协议）广播，我们需要有一个目标 IP 地址，同时还需要知道用于发送 ARP 广播的接口的 MAC 地址。 首先查询 ARP 缓存，如果缓存命中，我们返回结果：目标 IP = MAC 如果缓存没有命中： 查看路由表，看看目标 IP 地址是不是在本地路由表中的某个子网内。是的话，使用跟那个子网相连的接口，否则使用与默认网关相连的接口。 查询选择的网络接口的 MAC 地址 我们发送一个二层（ OSI 模型 中的数据链路层）ARP 请求：ARP Request:1234Sender MAC: interface:mac:address:hereSender IP: interface.ip.goes.hereTarget MAC: FF:FF:FF:FF:FF:FF (Broadcast)Target IP: target.ip.goes.here 根据连接主机和路由器的硬件类型不同，可以分为以下几种情况： 直连： 如果我们和路由器是直接连接的，路由器会返回一个 ARP Reply （见下面）。 集线器： 如果我们连接到一个集线器，集线器会把 ARP 请求向所有其它端口广播，如果路由器也“连接”在其中，它会返回一个 ARP Reply 。 交换机： 如果我们连接到了一个交换机，交换机会检查本地 CAM/MAC 表，看看哪个端口有我们要找的那个 MAC 地址，如果没有找到，交换机会向所有其它端口广播这个 ARP 请求。如果交换机的 MAC/CAM 表中有对应的条目，交换机会向有我们想要查询的 MAC 地址的那个端口发送 ARP 请求如果路由器也“连接”在其中，它会返回一个 ARP ReplyARP Reply:1234Sender MAC: target:mac:address:hereSender IP: target.ip.goes.hereTarget MAC: interface:mac:address:hereTarget IP: interface.ip.goes.here 现在我们有了 DNS 服务器或者默认网关的 IP 地址172.21.0.21，如下图，我们可以继续 DNS 请求了： 使用 53 端口向 DNS 服务器发送 UDP 请求包，如果响应包太大，会使用 TCP 协议 如果本地/ISP DNS 服务器没有找到结果，它会发送一个递归查询请求，一层一层向高层 DNS 服务器做查询，直到查询到起始授权机构，如果找到会把结果返回。 使用套接字当浏览器得到了目标服务器的 IP 地址，以及 URL 中给出来端口号（http 协议默认端口号是 80， https 默认端口号是 443），它会调用系统库函数 socket ，请求一个 TCP流套接字，对应的参数是 AF_INET/AF_INET6 和 SOCK_STREAM 。 这个请求首先被交给传输层，在传输层请求被封装成 TCP segment。目标端口会被加入头部，源端口会在系统内核的动态端口范围内选取（Linux下是ip_local_port_range) TCP segment 被送往网络层，网络层会在其中再加入一个 IP 头部，里面包含了目标服务器的IP地址以及本机的IP地址，把它封装成一个IP packet。 这个 TCP packet 接下来会进入链路层，链路层会在封包中加入 frame 头部，里面包含了本地内置网卡的MAC地址以及网关（本地路由器）的 MAC 地址。像前面说的一样，如果内核不知道网关的 MAC 地址，它必须进行 ARP 广播来查询其地址。 到了现在，TCP 封包已经准备好了，可以使用下面的方式进行传输： 以太网 WiFi 蜂窝数据网络 TCP三次握手TLS握手 客户端发送一个 ClientHello 消息到服务器端，消息中同时包含了它的 Transport Layer Security (TLS) 版本，可用的加密算法和压缩算法。 服务器端向客户端返回一个 ServerHello 消息，消息中包含了服务器端的TLS版本，服务器所选择的加密和压缩算法，以及数字证书认证机构（Certificate Authority，缩写 CA）签发的服务器公开证书，证书中包含了公钥。客户端会使用这个公钥加密接下来的握手过程，直到协商生成一个新的对称密钥 客户端根据自己的信任CA列表，验证服务器端的证书是否可信。如果认为可信，客户端会生成一串伪随机数，使用服务器的公钥加密它。这串随机数会被用于生成新的对称密钥 服务器端使用自己的私钥解密上面提到的随机数，然后使用这串随机数生成自己的对称主密钥客户端发送一个 Finished 消息给服务器端，使用对称密钥加密这次通讯的一个散列值 服务器端生成自己的 hash 值，然后解密客户端发送来的信息，检查这两个值是否对应。如果对应，就向客户端发送一个 Finished 消息，也使用协商好的对称密钥加密从现在开始，接下来整个 TLS 会话都使用对称秘钥进行加密，传输应用层（HTTP）内容 HTTP 协议如果浏览器是 Google 出品的，它不会使用 HTTP 协议来获取页面信息，而是会与服务器端发送请求，商讨使用 SPDY 协议。 如果浏览器使用 HTTP 协议而不支持 SPDY 协议，它会向服务器发送这样的一个请求:1234GET / HTTP/1.1Host: google.comConnection: close[其他头部] 如下图 浏览器背后的故事当服务器提供了资源之后（HTML，CSS，JS，图片等），浏览器会执行下面的操作： 解析 —— HTML，CSS，JS渲染 —— 构建 DOM 树 -&gt; 渲染 -&gt; 布局 -&gt; 绘制。 参考https://github.com/skyline75489/what-happens-when-zh_CN]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询缓存]]></title>
    <url>%2F2019%2F02%2F22%2FMysql%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[开启查询缓存后，查询语句的解析过程： 在解析一个查询语句之前，如果查询缓存是打开的，那么MySQL会优先检查这个查询是否命中查询缓存中的数据。如果当前的查询恰好命中了查询缓存，那么在返回查询结果之前MySQL会检查一次用户权限。若权限没有问题，MySQL会跳过所有其他阶段（解析、优化、执行等），直接从缓存中拿到结果并返回给客户端。这种情况下，查询不会被解析，不用生成执行计划，不会被执行。 开启查询缓存设置使用查询缓存的方式使用 query_cache_type 变量来开启查询缓存，开启方式有三种： ON : 正常缓存。表示在使用 SELECT 语句查询时，若没指定 SQL_NO_CACHE 或其他非确定性函数，则一般都会将查询结果缓存下来。 DEMAND ：指定SQL_CACHE才缓存。表示在使用 SELECT 语句查询时，必须在该 SELECT 语句中指定 SQL_CACHE 才会将该SELECT语句的查询结果缓存下来。 例如：select SQL_CACHE name from user where id = 15; #只有明确指定 SQL_CACHE 的SELECT语句，才会将查询结果缓存。 OFF： 关闭查询缓存。 立刻生效，重启服务失效 mysql&gt; set global query_cache_type=1; 当my.cnf 中，query_cache_type = OFF ，启动mysql服务后，在mysql命令行中使用上面语句开启查询缓存，会报错：ERROR 1651 (HY000): Query cache is disabled; restart the server with query_cache_type=1 to enable it。遇到这种情况，是无法在mysql命令行中开启查询缓存的，必须修改my.cnf的query_cache_type = ON，然后重启mysql服务。 设置查询缓存的大小 query_cache_size ：查询缓存的总体可用空间。 注意：如果 query_cache_size=0 ，那即便你设置了 query_cache_type = ON，查询缓存仍然是无法工作的。 查询缓存相关参数123456uery_cache_limit : MySQL能够缓存的最大查询结果；如果某查询的结果大小大于此值，则不会被缓存；query_cache_min_res_unit : 查询缓存中分配内存的最小单位；(注意：此值通常是需要调整的，此值被调整为接近所有查询结果的平均值是最好的) 计算单个查询的平均缓存大小：（query_cache_size-Qcache_free_memory）/Qcache_queries_in_cachequery_cache_size : 查询缓存的总体可用空间，单位为字节；其必须为1024的倍数；query_cache_type: 查询缓存类型；是否开启缓存功能，开启方式有三种&#123;ON|OFF|DEMAND&#125;；query_cache_wlock_invalidate : 当其它会话锁定此次查询用到的资源时，是否不能再从缓存中返回数据；（OFF表示可以从缓存中返回数据） 查询缓存状态12345678910111213mysql&gt; SHOW GLOBAL STATUS LIKE &apos;Qcache%&apos;;+-------------------------+----------+| Variable_name | Value |+-------------------------+----------+| Qcache_free_blocks | 1 | #查询缓存中的空闲块| Qcache_free_memory | 16759656| #查询缓存中尚未使用的空闲内存空间| Qcache_hits | 16 | #缓存命中次数| Qcache_inserts | 71 | #向查询缓存中添加缓存记录的条数| Qcache_lowmem_prunes | 0 | #表示因缓存满了而不得不清理部分缓存以存储新的缓存，这样操作的次数。若此数值过大，则表示缓存空间太小了。| Qcache_not_cached | 57 | #没能被缓存的次数| Qcache_queries_in_cache | 0 | #此时仍留在查询缓存的缓存个数| Qcache_total_blocks | 1 | #共分配出去的块数+-------------------------+----------+ 衡量缓存是否有效方式一：1234567mysql&gt; SHOW GLOBAL STATUS WHERE Variable_name=&apos;Qcache_hits&apos; OR Variable_name=&apos;Com_select&apos;;+---------------+-----------+| Variable_name | Value |+---------------+-----------+| Com_select | 279292490 | #非缓存查询次数| Qcache_hits | 307366973 | # 缓存命中次数+---------------+----------- 缓存命中率：Qcache_hits/(Qcache_hits+Com_select) 方式二：“命中和写入”的比率这是另外一种衡量缓存是否有效的指标。 123456mysql&gt; SHOW GLOBAL STATUS WHERE Variable_name=&apos;Qcache_hits&apos; OR Variable_name=&apos;Qcache_inserts&apos;;+----------------+-----------+| Variable_name | Value |+----------------+-----------+| Qcache_hits | 307416113 | #缓存命中次数| Qcache_inserts | 108873957 | #向查询缓存中添加缓存记录的条数 “命中和写入”的比率: Qcache_hits/Qcache_inserts # 如果此比值大于3:1, 说明缓存也是有效的；如果高于10:1，相当理想； 缓存失效问题当数据表改动时，基于该数据表的任何缓存都会被删除。（表层面的管理，不是记录层面的管理，因此失效率较高） 注意事项： 应用程序，不应该关心query cache的使用情况。可以尝试使用，但不能由query cache决定业务逻辑，因为query cache由DBA来管理。 缓存是以SQL语句为key存储的，因此即使SQL语句功能相同，但如果多了一个空格或者大小写有差异都会导致匹配不到缓存。 参考：https://www.jianshu.com/p/5c3ddf9a454chttps://juejin.im/post/5c6b9c09f265da2d8a55a855]]></content>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络之raw_socket]]></title>
    <url>%2F2019%2F02%2F22%2F%E7%BD%91%E7%BB%9C%E4%B9%8Braw-socket%2F</url>
    <content type="text"><![CDATA[什么是Raw_Socket?raw socket，即原始套接字，可以接收本机网卡上的数据帧或者数据包,对与监听网络的流量和分析是很有作用的.一共可以有3种方式创建这种socket 1.socket(AF_INET, SOCK_RAW, IPPROTO_TCP|IPPROTO_UDP|IPPROTO_ICMP)发送接收ip数据包 2.socket(PF_PACKET, SOCK_RAW, htons(ETH_P_IP|ETH_P_ARP|ETH_P_ALL))发送接收以太网数据帧 3.socket(AF_INET, SOCK_PACKET, htons(ETH_P_IP|ETH_P_ARP|ETH_P_ALL))用于抓包程序，过时了,不要用啊 (raw socket只有在Linux平台上才能发挥它本该有的功能。因为windows进行了限制，比如只能发送UDP包，只能发送正确的UDP包，不能冒充源地址，即源地址只能填本机地址) 通过一个例子来理解Raw_scoket的原理比如网卡收到了一个 14+20+8+100+4 的udp的以太网数据帧. 首先,网卡对该数据帧进行硬过滤(根据网卡的模式不同会有不同的动作,如果设置了promisc混杂模式的话,则不做任何过滤直接交给下一层输入例程,否则非本机mac或者广播mac会被直接丢弃).按照上面的例子,如果成功的话,会进入ip输入例程.但是在进入ip输入例程之前,系统会检查系统中是否有通过socket(AF_PACKET, SOCK_RAW, ..)创建的套接字.如果有的话并且协议相符,在这个例子中就是需要ETH_P_IP或者ETH_P_ALL类型.系统就给每个这样的socket接收缓冲区发送一个数据帧拷贝.然后进入下一步. 其次,进入了ip输入例程(ip层会对该数据包进行软过滤,就是检查校验或者丢弃非本机ip或者广播ip的数据包等,具体要参考源代码),例子中就是如果成功的话会进入udp输入例程.但是在交给udp输入例程之前,系统会检查系统中是否有通过socket(AF_INET, SOCK_RAW, ..)创建的套接字.如果有的话并且协议相符,在这个例子中就是需要IPPROTO_UDP类型.系统就给每个这样的socket接收缓冲区发送一个数据帧拷贝.然后进入下一步。 最后,进入udp输入例程 … ps:如果校验和出错的话,内核会直接丢弃该数据包的.而不会拷贝给sock_raw的套接字,因为校验和都出错了,数据肯定有问题的包括所有信息都没有意义了. socket的分类根据网路的7层模型，socket可以分为3种。 传输层socket-最常用的socket，非raw socket 网络层socket - 网络层 raw socket MAC层socket -收发数据链路层数据 raw socket的用途 通过raw socket来接收发向本机的ICMP,IGMP协议包,或者用来发送这些协议包. 接收发向本机但TCP/IP栈不能够处理的IP包：现在许多操作系统在实现网络部分的时候,通常只实现了常用的几种协议,如tcp,udp,icmp等,但象其它的如ospf,ggp等协议,操作系统往往没有实现,如果自己有必要编写位于其上的应用,就必须借助raw socket来实现,这是因为操作系统遇到自己不能够处理的数据包(ip头中的protocol所指定的上层协议不能处理)就将这个包交给协议对应的raw socket. 用来发送一些自己制定源地址等特殊作用的IP包(自己写IP头,TCP头等等)，因为内核不能识别的协议、格式等将传给原始套接字，因此，可以使用原始套接字定义用户自己的协议格式 内核接收网络数据后在rawsocket上处理原则 (1):对于UDP/TCP产生的IP数据包,内核不将它传递给任何网络层的原始套接字,而只是将这些数据直接交给对应的传输层UDP/TCP数据socket处理句柄。所以,只能通过MAC层原始套接字将第3个参数指定为htons(ETH_P_IP)来访问TCP/UDP数据。 (2):对于ICMP和EGP等使用IP数据包承载数据但又在传输层之下的协议类型的IP数据包,内核不管是否已经有注册了句柄来处理这些数据,都会将这些IP数据包复制一份传递给协议类型匹配的原始套接字.（网络层套接字能截获除TCP/UDP以外传输层协议号protocol相同的ip数据） (3):对于不能识别协议类型的数据包,内核进行必要的校验,然后会查看是否有类型匹配的原始套接字负责处理这些数据,如果有的话,就会将这些IP数据包复制一份传递给匹配的原始套接字,否则,内核将会丢弃这个IP数据包,并返回一个ICMP主机不可达的消息给源主机. (4):如果原始套接字bind绑定了一个地址,核心只将目的地址为本机IP地址的数包传递给原始套接字,如果某个原始套接字没有bind地址,核心就会把收到的所有IP数据包发给这个原始套接字. (5):如果原始套接字调用了connect函数,则核心只将源地址为connect连接的IP地址的IP数据包传递给这个原始套接字. (6):如果原始套接字没有调用bind和connect函数,则核心会将所有协议匹配的IP数据包传递给这个原始套接字. 啥是Packet套接字？？在linux环境中要从链路层（MAC）直接收发数据帧，可以通过libpcap与libnet两个动态库来分别完成收与发的工作。虽然它已被广泛使用，但在要求进行跨平台移植的软件中使用仍然有很多弊端。 这里介绍一种更为直接地、无须安装其它库的从MAC层收发数据帧的方式，即通过定义链路层的套接字来完成。 Packet套接字用于在MAC层上收发原始数据帧，这样就允许用户在用户空间完成MAC之上各个层次的实现。给无论是进行开发还是测试的人们带来了极大的便利性。 Packet套接字的定义方式与传送层的套接字定义类似，如下： packet_socket=socket(PF_PACKET,int socket_type,int protocol);（这个套接字的打开需要用户有root权限） RAW套接字和Packet套接字的比较 Packet套接字需要关联到一个特定的网卡直接发送，无需经过路由查找和地址解析。这是显然的，路由查找的目的无非也就是定位到一个网卡，现在网卡已经有了，直接发送即可，至于发到了哪里，能不能到达目的地，听天由命了。 RAW套接字这种RAW套接字发送的报文是需要经过路由查找的，只是说IP头以及IP上层的协议以及数据可以自己构造。 代码：用rawSocket来进行自定义IP报文的源地址。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/ip.h&gt;#include &lt;netinet/udp.h&gt;#include&lt;memory.h&gt;#include&lt;stdlib.h&gt;#include &lt;linux/if_ether.h&gt;#include &lt;linux/if_packet.h&gt; // sockaddr_ll#include&lt;arpa/inet.h&gt;#include&lt;netinet/if_ether.h&gt;#include&lt;iomanip&gt;#include&lt;iostream&gt; // The packet length#define PCKT_LEN 100 //UDP的伪头部struct UDP_PSD_Header&#123; u_int32_t src; u_int32_t des; u_int8_t mbz; u_int8_t ptcl; u_int16_t len;&#125;;//计算校验和unsigned short csum(unsigned short *buf, int nwords)&#123; unsigned long sum; for (sum = 0; nwords &gt; 0; nwords--) &#123; sum += *buf++; &#125; sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff); sum += (sum &gt;&gt; 16); return (unsigned short)(~sum);&#125; // Source IP, source port, target IP, target port from the command line argumentsint main(int argc, char *argv[])&#123; int sd; char buffer[PCKT_LEN] ; //查询www.chongfer.cn的DNS报文 unsigned char DNS[] = &#123; 0xd8, 0xcb , 0x01, 0x00, 0x00, 0x01, 0x00 ,0x00, 0x00, 0x00, 0x00, 0x00, 0x03, 0x77, 0x77, 0x77, 0x08, 0x63, 0x68, 0x6f, 0x6e, 0x67, 0x66, 0x65, 0x72, 0x02, 0x63, 0x6e, 0x00, 0x00, 0x01, 0x00, 0x01 &#125;; struct iphdr *ip = (struct iphdr *) buffer; struct udphdr *udp = (struct udphdr *) (buffer + sizeof(struct iphdr)); // Source and destination addresses: IP and port struct sockaddr_in sin, din; int one = 1; const int *val = &amp;one; //缓存清零 memset(buffer, 0, PCKT_LEN); if (argc != 5) &#123; printf("- Invalid parameters!!!\n"); printf("- Usage %s &lt;source hostname/IP&gt; &lt;source port&gt; &lt;target hostname/IP&gt; &lt;target port&gt;\n", argv[0]); exit(-1); &#125; // Create a raw socket with UDP protocol sd = socket(AF_INET, SOCK_RAW, IPPROTO_UDP); if (sd &lt; 0) &#123; perror("socket() error"); // If something wrong just exit exit(-1); &#125; else printf("socket() - Using SOCK_RAW socket and UDP protocol is OK.\n"); //IPPROTO_TP说明用户自己填写IP报文 //IP_HDRINCL表示由内核来计算IP报文的头部校验和，和填充那个IP的id if (setsockopt(sd, IPPROTO_IP, IP_HDRINCL, val, sizeof(int))) &#123; perror("setsockopt() error"); exit(-1); &#125; else printf("setsockopt() is OK.\n"); // The source is redundant, may be used later if needed // The address family sin.sin_family = AF_INET; din.sin_family = AF_INET; // Port numbers sin.sin_port = htons(atoi(argv[2])); din.sin_port = htons(atoi(argv[4])); // IP addresses sin.sin_addr.s_addr = inet_addr(argv[1]); din.sin_addr.s_addr = inet_addr(argv[3]); // Fabricate the IP header or we can use the // standard header structures but assign our own values. ip-&gt;ihl = 5; ip-&gt;version = 4;//报头长度，4*32=128bit=16B ip-&gt;tos = 0; // 服务类型 ip-&gt;tot_len = ((sizeof(struct iphdr) + sizeof(struct udphdr)+sizeof(DNS))); //ip-&gt;id = htons(54321);//可以不写 ip-&gt;ttl = 64; // hops生存周期 ip-&gt;protocol = 17; // UDP ip-&gt;check = 0; // Source IP address, can use spoofed address here!!! ip-&gt;saddr = inet_addr(argv[1]); // The destination IP address ip-&gt;daddr = inet_addr(argv[3]); // Fabricate the UDP header. Source port number, redundant udp-&gt;source = htons(atoi(argv[2]));//源端口 // Destination port number udp-&gt;dest = htons(atoi(argv[4]));//目的端口 udp-&gt;len = htons(sizeof(struct udphdr)+sizeof(DNS));//长度 //forUDPCheckSum用来计算UDP报文的校验和用 //UDP校验和需要计算 伪头部、UDP头部和数据部分 char * forUDPCheckSum = new char[sizeof(UDP_PSD_Header) + sizeof(udphdr)+sizeof(DNS)+1]; memset(forUDPCheckSum, 0, sizeof(UDP_PSD_Header) + sizeof(udphdr) + sizeof(DNS) + 1); UDP_PSD_Header * udp_psd_Header = (UDP_PSD_Header *)forUDPCheckSum; udp_psd_Header-&gt;src = inet_addr(argv[1]); udp_psd_Header-&gt;des = inet_addr(argv[3]); udp_psd_Header-&gt;mbz = 0; udp_psd_Header-&gt;ptcl = 17; udp_psd_Header-&gt;len = htons(sizeof(udphdr)+sizeof(DNS)); memcpy(forUDPCheckSum + sizeof(UDP_PSD_Header), udp, sizeof(udphdr)); memcpy(forUDPCheckSum + sizeof(UDP_PSD_Header) + sizeof(udphdr), DNS, sizeof(DNS)); //ip-&gt;check = csum((unsigned short *)ip, sizeof(iphdr)/2);//可以不用算 //计算UDP的校验和，因为报文长度可能为单数，所以计算的时候要补0 udp-&gt;check = csum((unsigned short *)forUDPCheckSum,(sizeof(udphdr)+sizeof(UDP_PSD_Header)+sizeof(DNS)+1)/2); setuid(getpid());//如果不是root用户，需要获取权限 // Send loop, send for every 2 second for 2000000 count printf("Trying...\n"); printf("Using raw socket and UDP protocol\n"); printf("Using Source IP: %s port: %u, Target IP: %s port: %u.\n", argv[1], atoi(argv[2]), argv[3], atoi(argv[4])); std::cout &lt;&lt; "Ip length:" &lt;&lt; ip-&gt;tot_len &lt;&lt; std::endl; int count; //将DNS报文拷贝进缓存区 memcpy(buffer + sizeof(iphdr) + sizeof(udphdr), DNS, sizeof(DNS)); for (count = 1; count &lt;= 2000000; count++) &#123; if (sendto(sd, buffer, ip-&gt;tot_len, 0, (struct sockaddr *)&amp;din, sizeof(din)) &lt; 0) // Verify &#123; perror("sendto() error"); exit(-1); &#125; else &#123; printf("Count #%u - sendto() is OK.\n", count); sleep(2); &#125; &#125; close(sd); return 0;&#125; 结果：在IP为192.168.1.50的机器上冒充那个IP为192.168.1.71的机器向阿里的DNS服务器114.114.114.114上发送DNS查询报文 在IP为192.168.1.71的机器上收到阿里DNS服务器传回来的DNS报文 为啥是 unreachable - admin prohibited, length 413，经过查询是因为防火墙的原因。 关闭centos防火墙，service iptables stop关闭ubuntu防火墙，ufw stop。一般用户，只需如下设置：sudo apt-get install ufwsudo ufw enablesudo ufw default deny以上三条命令已经足够安全了，如果你需要开放某些服务，再使用sudo ufw allow开启。 关闭防火墙之后，再次查看，如下结果： 参考：https://blog.csdn.net/firefoxbug/article/details/7561159https://blog.51cto.com/a1liujin/1697465https://blog.csdn.net/yong61/article/details/8549654https://blog.csdn.net/dog250/article/details/83830872https://www.cnblogs.com/sammyliu/p/4981194.htmlhttps://blog.csdn.net/luchengtao11/article/details/73878760]]></content>
      <categories>
        <category>TCP/IP</category>
      </categories>
      <tags>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用travis-ci自动部署github上的项目]]></title>
    <url>%2F2019%2F02%2F03%2F%E4%BD%BF%E7%94%A8travis-ci%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2github%E4%B8%8A%E7%9A%84%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[travis-ci账户用github账户登录，找到对应项目进行勾选，如下图。 生成token，如下图。 配置token，如下图。（配置私密的环境变量时一定要加密，因为会显示在日志中且能够被他人看到） 还需要添加一些环境变量使起更方便(地址别填错了)，如下图。 ###有个问题：hexo g 之后并没有在travis中看到相关信息，难道非要用git推送吗？还有.travis.yml应该放在哪，我现在放在了blogs目录下。 答案：项目应该有两个分支，一个源码分支，一个发布之后的分支，.travis.yml应该放在源码分支的根目录下。 参考https://www.cnblogs.com/morang/p/7228488.htmlhttps://blog.csdn.net/woblog/article/details/51319364http://lujiahao.tk/2018/06/27/Travis%20CI%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/ 为博客添加一个新分支hexo-source，并设置为默认分支，这样就是用两个分支进行管理了。执行git add .、git commit -m “”、git push origin hexo来提交hexo网站源文件依次执行hexo g和hexo d生成静态网页部署至Github上 hexo备份参考: https://www.jianshu.com/p/57b5a384f234 https://www.jianshu.com/p/a27e9761ecf3]]></content>
      <categories>
        <category>TravisCI</category>
      </categories>
      <tags>
        <tag>TravisCI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker化秒杀疑云]]></title>
    <url>%2F2019%2F01%2F25%2FDocker%E5%8C%96%E7%A7%92%E6%9D%80%E7%96%91%E4%BA%91%2F</url>
    <content type="text"><![CDATA[为什么用docker-compose就有一堆错误，而一个一个起容器就不会有错误呢？所有的操作都一样啊。。莫非跟网关有关系吗？？一个用br-xxxxx，一个用docker0。docker-compose用的网关是br-10e925ab0d49这种形式的。而且每次br还不一样。没有docker0作为网关 下面是报的一些错误： 1234567Caused by: com.rabbitmq.client.AuthenticationFailureException: ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile. at com.rabbitmq.client.impl.AMQConnection.start(AMQConnection.java:342) ~[amqp-client-4.0.3.jar!/:4.0.3] at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:909) ~[amqp-client-4.0.3.jar!/:4.0.3] at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:859) ~[amqp-client-4.0.3.jar!/:4.0.3] at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:799) ~[amqp-client-4.0.3.jar!/:4.0.3] at org.springframework.amqp.rabbit.connection.AbstractConnectionFactory.createBareConnection(AbstractConnectionFactory.java:352) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] 原因：默认安装好rabbitmq就有服务（windows服务），但没有web监控（localhost:15672）;默认的端口就是5672，用户guest密码guest，但这个用户名只能在本机访问，如果要网络访问，需要做用户管理；参考：https://blog.csdn.net/lwkcn/article/details/25086467得知，就是写错用户名和密码了。 将rabbitmq的172.21.6.57改为localhost之后 报错信息变成了 12345678910111213141516171819202122232425262019-01-21 02:32:22.362 ERROR 1 --- [cTaskExecutor-2] o.s.a.r.l.SimpleMessageListenerContainer : Failed to check/redeclare auto-delete queue(s).org.springframework.amqp.AmqpConnectException: java.net.ConnectException: Connection refused (Connection refused) at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:62) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.connection.AbstractConnectionFactory.createBareConnection(AbstractConnectionFactory.java:368) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.connection.CachingConnectionFactory.createConnection(CachingConnectionFactory.java:573) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.core.RabbitTemplate.doExecute(RabbitTemplate.java:1430) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1411) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.core.RabbitTemplate.execute(RabbitTemplate.java:1387) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.core.RabbitAdmin.getQueueProperties(RabbitAdmin.java:336) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.redeclareElementsIfNecessary(SimpleMessageListenerContainer.java:1171) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$AsyncMessageProcessingConsumer.run(SimpleMessageListenerContainer.java:1422) [spring-rabbit-1.7.4.RELEASE.jar!/:na] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_111]Caused by: java.net.ConnectException: Connection refused (Connection refused) at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_111] at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_111] at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_111] at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_111] at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_111] at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_111] at com.rabbitmq.client.impl.SocketFrameHandlerFactory.create(SocketFrameHandlerFactory.java:50) ~[amqp-client-4.0.3.jar!/:4.0.3] at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:907) ~[amqp-client-4.0.3.jar!/:4.0.3] at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:859) ~[amqp-client-4.0.3.jar!/:4.0.3] at com.rabbitmq.client.ConnectionFactory.newConnection(ConnectionFactory.java:799) ~[amqp-client-4.0.3.jar!/:4.0.3] at org.springframework.amqp.rabbit.connection.AbstractConnectionFactory.createBareConnection(AbstractConnectionFactory.java:352) ~[spring-rabbit-1.7.4.RELEASE.jar!/:na] ... 8 common frames omitted 应用间网络还不完善，应该使用网络隔离，app在front，其余都在back。docker network create front命令是创建网络的。 默认的rabbitmq:3镜像没有management，应该用rabbitmq:management，我还怕是不是因为版本不一致导致的问题，专门用的rabbitmq:3.7.5-management，还是不行，还是报错。 123456789101112131415com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failureThe last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server. at sun.reflect.GeneratedConstructorAccessor31.newInstance(Unknown Source) ~[na:na] at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_111] at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[na:1.8.0_111] at com.mysql.jdbc.Util.handleNewInstance(Util.java:425) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:989) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at com.mysql.jdbc.MysqlIO.&lt;init&gt;(MysqlIO.java:341) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at com.mysql.jdbc.ConnectionImpl.coreConnect(ConnectionImpl.java:2189) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2222) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2017) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at com.mysql.jdbc.ConnectionImpl.&lt;init&gt;(ConnectionImpl.java:779) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at com.mysql.jdbc.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:47) ~[mysql-connector-java-5.1.44.jar!/:5.1.44] at sun.reflect.GeneratedConstructorAccessor28.newInstance(Unknown Source) ~[na:na] 莫非是因为 在容器里边，他不认 localhost吗？？？必须写真实的IP才能找到。。。。 为什么没写到mysql中去呢 ，秒杀成功后吗，应该库存减少啊 但是并没有减少。。。。可能是因为发送了 秒杀请求，但是没有进行消息确认，所以 库存的数据量并不会减少。。。下一次又会读取到7 这个数量。。。。 现在的业务逻辑有个错误啊 ，我第一次秒杀成功后，在点击秒杀，确实说 非法请求了但是redis里还是减少了一个 商品 ，但是mysql里没有减少，说明没有发送成功秒杀的消息给mysql 所以并没有减少。 update s_goods set start_date=&#39;2019-01-22 13:55:50&#39; where id=1; 注意有八个小时的时差 数据库里是05点，页面上显示13点。 12345com.sjt.miaosha.rabbitmq.MQSender : send message:&#123;"goodsId":1,"user":&#123;"id":15812341234,"lastLoginDate":1525086640000,"loginCount":1,"nickname":"jack","password":"b631975e482e55b7692106f55a5b0a82","registerDate":1525086636000,"salt":"1a2b3c"&#125;&#125;2019-01-22 05:52:35.118 INFO 1 --- [io-65510-exec-8] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#1ca81352:40/SimpleConnection@3f516387 [delegate=amqp://admin@172.21.6.57:5672/, localPort= 57984]2019-01-22 05:53:02.388 INFO 1 --- [io-65510-exec-3] c.s.miaosha.controller.LoginController : LoginVo [mobile=15812341234, password=ae6712ae454da07f5a86e2b5b21f4ea2]2019-01-22 05:53:10.551 INFO 1 --- [io-65510-exec-1] com.sjt.miaosha.rabbitmq.MQSender : send message:&#123;"goodsId":1,"user":&#123;"id":15812341234,"lastLoginDate":1525086640000,"loginCount":1,"nickname":"jack","password":"b631975e482e55b7692106f55a5b0a82","registerDate":1525086636000,"salt":"1a2b3c"&#125;&#125;]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀项目优化]]></title>
    <url>%2F2019%2F01%2F25%2F%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[逻辑 如何解决超卖问题（1）在sql加上判断防止数据边为负数（2）数据库加唯一索引防止用户重复购买（3）redis预减库存减少数据库访问 内存标记减少redis访问 请求先入队列缓冲，异步下单，增强用户体验 为什么threadlocal存储user对象，原理？ 并发编程中重要的问题就是数据共享，当你在一个线程中改变任意属性时，所有的线程都会因此受到影响，同时会看到第一个线程修改后的值。有时我们希望如此，比如：多个线程增大或减小同一个计数器变量。但是，有时我们希望确保每个线程，只能工作在它自己的线程实例的拷贝上，同时不会影响其他线程的数据。 举例： 举个例子，想象你在开发一个电子商务应用，你需要为每一个控制器处理的顾客请求，生成一个唯一的事务ID，同时将其传到管理器或DAO的业务方法中，以便记录日志。一种方案是将事务ID作为一个参数，传到所有的业务方法中。但这并不是一个好的方案，它会使代码变得冗余。你可以使用ThreadLocal类型的变量解决这个问题。首先在控制器或者任意一个预处理器拦截器中生成一个事务ID然后在ThreadLocal中 设置事务ID，最后，不论这个控制器调用什么方法，都能从threadlocal中获取事务ID而且这个应用的控制器可以同时处理多个请求，同时在框架 层面，因为每一个请求都是在一个单独的线程中处理的，所以事务ID对于每一个线程都是唯一的，而且可以从所有线程的执行路径获取运行结果可以看出每个线程都在维护自己的变量：123456789101112131415161718192021222324252627 Starting Thread: 0 : Fri Sep 21 23:05:34 CST 2018&lt;br&gt; Starting Thread: 2 : Fri Sep 21 23:05:34 CST 2018&lt;br&gt; Starting Thread: 1 : Fri Jan 02 05:36:17 CST 1970&lt;br&gt; Thread Finished: 1 : Fri Jan 02 05:36:17 CST 1970&lt;br&gt; Thread Finished: 0 : Fri Sep 21 23:05:34 CST 2018&lt;br&gt; Thread Finished: 2 : Fri Sep 21 23:05:34 CST 2018&lt;br&gt;``` 局部线程通常使用在这样的情况下，当你有一些对象并不满足线程安全，但是你想避免在使用synchronized关键字。 块时产生的同步访问，那么，让每个线程拥有它自己的对象实例 注意：局部变量是同步或局部线程的一个好的替代，它总是能够保证线程安全。唯一可能限制你这样做的是你的应用设计约束&lt;br&gt; 所以设计threadlocal存储user不会对对象产生影响，每次进来一个请求都会产生自身的线程变量来存储### Redis* Key的优化。```java 关键伪代码生成rediskey, objects包括ucid、用户输入入参、分页信息等等public static String builder(String prefix, Object... objects) &#123; String input = JSONObject.toJSONString(Arrays.asList(objects)); String output = Util.md5_16(input); return prefix+output;&#125;cacheRedis.setex(key,EXPIRE_TIME_2S,info); 设计优点：借鉴spring-data-redis将入参通用为objects…序列化，然后将JsonString Md5压缩为16位，这里主要由于在秒杀开始时，redis数据会出现大量缓存列表数据，redis储存100w个value长度为32位,key长度为16位的数据时，需要使用个130MB内存，如果key的长度为32位时需要160MB左右的内存，所以压缩key的长度在这种场景很有必要。 不要什么都放在redis中像列表页缓存，切勿为了减少redis的开销，将数据库每一列放到redis中，在redis中查询汇总，例如：每个秒杀资源都放在redis中，秒杀资源页需要10次redis链接才能完成一次列表页的组装。这样做会将服务器的qps成几何倍数的扩大到与redis的qps中造成系统获取不到redis连接资源 redis的库存如何与数据库的库存保持一致redis的数量不是库存,他的作用仅仅只是为了阻挡多余的请求透穿到DB，起到一个保护的作用因为秒杀的商品有限，比如10个，让1万个请求区访问DB是没有意义的，因为最多也就只能10个请求下单成功，所有这个是一个伪命题，我们是不需要保持一致的。 为什么redis数量会减少为负数 12345678 //预见库存 long stock = redisService.decr(GoodsKey.getMiaoshaGoodsStock,""+goodsId) ;if(stock &lt;0)&#123; localOverMap.put(goodsId, true);return Result.error(CodeMsg.MIAO_SHA_OVER);&#125;假如redis的数量为1,这个时候同时过来100个请求，大家一起执行decr数量就会减少成-99这个是正常的进行优化后改变了sql写法和内存写法则不会出现上述问题 redis 分布式锁实现方法 redis分布式锁解决什么问题1.一个进程中的多个线程,多个线程并发访问同一个资源的时候,如何解决线程安全问题。2.一个分布式架构系统中的两个模块同时去访问一个文件对文件进行读写操作3.多个应用对同一条数据做修改的时候,如何保证数据的安全性在但一个进程中,我们可以用到synchronized、lock之类的同步操作去解决,但是对于分布式架构下多进程的情况下,如何做到跨进程的锁。就需要借助一些第三方手段来完成 我用了四种方法 ，分别指出了不同版本的缺陷以及演进的过程 orderclosetaskV1—-&gt;&gt;版本没有操作，在分布式系统中会造成同一时间，资源浪费而且很容易出现并发问题V2—&gt;&gt;版本加了分布式redis锁，在访问核心方法前，加入redis锁可以阻塞其他线程访问,可以很好的处理并发问题,但是缺陷就是如果机器突然宕机，或者线路波动等，就会造成死锁，一直不释放等问题V3版本–&gt;&gt;很好的解决了这个问题v2的问题，就是加入时间对比如果当前时间已经大与释放锁的时间说明已经可以释放这个锁重新在获取锁，setget方法可以把之前的锁去掉在重新获取,旧值在于之前的值比较，如果无变化说明这个期间没有人获取或者操作这个redis锁，则可以重新获取V4—-&gt;&gt;采用成熟的框架redisson,封装好的方法则可以直接处理，但是waittime记住要这只为0 Mysql 需注意 因为秒杀，大促，打折等活动进行频繁，所以需要单独建立秒杀_….表来管理否则会经常进行回归 RabbitMQ 订单处理队列rabbitmq请求先入队缓冲，异步下单，增强用户体验请求出队，生成订单，减少库存客户端定时轮询检查是否秒杀成功 rabbitmq如何做到消息不重复不丢失即使服务器重启-1.exchange持久化-2.queue持久化-3.发送消息设置MessageDeliveryMode.persisent这个也是默认的行为-4.手动确认 事务 RPC事务补偿当集中式进行服务化RPC演进成分布式的时候，事务则成为了进行分布式的一个痛点，本项目的做法为：1.进行流程初始化，当分别调用不用服务化接口的时候，成功则进行流程，失败则返回并进行状态更新将订单状态变为回滚2.使用定时任务不断的进行处理rollback的订单进行回滚 Mavenmaven隔离就是在开发中，把各个环境的隔离开来，一般分为 本地（local） 开发(dev) 测试(test) 线上(prod) 在环境部署中为了防止人工修改的弊端！ spring.profiles.active=@activatedProperties@ 架构1234567891011121314151617181920212223242526项目进行dubbo+ZK改造 ├── miaosha-admin 登录模块 │ ├── pom.xml │ └── miaosha-admin-api │ └── miaosha-admin-service │ └── miaosha-admin-web │ └── miaosha-common │ │ ├── miaosha-order 订单秒杀模块 │ ├── pom.xml │ └── miaosha-order-api │ └── miaosha-order-service │ └── miaosha-order-web │ └── miaosha-order-common │ │ ├── miaosha-message 消息模块 │ ├── pom.xml │ └── miaosha-message-api │ └── miaosha-message-service │ └── miaosha-message-web │ └── miaosha-message-common │]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zero-Copy]]></title>
    <url>%2F2019%2F01%2F25%2FZero-Copy%2F</url>
    <content type="text"><![CDATA[这是一篇关于“零拷贝”的英文文献，写的非常好。有时间翻译一下。https://developer.ibm.com/articles/j-zerocopy/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker化秒杀项目九九八十一难]]></title>
    <url>%2F2019%2F01%2F20%2FDocker%E5%8C%96%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE%E4%B9%9D%E4%B9%9D%E5%85%AB%E5%8D%81%E4%B8%80%E9%9A%BE%2F</url>
    <content type="text"><![CDATA[Docker化Mysql在我的Docker秒杀项目中，第一开始我都是把执行脚本和创建数据库文件都先弄到一个镜像中去，然后基于这个新镜像在起docker容器，但是后来一想，这种方法很麻烦，有没有一种更好的方法呢？通过一篇文章，有了灵感。 Volume持久化首先，我们可以在创建数据库容器的时候指定容器内数据库创建docker run --name mysqldock -e MYSQL_ROOT_PASSWORD=admin -e MYSQL_DATABASE=inst1 -d -p 3066:3066 mysql通过-e MYSQL_DATABASE这个配置就可以在创建容器时创建inst1这个数据库。 官方文档对docker commit的说明是：The commit operation will not include any data contained in volumes mounted inside the container. 意思是commit操作并不会包含容器内挂载数据卷中的数据变化。难道是因为mysql容器的挂载数据卷引起的？也就是说数据库容器/var/lib/mysql路径作为volume挂载在host主机上/var/lib/docker/volumes/该容器ID。 但是通过-e参数创建的数据库就还在，继续看docker commit官方文档It can be useful to commit a container’s file changes or settings into a new image.对于文件变更(在容器内新创建一个文件)和设置（-e MYSQL_DATABASE=inst1）有用。 到此，原来我的疑问也就明朗了。 那么我们如何来对数据库容器进行持久化呢？我们可以通过docker提供的数据挂载来实现。docker的数据挂载分为三种，volume, bind mount和tmpfs，关于三种的具体说明，强烈推荐大家看一下官网的文档。这边简单说明一下： volume是由docker默认及推荐的挂载方式，volume由docker直接管理，同一个volume可以共享给多个容器使用，volume和容器的生命周期完全独立，容器删除时volume仍然存在，除非使用docker volume相应命令删除volume；缺点是volume在宿主机上比较难定位，在宿主机上直接操作volume比较困难。 bind mount是直接将宿主机文件系统上的文件路径映射到容器中，两边双向同步，显而易见，有缺点也有优点，优点是可以直接访问，也可以被别的程序使用，比如我们打包一个本地应用到本地/target路径，我们就可以把这个路径使用bind mount的方式挂在到依赖他的应用的docker容器中，这样本地应用打包后，docker里的数据卷也会同时更新；缺点也是显而易见的，因为你可以把任何文件路径使用bind mount的方式绑定到容器中，这样有可能一些安全问题，比如把宿主机的系统文件绑定到容器中。 tmpfs这种方式是使用宿主机的内存作为存储，不会写到宿主机的文件系统中，和前两种区别较大。 什么是Volume呢？为了能够保存（持久化）数据以及共享容器间的数据，Docker提出了Volume的概念。简单来说，Volume就是目录或者文件，它可以绕过默认的联合文件系统，而以正常的文件或者目录的形式存在于宿主机上。 注意：-v 的时候不能使用同一个源地址，否则创建起来的容器会闪退（再创建一个data目录来区分） 下面是各种磨难 为什么我自己新创建的数据库镜像mysql默认是关闭的？必须的通过/etc/init.d/mysql start 才能启动呢？？？ 在脚本中还不行，必须得手动进入容器内进行执行该命令，百思不得姐啊 。。。。。通过docker logs发现MySQL Community Server 5.7.24 is started.mysql: [Warning] Using a password on the command line interface can be insecure./mysql/createDatabase.sh: 21: /mysql/createDatabase.sh: cannot open miaosha.sql: No such file发现数据库已经起来了，但是说不能打开sql文件，难道是因为权限问题，？？？？必须在容器内才能拥有权限？？？（经证实。不是权限问题，是sql文件路径问题） 这次我手动在容器内执行 脚本 就能成功，（第一次说找不到sql文件，第二次就成功了，到底是什么鬼？？？？？？）[info] A MySQL Server is already started.mysql: [Warning] Using a password on the command line interface can be insecure.mysql: [Warning] Using a password on the command line interface can be insecure. 最后，终于成功了，是因为路径的原因。原来为mysql -u${USERNAME} -p${PASSWORD} miaosha &lt; miaosha.sql改为 mysql -u${USERNAME} -p${PASSWORD} miaosha &lt; /mysql/miaosha.sql docker容器启动后马上退出经查阅资料：Docker容器同时只能管理一个进程，如果这个进程退出那么容器也就退出了，但这不表示容器只能运行一个进程(其他进程可在后台运行)，但是要使容器不退出必须有一个前台执行的进程。我这里通过，tail -f /dev/null这个命令 不让它退出。 挂载某一文件的问题 挂载之前需要改变文件权限为777，要不会引起修改宿主机上的文件 会引起内容不同步的问题参考https://blog.csdn.net/qq_21816375/article/details/78032521 成功，数据库启动正常docker run -d -p 3306:3306 --name miaoshaMysql -e MYSQL_ROOT_PASSWORD=123 -v / home/ubuntu16/miaosha-docker-compose/config/miaoshaMysql:/mysql -v /home/ubuntu16/miaosha-docker-compose/data/miaoshaMysql:/var/lib/mysql sjt157/miaoshamysql:v4 Docker化Rabbitmq遇到这个错误[error] Error when reading /var/lib/rabbitmq/.erlang.cookie: eacces 用这个命令解决chown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookie 最终成功启动命令docker run -d --name miaosharabbit -p 5672:5672 -p 15672:15672 -v /home/ubuntu16/miaosha-dock er-compose/config/miaoshaRabbit:/rabbitmq sjt157/miaosharabbitmq:v4 Docker化redis持久化参考mysql的持久化，我们也需要对redis进行持久化，这样我们的容器退出后才不会所有东西全部丢失。参考https://blog.csdn.net/haoxiaoyong1014/article/details/80241677 最终命令docker run -d -p 6379:6379 --name miaosharedis sjt157/miaosharedis:v2 docker-compose我们每次都docker run很麻烦，所以用docker-compose。1234567891011121314151617181920212223242526272829303132333435363738394041version: '2.1'services: mysql: image: sjt157/miaoshamysql:v4 ports: - "3306:3306" environment: - MYSQL_ROOT_PASSWORD=123 # - MYSQL_DATABASE=root volumes: - /home/ubuntu16/miaosha-docker-compose/config/miaoshaMysql:/mysql - /home/ubuntu16/miaosha-docker-compose/data/miaoshaMysql:/var/lib/mysql - /home/ubuntu16/miaosha-docker-compose/logs/miaoshaMysql:/logs restart: on-failure redis: image: sjt157/miaosharedis:v2 ports: - "6379:6379" volumes: - /home/ubuntu16/miaosha-docker-compose/data/miaoshaRedis:/data - /home/ubuntu16/miaosha-docker-compose/logs/miaoshaRedis:/logs restart: on-failure rabbitmq: image: sjt157/miaosharabbitmq:v4 ports: - "5672:5672" - "15672:15672" volumes: - /home/ubuntu16/miaosha-docker-compose/config/miaoshaRabbit:/rabbitmq - /home/ubuntu16/miaosha-docker-compose/logs/miaoshaRabbit:/logs restart: on-failure miaosha: image: sjt157/miaoshaapp:v2 ports: - "65534:65510" depends_on: - mysql - redis - rabbitmq restart: on-failure 通过docker-compose up -d启动成功123456CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7152d7c2f012 sjt157/miaoshaapp:v2 &quot;java -jar -Dloader.…&quot; 4 minutes ago Up 4 minutes 0.0.0.0:65534-&gt;65510/tcp miaosha-docker-compose_miaosha_1_6a294f3118b7f9fada42b2b9 sjt157/miaosharabbitmq:v4 &quot;docker-entrypoint.s…&quot; 4 minutes ago Up 4 minutes 4369/tcp, 0.0.0.0:5672-&gt;5672/tcp, 5671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp miaosha-docker-compose_rabbitmq_1_b1a645775dbfda0590907e62 sjt157/miaosharedis:v2 &quot;docker-entrypoint.s…&quot; 4 minutes ago Up 4 minutes 0.0.0.0:6379-&gt;6379/tcp miaosha-docker-compose_redis_1_6d55cb3068980974f7a50423 sjt157/miaoshamysql:v4 &quot;docker-entrypoint.s…&quot; 4 minutes ago Up 4 minutes 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp miaosha-docker-compose_mysql_1_321cab31d805 通过docker-compose down 停止。 参考https://www.jianshu.com/p/530d00f97cbfhttps://blog.csdn.net/haoxiaoyong1014/article/details/80241677]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty之高水位、低水位]]></title>
    <url>%2F2019%2F01%2F19%2FNetty%E4%B9%8B%E9%AB%98%E6%B0%B4%E4%BD%8D%E3%80%81%E4%BD%8E%E6%B0%B4%E4%BD%8D%2F</url>
    <content type="text"><![CDATA[我们一听高低水位，肯定首先想到的肯定就是“大爸”（三峡大坝），我们都知道，三峡的水位曾经到达过172.85米，最高限制水位175米，其实这就是三峡的高水位，如果再进水，那么恐怕啥都不好用了。同理，Netty中有缓冲区，就相当于大坝起存储缓冲作用。当缓冲区达到一定大小时则不能写入，避免被撑爆。Netty中提供 了writeBufferLowWaterMark和writeBufferHighWaterMark选项用来控制高低水位。可以通过监控当前写缓冲区的水位状况，来避免占用大量的内存，因为ChannelOutboundBuffer本身是无界的，所以用的时候要注意。（感觉跟Netty提供的Traffic Shaping流量整形功能有点像）。我们来看一下源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * WriteBufferWaterMark is used to set low water mark and high water mark for the write buffer. * &lt;p&gt; * If the number of bytes queued in the write buffer exceeds the * &#123;@linkplain #high high water mark&#125;, &#123;@link Channel#isWritable()&#125; * will start to return &#123;@code false&#125;. * &lt;p&gt; * If the number of bytes queued in the write buffer exceeds the * &#123;@linkplain #high high water mark&#125; and then * dropped down below the &#123;@linkplain #low low water mark&#125;, * &#123;@link Channel#isWritable()&#125; will start to return * &#123;@code true&#125; again. */public final class WriteBufferWaterMark &#123; private static final int DEFAULT_LOW_WATER_MARK = 32 * 1024; private static final int DEFAULT_HIGH_WATER_MARK = 64 * 1024; public static final WriteBufferWaterMark DEFAULT = new WriteBufferWaterMark(DEFAULT_LOW_WATER_MARK, DEFAULT_HIGH_WATER_MARK, false); private final int low; private final int high; /** * Create a new instance. * * @param low low water mark for write buffer. * @param high high water mark for write buffer */ public WriteBufferWaterMark(int low, int high) &#123; this(low, high, true); &#125; /** * This constructor is needed to keep backward-compatibility. */ WriteBufferWaterMark(int low, int high, boolean validate) &#123; if (validate) &#123; if (low &lt; 0) &#123; throw new IllegalArgumentException(&quot;write buffer&apos;s low water mark must be &gt;= 0&quot;); &#125; if (high &lt; low) &#123; throw new IllegalArgumentException( &quot;write buffer&apos;s high water mark cannot be less than &quot; + &quot; low water mark (&quot; + low + &quot;): &quot; + high); &#125; &#125; this.low = low; this.high = high; &#125; /** * Returns the low water mark for the write buffer. */ public int low() &#123; return low; &#125; /** * Returns the high water mark for the write buffer. */ public int high() &#123; return high; &#125; @Override public String toString() &#123; StringBuilder builder = new StringBuilder(55) .append(&quot;WriteBufferWaterMark(low: &quot;) .append(low) .append(&quot;, high: &quot;) .append(high) .append(&quot;)&quot;); return builder.toString(); &#125;&#125; 从注释里头可以看到控制的是写缓冲，高低水位这两个参数控制的是Channel.isWritable()方法，当超过高水位时返回False，降到低水位之下后，又重新可写。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980private static final AtomicIntegerFieldUpdater&lt;ChannelOutboundBuffer&gt; UNWRITABLE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(ChannelOutboundBuffer.class, &quot;unwritable&quot;); private volatile int unwritable; /** * Returns &#123;@code true&#125; if and only if &#123;@linkplain #totalPendingWriteBytes() the total number of pending bytes&#125; did * not exceed the write watermark of the &#123;@link Channel&#125; and * no &#123;@linkplain #setUserDefinedWritability(int, boolean) user-defined writability flag&#125; has been set to * &#123;@code false&#125;. */ public boolean isWritable() &#123; return unwritable == 0; &#125; /** * Get how many bytes must be drained from the underlying buffer until &#123;@link #isWritable()&#125; returns &#123;@code true&#125;. * This quantity will always be non-negative. If &#123;@link #isWritable()&#125; is &#123;@code true&#125; then 0. */ public long bytesBeforeWritable() &#123; long bytes = totalPendingSize - channel.config().getWriteBufferLowWaterMark(); // If bytes is negative we know we are writable, but if bytes is non-negative we have to check writability. // Note that totalPendingSize and isWritable() use different volatile variables that are not synchronized // together. totalPendingSize will be updated before isWritable(). if (bytes &gt; 0) &#123; return isWritable() ? 0 : bytes; &#125; return 0; &#125; /** * Decrement the pending bytes which will be written at some point. * This method is thread-safe! */ void decrementPendingOutboundBytes(long size) &#123; decrementPendingOutboundBytes(size, true, true); &#125; private void decrementPendingOutboundBytes(long size, boolean invokeLater, boolean notifyWritability) &#123; if (size == 0) &#123; return; &#125; long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, -size); if (notifyWritability &amp;&amp; newWriteBufferSize &lt; channel.config().getWriteBufferLowWaterMark()) &#123; setWritable(invokeLater); &#125; &#125; private void setWritable(boolean invokeLater) &#123; for (;;) &#123; final int oldValue = unwritable; final int newValue = oldValue &amp; ~1; if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) &#123; if (oldValue != 0 &amp;&amp; newValue == 0) &#123; fireChannelWritabilityChanged(invokeLater); &#125; break; &#125; &#125; &#125; private void fireChannelWritabilityChanged(boolean invokeLater) &#123; final ChannelPipeline pipeline = channel.pipeline(); if (invokeLater) &#123; Runnable task = fireChannelWritabilityChangedTask; if (task == null) &#123; fireChannelWritabilityChangedTask = task = new Runnable() &#123; @Override public void run() &#123; pipeline.fireChannelWritabilityChanged(); &#125; &#125;; &#125; channel.eventLoop().execute(task); &#125; else &#123; pipeline.fireChannelWritabilityChanged(); &#125; &#125; bytesBeforeWritable方法先判断totalPendingSize是否大于lowWatermark，如果不大于则返回0，如果大于且isWritable返回true则返回0，否则返回差值decrementPendingOutboundBytes方法会判断，如果notifyWritability为true且newWriteBufferSize &lt; channel.config().getWriteBufferLowWaterMark()，则调用setWritablesetWritable(invokeLater)setWritable会更新unwritable，如果是从非0变为0，还会触发fireChannelWritabilityChanged进行通知123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081ChannelOutboundBuffer.setUnwritablenetty-all-4.1.25.Final-sources.jar!/io/netty/channel/ChannelOutboundBuffer.java private static final AtomicIntegerFieldUpdater&lt;ChannelOutboundBuffer&gt; UNWRITABLE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(ChannelOutboundBuffer.class, &quot;unwritable&quot;); private volatile int unwritable; /** * Returns &#123;@code true&#125; if and only if &#123;@linkplain #totalPendingWriteBytes() the total number of pending bytes&#125; did * not exceed the write watermark of the &#123;@link Channel&#125; and * no &#123;@linkplain #setUserDefinedWritability(int, boolean) user-defined writability flag&#125; has been set to * &#123;@code false&#125;. */ public boolean isWritable() &#123; return unwritable == 0; &#125; /** * Get how many bytes can be written until &#123;@link #isWritable()&#125; returns &#123;@code false&#125;. * This quantity will always be non-negative. If &#123;@link #isWritable()&#125; is &#123;@code false&#125; then 0. */ public long bytesBeforeUnwritable() &#123; long bytes = channel.config().getWriteBufferHighWaterMark() - totalPendingSize; // If bytes is negative we know we are not writable, but if bytes is non-negative we have to check writability. // Note that totalPendingSize and isWritable() use different volatile variables that are not synchronized // together. totalPendingSize will be updated before isWritable(). if (bytes &gt; 0) &#123; return isWritable() ? bytes : 0; &#125; return 0; &#125; /** * Increment the pending bytes which will be written at some point. * This method is thread-safe! */ void incrementPendingOutboundBytes(long size) &#123; incrementPendingOutboundBytes(size, true); &#125; private void incrementPendingOutboundBytes(long size, boolean invokeLater) &#123; if (size == 0) &#123; return; &#125; long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size); if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) &#123; setUnwritable(invokeLater); &#125; &#125; private void setUnwritable(boolean invokeLater) &#123; for (;;) &#123; final int oldValue = unwritable; final int newValue = oldValue | 1; if (UNWRITABLE_UPDATER.compareAndSet(this, oldValue, newValue)) &#123; if (oldValue == 0 &amp;&amp; newValue != 0) &#123; fireChannelWritabilityChanged(invokeLater); &#125; break; &#125; &#125; &#125; private void fireChannelWritabilityChanged(boolean invokeLater) &#123; final ChannelPipeline pipeline = channel.pipeline(); if (invokeLater) &#123; Runnable task = fireChannelWritabilityChangedTask; if (task == null) &#123; fireChannelWritabilityChangedTask = task = new Runnable() &#123; @Override public void run() &#123; pipeline.fireChannelWritabilityChanged(); &#125; &#125;; &#125; channel.eventLoop().execute(task); &#125; else &#123; pipeline.fireChannelWritabilityChanged(); &#125; &#125; bytesBeforeUnwritable方法先判断highWatermark与totalPendingSize的差值，totalPendingSize大于等于highWatermark，则返回0；如果小于highWatermark，且isWritable为true，则返回差值，否则返回0incrementPendingOutboundBytes方法判断如果newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()，则调用setUnwritable(invokeLater)setUnwritable会更新unwritable，如果是从0变为非0，还会触发fireChannelWritabilityChanged进行通知 综上，lowWatermark及highWatermark分别在decrementPendingOutboundBytes及incrementPendingOutboundBytes方法里头用到(目前应该是这两个方法起作用)，当小于lowWatermark或者大于highWatermark的时候，分别触发setWritable及setUnwritable，更改ChannelOutboundBuffer的unwritable字段，进而影响isWritable方法；在isWritable为true的时候会立马执行写请求，当返回false的时候，写请求会被放入队列等待isWritable为true时才能执行这些堆积的写请求。 实践出真知在Netty的物联网网关中，就可以通过new WriteBufferWaterMark(32 1024 1024, 64 1024 1024)来设置水位线，防止服务器处理能力极其低下但连接正常时，造成channel中缓存大量数据影响网关性能。具体设置多大我们可以根据我们的应用需要支持多少连接数和系统资源进行合理规划。高水位线和低水位线是字节数，默认高水位是64K，低水位是32K。 参考https://www.jianshu.com/p/a1166c34ae46https://gitee.com/willbeahero/IOTGatehttps://www.jianshu.com/p/890525ff73cb]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL之binlog]]></title>
    <url>%2F2019%2F01%2F18%2FMYSQL%E4%B9%8Bbinlog%2F</url>
    <content type="text"><![CDATA[什么是binlogbinlog日志用于记录所有更新了数据或者已经潜在更新了数据（例如，没有匹配任何行的一个DELETE）的所有语句。语句以“事件”的形式保存，它描述数据更改。 binlog作用因为有了数据更新的binlog，所以可以用于实时备份，与master/slave主从复制结合。 binlog的形式二进制日志包括两类文件：二进制日志索引文件（文件名后缀为.index）用于记录所有的二进制文件；二进制日志文件（文件名后缀为.00000*）记录数据库所有的DDL和DML(除了数据查询语句)语句事件。 命令show variables like ‘%log_bin%’；show variables like ‘log_bin’;show variables like ‘%general_log%’;show variables like ‘%log_%’; 如何开启binlog在my.cnf中加入以下内容（加入的位置不对的话会报错，说不认识这些选项）：应该在[mysqld]选项下加入1234567server-id=1 #server-id表示单个结点的id，这里由于只有一个结点，所以可以把id随机指定为一个数，这里将id设置成1。若集群中有多个结点，则id不能相同binlog_format = MIXED #binlog日志格式，mysql默认采用statement，建议使用mixedlog-bin = /var/lib/mysql/mysql-bin #binlog日志文件expire_logs_days = 7 #binlog过期清理时间max_binlog_size = 100m #binlog每个日志文件大小binlog_cache_size = 4m #binlog缓存大小max_binlog_cache_size = 512m #最大binlog缓存大小 重新启动用 service mariadb restart就好了 Tips（艰难的mysql重启过程）（1）重启mysql遇到的问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768 （1）通过rpm包安装的MySQL通过下面这样的方式重启 service mysqld restart/etc/inint.d/mysqld start（2）从源码包安装的MySQL（我的服务器上是/usr/bin）// Linux关闭MySQL的命令$mysql_dir/bin/mysqladmin -uroot -p shutdown// linux启动MySQL的命令$mysql_dir/bin/mysqld_safe &amp;用这个命令启动的时候一直卡在[1] 11513[root@rabbitmq bin]# 190118 19:30:00 mysqld_safe Logging to &apos;/var/log/mariadb/mariadb.log&apos;.190118 19:30:00 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql为什么呢？？？？查看了一下日志，说没有找到mysql-bin.index文件190118 19:23:41 [Note] /usr/libexec/mysqld (mysqld 5.5.56-MariaDB) starting as process 11421 ...190118 19:23:41 mysqld_safe mysqld from pid file /var/run/mariadb/mariadb.pid ended190118 19:30:00 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql190118 19:30:00 [ERROR] mysqld: File &apos;/data/mysql/mysql-bin.index&apos; not found (Errcode: 2)190118 19:30:00 [ERROR] Aborting在/data/mysql/创建了一个mysql-bin.index文件再次启动，还是报错190118 19:30:00 [Note] /usr/libexec/mysqld (mysqld 5.5.56-MariaDB) starting as process 11740 ...190118 19:30:00 mysqld_safe mysqld from pid file /var/run/mariadb/mariadb.pid ended190118 19:39:04 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql190118 19:39:04 [ERROR] mysqld: File &apos;/data/mysql/mysql-bin.index&apos; not found (Errcode: 13)190118 19:39:04 [ERROR] Aborting190118 19:39:04 [Note] /usr/libexec/mysqld: Shutdown completeerrcode13，一般就是权限问题，通过命令 chown -R mysql:mysql /data/mysql/mysql-bin.index将原来为 -rw-r--r--. 1 root root 0 1月 18 19:38 mysql-bin.index改为-rw-r--r--. 1 mysql mysql 0 1月 18 19:38 mysql-bin.index再次启动，还是报错190118 19:45:05 [Note] /usr/libexec/mysqld (mysqld 5.5.56-MariaDB) starting as process 12690 ...190118 19:45:05 mysqld_safe mysqld from pid file /var/run/mariadb/mariadb.pid ended190118 19:45:38 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql190118 19:45:38 [ERROR] mysqld: File &apos;/data/mysql/mysql-bin.~rec~&apos; not found (Errcode: 13)190118 19:45:38 [ERROR] MYSQL_BIN_LOG::open_purge_index_file failed to open register file.190118 19:45:38 [ERROR] MYSQL_BIN_LOG::open_index_file failed to sync the index file.190118 19:45:38 [ERROR] Aborting190118 19:45:38 [Note] /usr/libexec/mysqld: Shutdown complete换一种思路，更改log日志存在地点log-bin = /var/lib/mysql/mysql-bin 这次启动时 抱如下信息190118 19:52:58 [Note] /usr/libexec/mysqld (mysqld 5.5.56-MariaDB) starting as process 13554 ...190118 19:52:58 mysqld_safe mysqld from pid file /var/run/mariadb/mariadb.pid ended190118 19:56:48 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql190118 19:56:48 [Note] /usr/libexec/mysqld (mysqld 5.5.56-MariaDB) starting as process 13855 ...190118 19:56:48 InnoDB: The InnoDB memory heap is disabled190118 19:56:48 InnoDB: Mutexes and rw_locks use GCC atomic builtins190118 19:56:48 InnoDB: Compressed tables use zlib 1.2.7190118 19:56:48 InnoDB: Using Linux native AIO190118 19:56:48 InnoDB: Initializing buffer pool, size = 128.0M190118 19:56:48 InnoDB: Completed initialization of buffer pool190118 19:56:48 InnoDB: highest supported file format is Barracuda.190118 19:56:48 InnoDB: Waiting for the background threads to start190118 19:56:49 Percona XtraDB (http://www.percona.com) 5.5.52-MariaDB-38.3 started; log sequence number 1597945190118 19:56:50 [Note] Plugin &apos;FEEDBACK&apos; is disabled.190118 19:56:50 [Note] Server socket created on IP: &apos;0.0.0.0&apos;.190118 19:56:50 [Note] /usr/libexec/mysqld: ready for connections.Version: &apos;5.5.56-MariaDB&apos; socket: &apos;/var/lib/mysql/mysql.sock&apos; port: 3306 MariaDB Server还是报错，是不是mysqld_safe这个命令有毒啊。。。。换 service mariadb restart这个命令。。。 （2）每次服务器（数据库）重启，服务器会调用flush logs;，会新创建一个binlog日志 （3）mysqld_safe脚本执行的基本流程:1234567891011121314151617181920212223241、查找basedir和ledir。2、查找datadir和my.cnf。3、对my.cnf做一些检查，具体检查哪些选项请看附件中的注释。4、解析my.cnf中的组[mysqld]和[mysqld_safe]并和终端里输入的命令合并。5、调用parse_arguments函数解析用户传递的所有参数($@)。6、对系统日志和错误日志的判断和相应处理具体可以参考附件中的注释，及选项--err-log参数的赋值。7、对选项--user，--pid-file，--socket及--port进行处理及赋值，保证启动时如果不给出这些参数它也会有值。8、启动mysqld.a)启动时会判断一个进程号是否存在，如果存在那么就在错误日志中记录&quot;A mysqld process already exists&quot;并且退出。b)如不存在就删除进程文件，如果删除不了，那么就在错误日志中记录&quot;Fatal error: Can&apos;t remove the pid file&quot;并退出。9、启动时对表进行检查。如果启动的时候检查表的话设置key_buffer and sort_buffer会提高速度并且减少磁盘空间的使用。也可以使用myisam-recover选项恢复出错的myisam表。10、如果启动时你什么参数都没有给，那么它会选用一些特定的参数启动，具体哪些参数请看附件注释。11、如果服务器异常关闭，那么会restart。最后用三步来总结检查环境检查配置选项启动及启动后的处理总结：选用mysqld_safe启动的好处。1、mysqld_safe增加了一些安全特性，例如当出现错误时重启服务器并向错误日志文件写入运行时间信息。2、如果有的选项是mysqld_safe 启动时特有的，那么可以终端指定，如果在配置文件中指定需要放在[mysqld_safe]组里面，放在其他组不能被正确解析。3、mysqld_safe启动能够指定内核文件大小 ulimit -c $core_file_size以及打开的文件的数量ulimit -n $size。4、MySQL程序首先检查环境变量，然后检查配置文件，最后检查终端的选项，说明终端指定选项优先级最高 （4）命令systemctl enable mysqld.service一直报错Failed to execute operation: No such file or directory在CentOS7中已经不在支持mysql，就算你已经安装了，CentOS7还是表示很嫌弃使用 systemctl status mariadb.serviceCentOS7不支持 mysqld，无法启动了，所以才需要装mariadb 到现在可以发现终于把binlog给启动了show variables like ‘%log_bin%’; 常用binlog操作命令12345show master logs;查看所有binlog日志列表show master status;查看master状态，即最后(最新)一个binlog日志的编号名称，及其最后一个操作事件pos结束点(Position)值flush logs; 刷新log日志，自此刻开始产生一个新编号的binlog日志文件reset master;重置(清空)所有binlog日志show binlog events in &apos;mysql-bin.000002&apos;;查看binlog日志内容（以表格形式） binlog的三种工作模式（1）Row level （我的数据库上默认的是ROW） ROW是基于行级别的,他会记录每一行记录的变化,就是将每一行的修改都记录到binlog里面,记录的非常详细，但sql语句并没有在binlog里。 日志中会记录每一行数据被修改的情况，然后在slave端对相同的数据进行修改。在replication里面也不会因为存储过程触发器等造成Master-Slave数据不一致的问题,但是有个致命的缺点日志量比较大.由于要记录每一行的数据变化,当执行update语句后面不加where条件的时候或alter table的时候,产生的日志量是相当的大。 （2）Statement level（默认） 每一条被修改数据的sql都会记录到master的bin-log中，slave在复制的时候sql进程会解析成和原来master端执行过的相同的sql再次执行 优点：解决了 Row level下的缺点，不需要记录每一行的数据变化，减少bin-log日志量，节约磁盘IO，提高新能 缺点：在statement模式下，由于他是记录的执行语句，所以，为了让这些语句在slave端也能正确执行，那么他还必须记录每条语句在执行的时候的一些相关信息，也就是上下文信息，以保证所有语句在slave端被执行的时候能够得到和在master端执行时候相同的结果。另外就是，由于mysql现在发展比较快，很多的新功能不断的加入，使mysql的复制遇到了不小的挑战，自然复制的时候涉及到越复杂的内容，bug也就越容易出现。在statement中，目前已经发现不少情况会造成Mysql的复制出现问题，主要是修改数据的时候使用了某些特定的函数或者功能的时候会出现，比如：sleep()函数在有些版本中就不能被正确复制，在存储过程中使用了last_insert_id()函数，可能会使slave和master上得到不一致的id等等。由于row是基于每一行来记录的变化，所以不会出现，类似的问题。 （3）Mixed（混合模式） 结合了Row level和Statement level的优点。 在默认情况下是statement,但是在某些情况下会切换到row状态，如当一个DML更新一个ndb引擎表，或者是与时间用户相关的函数等。在主从的情况下，在主机上如果是STATEMENT模式，那么binlog就是直接写now()，然而如果这样的话，那么从机进行操作的时间，也执行now()，但明显这两个时间不会是一样的，所以对于这种情况就必须把STATEMENT模式更改为ROW模式，因为ROW模式会直接写值而不是写语句（该案例是错误的，即使是STATEMENT模式也可以使用now()函数，具体原因以后再分析）。同样ROW模式还可以减少从机的相关计算，如在主机中存在统计写入等操作时，从机就可以免掉该计算把值直接写入从机。 MySQL的日志（主要是Binlog）对系统性能的影响（1）日志产生的性能影响由于日志的记录带来的直接性能损耗就是数据库系统中最为昂贵的IO资源。 MySQL的日志主要包括错误日志（ErrorLog），更新日志（UpdateLog），二进制日志（Binlog），查询日志（QueryLog），慢查询日志（SlowQueryLog）等。特别注意：更新日志是老版本的MySQL才有的，目前已经被二进制日志替代。 在默认情况下，系统仅仅打开错误日志，关闭了其他所有日志，以达到尽可能减少IO损耗提高系统性能的目的。但是在一般稍微重要一点的实际应用场景中，都至少需要打开二进制日志，因为这是MySQL很多存储引擎进行增量备份的基础，也是MySQL实现复制的基本条件。有时候为了进一步的mysql性能优化，定位执行较慢的SQL语句，很多系统也会打开慢查询日志来记录执行时间超过特定数值（由我们自行设置）的SQL语句。 一般情况下，在生产系统中很少有系统会打开查询日志。因为查询日志打开之后会将MySQL中执行的每一条Query都记录到日志中，会该系统带来比较大的IO负担，而带来的实际效益却并不是非常大。一般只有在开发测试环境中，为了定位某些功能具体使用了哪些SQL语句的时候，才会在短时间段内打开该日志来做相应的分析。所以，在MySQL系统中，会对性能产生影响的MySQL日志（不包括各存储引擎自己的日志）主要就是Binlog了。 一般企业binlog模式的选择：互联网公司使用MySQL的功能较少（不用存储过程、触发器、函数），选择默认的Statement level；用到MySQL的特殊功能（存储过程、触发器、函数）则选择Mixed模式；用到MySQL的特殊功能（存储过程、触发器、函数），又希望数据最大化一直则选择Row模式； mysql对于日志格式的选定原则:如果是采用 INSERT，UPDATE，DELETE 等直接操作表的情况，则日志格式根据 binlog_format 的设定而记录,如果是采用 GRANT，REVOKE，SET PASSWORD 等管理语句来做的话，那么无论如何 都采用 SBR 模式记录。 参考https://blog.csdn.net/z1988316/article/details/7883147?utm_source=blogxgwz2https://blog.csdn.net/intelrain/article/details/80451120https://blog.csdn.net/weixin_38187469/article/details/79273962https://blog.csdn.net/keda8997110/article/details/50895171]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java之ShutDownHook]]></title>
    <url>%2F2019%2F01%2F18%2FJava%E4%B9%8BShutDownHook%2F</url>
    <content type="text"><![CDATA[线上JVM挂掉怎么办，不要怕，有优雅停机在线上Java程序中经常遇到进程程挂掉，一些状态没有正确的保存下来，这时候就需要在JVM关掉的时候执行一些清理现场的代码。Java中得ShutdownHook提供了比较好的方案。 什么时候可以用钩子1）程序正常退出2）使用System.exit()3）终端使用Ctrl+C触发的中断4）系统关闭5）使用Kill pid命令干掉进程（kill -9 pid不会调用钩子）6) OOM宕机 如何添加钩子Runtime.addShutdownHook(Thread hook) 12345678在JDK中方法的声明：public void addShutdownHook(Thread hook)参数hook -- 一个初始化但尚未启动的线程对象，注册到JVM钩子的运行代码。异常IllegalArgumentException -- 如果指定的钩已被注册，或如果它可以判定钩已经运行或已被运行IllegalStateException -- 如果虚拟机已经是在关闭的过程中SecurityException -- 如果存在安全管理器并且它拒绝的RuntimePermission（“shutdownHooks”） 12345678910111213141516/** * JVM的关闭钩子--JVM正常关闭才会执行 */ public static void addHook()&#123; Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() &#123; public void run() &#123; //清空缓存信息 System.out.println("网关正常关闭前执行 清空所有缓存信息..............................."); ClientChannelCache.clearAll(); CacheQueue.clearIpCountRelationCache(); CacheQueue.clearMasterChannelCache(); &#125; &#125;)); &#125; 注意的地方同一个JVM最好只使用一个关闭钩子，而不是每个服务都使用一个不同的关闭钩子，使用多个关闭钩子可能会出现当前这个钩子所要依赖的服务可能已经被另外一个关闭钩子关闭了。为了避免这种情况，建议关闭操作在单个线程中串行执行，从而避免了再关闭操作之间出现竞态条件或者死锁等问题。 参考https://www.cnblogs.com/shuo1208/p/5871224.htmlhttps://www.cnblogs.com/langtianya/p/4300282.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty-CPU使用率高达100%]]></title>
    <url>%2F2019%2F01%2F18%2FNetty-CPU%E4%BD%BF%E7%94%A8%E7%8E%87%E9%AB%98%E8%BE%BE100%2F</url>
    <content type="text"><![CDATA[Netty做数据转发，但是CPU使用率太高了。 解决方案：System.setProperty(&quot;org.jboss.netty.epollBugWorkaround&quot;, &quot;true&quot;);//避免CPU使用率达到100% Googling for sun.nio.ch.WindowsSelectorImpl$SubSelector high cpu brings up a few hits from as last at 2015. Are you running an older version of Netty? Also see https://github.com/netty/netty/issues/3857 - you may want to try running with -Dorg.jboss.netty.epollBugWorkaround=true. https://stackoverflow.com/questions/37881109/netty-eats-100-of-cpu]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git团队协作中经常使用哪些术语]]></title>
    <url>%2F2019%2F01%2F18%2FGit%E5%9B%A2%E9%98%9F%E5%8D%8F%E4%BD%9C%E4%B8%AD%E7%BB%8F%E5%B8%B8%E4%BD%BF%E7%94%A8%E5%93%AA%E4%BA%9B%E6%9C%AF%E8%AF%AD%2F</url>
    <content type="text"><![CDATA[ACK — acknowledgement, i.e. agreed/accepted change AFAIK As Far As I Know （就我所知） ASAP abbr. As Soon As Possible 尽快; BTW By The Way 顺便 Ditto. 最经典的一句 出自《人鬼情未了》 ——I love you ——Ditto. EOL end of life 寿命终止 FYI abbr. For Your Information 供参考; IMHO In My Humble Opinion 恕我直言 IIRC — if I recall correctly IANAL — “ I am not a lawyer ”, but I smell licensing issues LGTM LOOKS GOOD TO ME Review完别人的PR，没有问题 NACK/NAK — negative acknowledgement, i.e. disagree with change and/or conceptOk, thanks :) PTAL Please Take A Look 帮我看下，一般都是请别人 review 自己的 PR RFC — request for comments, i.e. I think this is a good idea, lets discuss REVNO 修订版号 revision number 的缩写 thx Thanks That makes sense to me cc 对我来说有意义 TR,DR Too long,dont read 一翻到底 WIP work in progress 工作在进行中;]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql之s_profiling]]></title>
    <url>%2F2019%2F01%2F18%2FMysql%E4%B9%8Bs-profiling%2F</url>
    <content type="text"><![CDATA[今天在听Cetus课程的时候，看到了老师说了set profiling=1； 并不知道这是干什么的，来记录一下。 Query Profiler 来定位一条 Query 的性能瓶颈，这里我们再详细介绍一下 Profiling 的用途及使用方法。 要想优化一条 Query，我们就需要清楚的知道这条 Query 的性能瓶颈到底在哪里，是消耗的 CPU计算太多，还是需要的的 IO 操作太多？要想能够清楚的了解这些信息，在 MySQL 5.0 和 MySQL 5.1正式版中已经可以非常容易做到了，那就是通过 Query Profiler 功能。 MySQL 的 Query Profiler 是一个使用非常方便的 Query 诊断分析工具，通过该工具可以获取一条Query 在整个执行过程中多种资源的消耗情况，如 CPU，IO，IPC，SWAP 等，以及发生的 PAGE FAULTS，CONTEXT SWITCHE 等等，同时还能得到该 Query 执行过程中 MySQL 所调用的各个函数在源文件中的位置。 下面我们看看 Query Profiler 的具体用法。 开启 profiling 参数 执行Query 在开启 Query Profiler 功能之后，MySQL 就会自动记录所有执行的 Query 的 profile 信息了。 取系统中保存的所有 Query 的 profile 概要信息通过执行 “SHOW PROFILE” 命令获取当前系统中保存的多个 Query 的 profile 的概要信息。 针对单个 Query 获取详细的 profile 信息上面的例子中是获取 CPU 和 Block IO 的消耗，非常清晰，对于定位性能瓶颈非常适用。希望得到取其他的信息，都可以通过执行 “SHOW PROFILE *** FOR QUERY n” 来获取，各位读者朋友可以自行测试熟悉。 参考https://www.cnblogs.com/ggjucheng/archive/2012/11/15/2772058.html]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库分片、分区、分表、分库傻傻分不清楚]]></title>
    <url>%2F2019%2F01%2F18%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%89%87%E3%80%81%E5%88%86%E5%8C%BA%E3%80%81%E5%88%86%E8%A1%A8%E3%80%81%E5%88%86%E5%BA%93%E5%82%BB%E5%82%BB%E5%88%86%E4%B8%8D%E6%B8%85%E6%A5%9A%2F</url>
    <content type="text"><![CDATA[分片什么是分片在分布式存储系统中，数据需要分散存储在多台设备上，数据分片（Sharding）就是用来确定数据在多台存储设备上分布的技术。数据分片要达到三个目的： 分布均匀，即每台设备上的数据量要尽可能相近； 负载均衡，即每台设备上的请求量要尽可能相近； 扩缩容时产生的数据迁移尽可能少。分片相关概念 逻辑库(schema) 通常对实际应用来说，并不需要知道中间件的存在，业务开发人员只需要知道数据库的概念，所以数据库中间件可以被看做是一个或多个数据库集群构成的逻辑库。 逻辑表（table） 既然有逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表就是逻辑表。逻辑表，可以是数据切分后，分布在一个或多个分片库中，也可以不做数据切分，不分片，只有一个表构成。 分片表 是指那些原有的很大数据的表，需要切分到多个数据库的表，这样，每个分片都有一部分数据，所有分片构成了完整的数据。 总而言之就是需要进行分片的表。 非分片表 一个数据库中并不是所有的表都很大，某些表是可以不用进行切分的，非分片是相对分片表来说的，就是那些不需要进行数据切分的表。 分片节点(dataNode) 数据切分后，一个大表被分到不同的分片数据库上面，每个表分片所在的数据库就是分片节点（dataNode）。 节点主机(dataHost) 数据切分后，每个分片节点（dataNode）不一定都会独占一台机器，同一机器上面可以有多个分片数据库，这样一个或多个分片节点（dataNode）所在的机器就是节点主机（dataHost）,为了规避单节点主机并发数限制，尽量将读写压力高的分片节点（dataNode）均衡的放在不同的节点主机（dataHost）。 分片规则(rule) 前面讲了数据切分，一个大表被分成若干个分片表，就需要一定的规则，这样按照某种业务规则把数据分到某个分片的规则就是分片规则，数据切分选择合适的分片规则非常重要，将极大的避免后续数据处理的难度。 优点缺点应用场景任何技术都是在合适的场合下能发挥应有的作用。 Sharding 也一样。联机游戏、IM、BSP 都是比较适合 Sharding 的应用场景。其共性是抽象出来的数据对象之间的关联数据很小。比如IM ，每个用户如果抽象成一个数据对象，完全可以独立存储在任何一个地方，数据对象是 Share Nothing 的；再比如 Blog 服务提供商的站点内容，基本为用户生成内容(UGC)，完全可以把不同的用户隔离到不同的存储集合，而对用户来说是透明的。 这个”Share Nothing” 是从数据库集群中借用的概念，举例来说，有些类型的数据粒度之间就不是 “Share Nothing” 的，比如类似交易记录的历史表信息，如果一条记录中既包含卖家信息与买家信息，如果随着时间推移，买、卖家会分别与其它用户继续进行交易，这样不可避免的两个买卖家的信息会分布到不同的 Sharding DB 上，而这时如果针对买卖家查询，就会跨越更多的 Sharding ，开销就会比较大。 Sharding 并不是数据库扩展方案的银弹，也有其不适合的场景，比如处理事务型的应用就会非常复杂。对于跨不同DB的事务，很难保证完整性，得不偿失。所以，采用什么样的 Sharding 形式，不是生搬硬套的。我们知道每台机器无论配置多么好它都有自身的物理上限，所以当我们应用已经能触及或远远超出单台机器的某个上限的时候，我们惟有寻找别的机器的帮助或者继续升级的我们的硬件，但常见的方案还是横向扩展, 通过添加更多的机器来共同承担压力。我们还得考虑当我们的业务逻辑不断增长，我们的机器能不能通过线性增长就能满足需求？Sharding可以轻松的将计算，存储，I/O并行分发到多台机器上，这样可以充分利用多台机器各种处理能力，同时可以避免单点失败，提供系统的可用性，进行很好的错误隔离。 分片的种类数据的切分（Sharding）根据其切分规则的类型，可以分为两种切分模式。 （1）一种是按照不同的表（或者Schema）来切分到不同的数据库（主机）之上，这种切分可以称之为数据的垂直（纵向）切分 （2）另外一种则是根据表中的数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上面，这种切分称之为数据的水平（横向）切分。 分片的方法数据分片一般都是使用Key或Key的哈希值来计算Key的分布，常见的几种数据分片的方法如下： 划分号段。这种一般适用于Key为整型的情况，每台设备上存放相同大小的号段区间，如把Key为[1, 10000]的数据放在第一台设备上，把Key为[10001, 20000]的数据放在第二台设备上，依次类推。这种方法实现很简单，扩容也比较方便，成倍增加设备即可，如原来有N台设备，再新增N台设备来扩容，把每台老设备上一半的数据迁移到新设备上，原来号段为[1, 10000]的设备，扩容后只保留号段[1, 5000]的数据，把号段为[5001, 10000]的数据迁移到一台新增的设备上。此方法的缺点是数据可能分布不均匀，如小号段数据量可能比大号段的数据量要大，同样的各个号段的热度也可能不一样，导致各个设备的负载不均衡；并且扩容也不够灵活，只能成倍地增加设备。 取模。这种方法先计算Key的哈希值，再对设备数量取模（整型的Key也可直接用Key取模），假设有N台设备，编号为0~N-1，通过Hash(Key)%N就可以确定数据所在的设备编号。这种方法实现也非常简单，数据分布和负载也会比较均匀，可以新增任何数量的设备来扩容。主要的问题是扩容的时候，会产生大量的数据迁移，比如从N台设备扩容到N+1台，绝大部分的数据都要在设备间进行迁移。 检索表。在检索表中存储Key和设备的映射关系，通过查找检索表就可以确定数据分布，这里的检索表也可以比较灵活，可以对每个Key都存储映射关系，也可结合号段划分等方法来减小检索表的容量。这样可以做到数据均匀分布、负载均衡和扩缩容数据迁移量少。缺点是需要存储检索表的空间可能比较大，并且为了保证扩缩容引起的数据迁移量比较少，确定映射关系的算法也比较复杂。 一致性哈希。一致性哈希算法（Consistent Hashing）在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot Spot)问题，该方法的详细介绍参考此处http://blog.csdn.net/sparkliang/article/details/5279393。一致性哈希的算法简单而巧妙，很容易做到数据均分布，其单调性也保证了扩缩容的数据迁移是比较少的。 通过上面的对比，在这个系统选择一致性哈希的方法来进行数据分片。 分区什么是分区 数据分区是一种物理数据库的设计技术，它的目的是为了在特定的SQL操作中减少数据读写的总量以缩减响应时间。分区并不是生成新的数据表，而是将表的数据均衡分摊到不同的硬盘，系统或是不同服务器存储介子中，实际上还是一张表。另外，分区可以做到将表的数据均衡到不同的地方，提高数据检索的效率，降低数据库的频繁IO压力值 包括水平分区和垂直分区 优点 相对于单个文件系统或是硬盘，分区可以存储更多的数据； 数据管理比较方便，比如要清理或废弃某年的数据，就可以直接删除该日期的分区数据即可； 精准定位分区查询数据，不需要全表扫描查询，大大提高数据检索效率； 可跨多个分区磁盘查询，来提高查询的吞吐量； 在涉及聚合函数查询时，可以很容易进行数据的合并； 缺点什么时候分区 一张表的查询速度已经慢到影响使用的时候。 sql经过优化 数据量大 表中的数据是分段的 对数据的操作往往只涉及一部分数据，而不是所有的数据 分片和分区的区别与联系有的时候，Sharding 也被近似等同于水平分区(Horizontal Partitioning)，网上很多地方也用水平分区来指代 Sharding，但我个人认为二者之间实际上还是有区别的。的确，Sharding 的思想是从分区的思想而来，但数据库分区基本上是数据对象级别的处理，比如表和索引的分区，每个子数据集上能够有不同的物理存储属性，还是单个数据库范围内的操作，而 Sharding 是能够跨数据库，甚至跨越物理机器的。 Sharding 分区 存储依赖 可跨越DB、物理机器 可跨越表空间，不同的物理属性，不能跨DB存储 数据划分 时间、范围、面向服务等 范围、Hash、列表、混合分区等 存储方式 分布式 集中式 扩展性 Scale Out Scale Up 可用性 无单点 存在单点（DB本身） 价格 低廉 适中（DAS）甚至昂贵（SAN） 应用场景 常见于WEB2.0网站 多数传统应用 分表什么是分表就是把一张表按一定的规则分解成N个具有独立存储空间的实体表。系统读写时需要根据定义好的规则得到对应的字表明，然后操作它。 优点缺点什么时候分表一张表的查询速度已经慢到影响使用的时候。 sql经过优化 数据量大当频繁插入或者联合查询时，速度变慢 分区和分表的区别与联系分区从逻辑上来讲只有一张表，而分表则是将一张表分解成多张表。 分区和分表的目的都是减少数据库的负担，提高表的增删改查效率。 分区只是一张表中的数据的存储位置发生改变，分表是将一张表分成多张表。 当访问量大，且表数据比较大时，两种方式可以互相配合使用。 当访问量不大，但表数据比较多时，可以只进行分区。 分库什么是分库一旦分表，一个库中的表会越来越多 优点缺点什么时候分库单台DB的存储空间不够 随着查询量的增加单台数据库服务器已经没办法支撑 一般优化思路垂直分库–&gt;水平分库–&gt;读写分离 分库之后的问题事务的支持，分库分表，就变成了分布式事务 join时跨库，跨表的问题 分库分表，读写分离使用了分布式，分布式为了保证强一致性，必然带来延迟，导致性能降低，系统的复杂度变高。 问题解决方案对于不同的方式之间没有严格的界限，特点不同，侧重点不同。需要根据实际情况，结合每种方式的特点来进行处理。 选用第三方的数据库中间件（Atlas，Mycat，TDDL，DRDS），同时业务系统需要配合数据存储的升级。 参考https://blog.csdn.net/qq_28289405/article/details/80576614https://blog.csdn.net/weixin_38074050/article/details/78640004http://blog.sina.com.cn/s/blog_72ef7bea0101cjtb.html]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读《码出高效》笔记]]></title>
    <url>%2F2019%2F01%2F17%2F%E8%AF%BB%E3%80%8A%E7%A0%81%E5%87%BA%E9%AB%98%E6%95%88%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于 0与1的信号处理为我们带来了缤纷多彩的计算机世界，随着基础材料和信 号处理技术的发展，未来计算机能够处理的基础信号将不仅仅是二进制信息。比如， 三进制（ 高电平、低电平、断电），甚至十进制信息，届时计算机世界又会迎来一次 全新的变革。 在要求绝对精确表示的业务场景下，比如金融行业的货币表示，推荐使用整型存 储其最小单位的值，展示时可以转换成该货币的常用单位，比如人民币使用分存储， 美元使用美分存储。在要求精确表示小数点 位的业务场景下，比如圆周率要求存储 小数点后 1000 位数字，使用单精度和双精度浮点数类型保存是难以做到的，这时推 荐采用数组保存小数部分的数据。在比较浮点数时，由于存在误差，往往会出现意料 之外的结果，所以禁止通过判断两个浮点数是否相等来控制某些业务流程。在数据库 中保存小数时，推荐使用 decimal 类型，禁止使用 float类型和 double 类型。因为这 两种类型在存储的时候，存在精度损失的问题。 程序在发送消息时，应用层接既定的协议打包数据 随后由传输层加 上双方的端口 ，由网络层加上双方的 IP 地址，由链路层加上双方的 MAC 地址 将数据拆分成数据帧 经过多个路由器 网关后 到达目标机器。简而言之 就是按 端口→ IP 地址→ MAC 地址 这样的路径进行数据的封装和发送 解包的时候反过 来操作即可 从经验上来看，在数据库层面的请求应答时间必须在 100ms以内，秒级的 SQL 查询通常存在巨大的性能提升空间，有如下应对方案，（1）建立合适的索引（2）排查连接资源未显式关闭的情形。 要特别注意在 ThreadLocal 或流式计算 中使用数据库连接的地方。（3）合并短的请求（4）合理拆分多个表 join SQL 是超过三个表则禁止 join 如果表结构建 得不合理，应用逻辑处理不当，业务模型抽象有问题 那么三表 join 的数据量由于笛 卡儿积操作会呈几何级数增加，所以不推荐这样的做法。另外，对于需要join 的字段， 数据类型应保持绝对一致。多表关联查询时，应确保被关联的字段要有索引。（5）使用临时表（6）应用层优化。 包括进行数据结构优化、并发多线程改造等。 除了开发人员造成的漏洞，近年来出现了一种 Self-XSS 的攻击方式。 Sel -XSS 是利用部分非开发人员不懂技术，黑客通过红包、奖品或者优惠券等形式 诱导用户 复制攻击者提供的恶意代码 并非占贴到浏览器的 Console 中运行 从而导致 xss 。由 Self-XSS 属于社会工程学攻击，技术上目前尚无有效防范机制 因此只能通过在 Console 中展示提醒文案来阻止用户执行未知代码。 包装类的存在解决了基本数据类型无法做到的事情比如 泛型类型 参数、序列化、类型转换、高频区间数据缓存。尤其是最后－项，我们都知道 Integer 会缓存－ 128到 127 之间的值，对于 Integer var=？在－ 128 127 之间的赋值， Integer 象由 ntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使 用＝＝进行判断，但是这个区间之外的所有数据都会在堆上产生，并不会复用已有对象， 这是一个大问题。因此，推荐所有包装类对象之间值的比较 全部使用 equals （）方法。该例很好地说明了 Long只是缓存了 -128 到127 之间的值，而 1000L 没有被缓存； 在将 Integer 最大缓存值改为 7777 后， 1001被成功缓存。合理掌握包装类的缓存策略， 防止遇到问题是一个方面，使自己的程序性能最大化，更是程序员的情怀所在。在选择使用包装类还是基本数据类型时，推荐使用如下方式：（1） 所有的POJO类属性必须使用包装属性类型（2） RPC方法的返回值和参数必须使用包装数据类型（3） 所有的局部变量推荐使用基本数据类型]]></content>
      <categories>
        <category>Books</category>
      </categories>
      <tags>
        <tag>Books</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么不应该使用ZooKeeper做服务发现]]></title>
    <url>%2F2019%2F01%2F17%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%BA%94%E8%AF%A5%E4%BD%BF%E7%94%A8ZooKeeper%E5%81%9A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[本文作者通过ZooKeeper与Eureka作为 Service发现服务（注：WebServices 体系中的UDDI就是个发现服务）的优劣对比，分享了Knewton在云计算平台部署服务的经验。本文虽然略显偏激，但是看得出Knewton在云平台方面是非常有经验的，这篇文章从实践角度出发分别从云平台特点、CAP原理以及运维三个方面对比了ZooKeeper与Eureka两个系统作为发布服务的优劣，并提出了在云平台构建发现服务的方法论。 背景很多公司选择使用 ZooKeeper作为Service发现服务（Service Discovery），但是在构建Knewton（Knewton是一个提供个性化教育平台的公司、学校和出版商可以通过Knewton平台为学生提供自适应的学习材料）平台时，我们发现这是个根本性的错误。在这边文章中，我们将用我们在实践中遇到的问题来说明，为什么使用ZooKeeper做Service发现服务是个错误。 请留意服务部署环境让我们从头开始梳理。我们在部署服务的时候，应该首先考虑服务部署的平台（平台环境），然后才能考虑平台上跑的软件系统或者如何在选定的平台上自己构建一套系统。例如，对于云部署平台来说，平台在硬件层面的伸缩（注：作者应该指的是系统的冗余性设计，即系统遇到单点失效问题，能够快速切换到其他节点完成任务）与如何应对网络故障是首先要考虑的。当你的服务运行在大量服务器构建的集群之上时（注：原话为大量可替换设备），则肯定会出现单点故障的问题。对于knewton来说，我们虽然是部署在AWS上的，但是在过往的运维中，我们也遇到过形形色色的故障；所以，你应该把系统设计成“故障开放型”（expecting failure）的。其实有很多同样使用AWS的公司跟我们遇到了（同时有很多 书是介绍这方面的）相似的问题。你必须能够提前预料到平台可能会出现的问题如：意外故障（注：原文为box failure，只能意会到作者指的是意外弹出的错误提示框），高延迟与网络分割问题（注：原文为network partitions。意思是当网络交换机出故障会导致不同子网间通讯中断）——同时我们要能构建足够弹性的系统来应对它们的发生。 永远不要期望你部署服务的平台跟其他人是一样的！当然，如果你在独自运维一个数据中心，你可能会花很多时间与钱来避免硬件故障与网络分割问题，这是另一种情况了；但是在云计算平台中，如AWS，会产生不同的问题以及不同的解决方式。当你实际使用时你就会明白，但是，你最好提前应对它们（注：指的是 上一节说的意外故障、高延迟与网络分割问题）的发生。 ZooKeeper作为发现服务的问题ZooKeeper（注：ZooKeeper是著名Hadoop的一个子项目，旨在解决大规模分布式应用场景下，服务协调同步（Coordinate Service）的问题；它可以为同在一个分布式系统中的其他服务提供：统一命名服务、配置管理、分布式锁服务、集群管理等功能）是个伟大的开源项目，它很成熟，有相当大的社区来支持它的发展，而且在生产环境得到了广泛的使用；但是用它来做Service发现服务解决方案则是个错误。 在分布式系统领域有个著名的CAP定理（C- 数据一致性；A-服务可用性；P-服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个）；ZooKeeper是个CP的，即任何时刻对ZooKeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性；但是它不能保证每次服务请求的可用性（注：也就 是在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果）。但是别忘了，ZooKeeper是分布式协调服务，它的职责是保证数据（注：配置数据，状态数据）在其管辖下的所有服务之间保持同步、一致；所以就不难理解为什么ZooKeeper被设计成CP而不是AP特性的了，如果是AP的，那么将会带来恐怖的后果（注：ZooKeeper就像交叉路口的信号灯一样，你能想象在交通要道突然信号灯失灵的情况吗？）。而且， 作为ZooKeeper的核心实现算法Zab，就是解决了分布式系统下数据如何在多个服务之间保持同步问题的。 作为一个分布式协同服务，ZooKeeper非常好，但是对于Service发现服务来说就不合适了；因为对于Service发现服务来说就算是返回了包含不实的信息的结果也比什么都不返回要好；再者，对于Service发现服务而言，宁可返回某服务5分钟之前在哪几个服务器上可用的信息，也不能因为暂时的网络故障而找不到可用的服务器，而不返回任何结果。所以说，用ZooKeeper来做Service发现服务是肯定错误的，如果你这么用就惨了！ 而且更何况，如果被用作Service发现服务，ZooKeeper本身并没有正确的处理网络分割的问题；而在云端，网络分割问题跟其他类型的故障一样的确会发生；所以最好提前对这个问题做好100%的准备。就像Jepsen在 ZooKeeper网站上发布的博客中所说：在ZooKeeper中，如果在同一个网络分区（partition）的节点数（nodes）数达不到 ZooKeeper选取Leader节点的“法定人数”时，它们就会从ZooKeeper中断开，当然同时也就不能提供Service发现服务了。 如果给ZooKeeper加上客户端缓存（注：给ZooKeeper节点配上本地缓存）或者其他类似技术的话可以缓解ZooKeeper因为网络故障造成节点同步信息错误的问题。Pinterest与 Airbnb公司就使用了这个方法来防止ZooKeeper故障发生。这种方式可以从表面上解决这个问题，具体地说，当部分或者所有节点跟ZooKeeper断开的情况下，每个节点还可以从本地缓存中获取到数据；但是，即便如此，ZooKeeper下所有节点不可能保证任何时候都能缓存所有的服务注册信息。如果 ZooKeeper下所有节点都断开了，或者集群中出现了网络分割的故障（注：由于交换机故障导致交换机底下的子网间不能互访）；那么ZooKeeper 会将它们都从自己管理范围中剔除出去，外界就不能访问到这些节点了，即便这些节点本身是“健康”的，可以正常提供服务的；所以导致到达这些节点的服务请求被丢失了。（注：这也是为什么ZooKeeper不满足CAP中A的原因） 更深层次的原因是，ZooKeeper是按照CP原则构建的，也就是说它能保证每个节点的数据保持一致，而为ZooKeeper加上缓存的做法的目的是为了让ZooKeeper变得更加可靠（available）；但是，ZooKeeper设计的本意是保持节点的数据一致，也就是CP。所以，这样一来，你可能既得不到一个数据一致的（CP）也得不到一个高可用的（AP）的Service发现服务了；因为，这相当于你在一个已有的CP系统上强制栓了一个AP的系统，这在本质上就行不通的！一个Service发现服务应该从一开始就被设计成高可用的才行！ 如果抛开CAP原理不管，正确的设置与维护ZooKeeper服务就非常的困难；错误会经常发生，导致很多工程被建立只是为了减轻维护ZooKeeper的难度。这些错误不仅存在与客户端而且还存在于ZooKeeper服务器本身。Knewton平台很多故障就是由于ZooKeeper使用不当而导致的。那些看似简单的操作，如：正确的重建观察者（reestablishing watcher）、客户端Session与异常的处理与在ZK窗口中管理内存都是非常容易导致ZooKeeper出错的。同时，我们确实也遇到过 ZooKeeper的一些经典bug：ZooKeeper-1159 与ZooKeeper-1576； 我们甚至在生产环境中遇到过ZooKeeper选举Leader节点失败的情况。这些问题之所以会出现，在于ZooKeeper需要管理与保障所管辖服务 群的Session与网络连接资源（注：这些资源的管理在分布式系统环境下是极其困难的）；但是它不负责管理服务的发现，所以使用ZooKeeper当 Service发现服务得不偿失。 做出正确的选择：Eureka的成功我们把Service发现服务从ZooKeeper切换到了Eureka平台，它是一个开源的服务发现解决方案，由Netflix公司开发。（注：Eureka由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作 服务注册服务器。Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。）Eureka一开 始就被设计成高可用与可伸缩的Service发现服务，这两个特点也是Netflix公司开发所有平台的两个特色。（他们都在讨论Eureka）。自从切换工作开始到现在，我们实现了在生产环境中所有依赖于Eureka的产品没有下线维护的记录。我们也被告知过，在云平台做服务迁移注定要遇到失败；但是我们从这个例子中得到的经验是，一个优秀的Service发现服务在其中发挥了至关重要的作用！]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你了解Node.js吗？]]></title>
    <url>%2F2019%2F01%2F17%2F%E4%BD%A0%E4%BA%86%E8%A7%A3Node-js%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[如果你去年注意过技术方面的新闻，我敢说你至少看到node.js不下一两次。那么问题来了“node.js是什么？”。有些人没准会告诉你“这是一种通过JavaScript语言开发web服务端的东西”。如果这种晦涩解释还没把你搞晕，你没准会接着问：“为什么我们要用node.js？”，别人一般会告诉你：node.js有非阻塞，事件驱动I/O等特性，从而让高并发（high concurrency）在的轮询（Polling）和comet构建的应用中成为可能。 当你看完这些解释觉得跟看天书一样的时候，你估计也懒得继续问了。不过没事。我这篇文章就是在避开高端术语的同时，帮助你你理解node.js的。 浏览器给网站发请求的过程一直没怎么变过。当浏览器给网站发了请求。服务器收到了请求，然后开始搜寻被请求的资源。如果有需要，服务器还会查询一下数据库，最后把响应结果传回浏览器。不过，在传统的web服务器中（比如Apache），每一个请求都会让服务器创建一个新的进程来处理这个请求。 后来有了Ajax。有了Ajax，我们就不用每次都请求一个完整的新页面了，取而代之的是，每次只请求需要的部分页面信息就可以了。这显然是一个进步。但是比如你要建一个FriendFeed这样的社交网站（类似人人网那样的刷朋友新鲜事的网站），你的好友会随时的推送新的状态，然后你的新鲜事会实时自动刷新。要达成这个需求，我们需要让用户一直与服务器保持一个有效连接。目前最简单的实现方法，就是让用户和服务器之间保持长轮询（long polling）。 HTTP请求不是持续的连接，你请求一次，服务器响应一次，然后就完了。长轮训是一种利用HTTP模拟持续连接的技巧。具体来说，只要页面载入了，不管你需不需要服务器给你响应信息，你都会给服务器发一个Ajax请求。这个请求不同于一般的Ajax请求，服务器不会直接给你返回信息，而是它要等着，直到服务器觉得该给你发信息了，它才会响应。比如，你的好友发了一条新鲜事，服务器就会把这个新鲜事当做响应发给你的浏览器，然后你的浏览器就刷新页面了。浏览器收到响应刷新完之后，再发送一条新的请求给服务器，这个请求依然不会立即被响应。于是就开始重复以上步骤。利用这个方法，可以让浏览器始终保持等待响应的状态。虽然以上过程依然只有非持续的Http参与，但是我们模拟出了一个看似持续的连接状态 我们再看传统的服务器（比如Apache）。每次一个新用户连到你的网站上，你的服务器就得开一个连接。每个连接都需要占一个进程，这些进程大部分时间都是闲着的（比如等着你好友发新鲜事，等好友发完才给用户响应信息。或者等着数据库返回查询结果什么的）。虽然这些进程闲着，但是照样占用内存。这意味着，如果用户连接数的增长到一定规模，你服务器没准就要耗光内存直接瘫了。 这种情况怎么解决？解决方法就是刚才上边说的：非阻塞和事件驱动。这些概念在我们谈的这个情景里面其实没那么难理解。你把非阻塞的服务器想象成一个loop循环，这个loop会一直跑下去。一个新请求来了，这个loop就接了这个请求，把这个请求传给其他的进程（比如传给一个搞数据库查询的进程），然后响应一个回调（callback）。完事了这loop就接着跑，接其他的请求。这样下来。服务器就不会像之前那样傻等着数据库返回结果了。 如果数据库把结果返回来了，loop就把结果传回用户的浏览器，接着继续跑。在这种方式下，你的服务器的进程就不会闲着等着。从而在理论上说，同一时刻的数据库查询数量，以及用户的请求数量就没有限制了。服务器只在用户那边有事件发生的时候才响应，这就是事件驱动。 FriendFeed是用基于Python的非阻塞框架Tornado (知乎也用了这个框架) 来实现上面说的新鲜事功能的。不过，Node.js就比前者更妙了。Node.js的应用是通过javascript开发的，然后直接在Google的变态V8引擎上跑。用了Node.js，你就不用担心用户端的请求会在服务器里跑了一段能够造成阻塞的代码了。因为javascript本身就是事件驱动的脚本语言。你回想一下，在给前端写javascript的时候，更多时候你都是在搞事件处理和回调函数。javascript本身就是给事件处理量身定制的语言。 Node.js还是处于初期阶段。如果你想开发一个基于Node.js的应用，你应该会需要写一些很底层代码。但是下一代浏览器很快就要采用WebSocket技术了，从而长轮询也会消失。在Web开发里，Node.js这种类型的技术只会变得越来越重要]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>Node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你了解响应式编程吗？]]></title>
    <url>%2F2019%2F01%2F17%2F%E4%BD%A0%E4%BA%86%E8%A7%A3%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[响应式编程？其实说白了，和传统的编程方式没什么区别，都是一些函数调用，只不过是增加了很多适配模式等。响应式编程的英文名，Reactive Programming，那就是针对响应的呗。那啥叫响应呢？你烧水呢，水烧开了，水壶会叫，这就是一下响应了。不要想的太复杂，这些东西都是基于现实世界的需要而来的。响应式它是依赖于事件的，响应式的代码它的运行不是按代码的顺序，而是跟多个按时间发生的事件有关。可能你会想，依赖事件？这不就是“回调”嘛，但在响应式编程里，这些按时间排列的事件，被称为“流”，stream。 简单的讲，响应式中的事件序列类似于js的数组，它里面的事件流就是时间的序列。响应式编程，就是异步的数据流的开发。响应式编程，它的关注重点在于“大量的UI事件与数据的互相影响”。啥意思呢，就例如某篇文章，你点个赞，那么一、所有其它人能看到赞；二、作者本人赞数量增加；三、文章权重提升；四、作者排名可能变化；。。。更多，“一个数据的变化，它的影响可能是呈现网状扩散”。它的特点吧，一是速度响应快，低延迟；二是健壮性弹性，有故障也能尽量响应；三是资源弹性，访问量大自动加资源，少了自动减；四是有消息自动传递。响应式的思想，实际是观察者模式 + （stream与事件源的通信控制）。 函数式编程？函数式编程是一系列被不公平对待的编程思想的保护伞，它的核心思想是，它是一种将程序看成是数学方法的求值、不会改变状态、不会产生副作用（后面我们马上会谈到）的编程方式。 FP 核心思想强调： 声明式代码 —— 程序员应该关心是什么，让编译器和运行环境去关心怎样做。 明确性 —— 代码应该尽可能的明显。尤其是要隔离副作用避免意外。要明确定义数据流和错误处理，要避免 GOTO 语句和 异常，因为它们会将应用置于意外的状态。 并发 —— 因为纯函数的概念，大多数函数式代码默认都是并行的。由于CPU运行速度没有像以前那样逐年加快（(详见 摩尔定律)）， 普遍看来这个特点导致函数式编程渐受欢迎。以及我们也必须利用多核架构的优点，让代码尽量的可并行。 高阶函数 —— 函数和其他的语言基本元素一样是一等公民。你可以像使用 string 和 int 一样的去传递函数。 不变性 —— 变量一经初始化将不能修改。一经创建，永不改变。如果需要改变，需要创建新的。这是明确性和避免副作用之外的另一方面。如果你知道一个变量不能改变，当你使用时会对它的状态更有信心。 函数式编程：JS、Scala、Erlang 响应式编程与函数式编程的区别？它和函数式编程的区别，这个简单的说一下，函数式编程就是二个字，“不变”。啥都不变，一经创建永远不变。如果要变，再创建个新的。在它里面函数就是数据的通道。参数确定时，结果是可以预测的。 ##更进一步 怎么理解响应式的背压？可以理解为承上启下。比如洪水，大坝的作用就是背压。背压应该写在靠近生产者的地方，或者说是连接元素生产者和消费者的一个地方，即生产者和消费者的连线者。背压应该具有承载元素的能力，也就是其必须是一个容器的，而且元素的存储与下发应该具有先后的，可以使用队列来实现。打一个比喻：去电影院看电影，我们作为消费者消费电影，电影厂商提供生产电影，电影院负责下发电影，电影院作为生产者与消费者之间的连线者，我们不需要关心电影院会放映多少电影，我们只需要观看就行了。 怎么理解阻塞和异步？咖啡很烫，不能喝，只能等到冷却，这个冷却就作为了阻塞，因为其占据了一条线程，但我们可以看电视，也就是说你阻塞你的 ，但是我仍然可以看电视。看电视是主线程。于是异步就出现了，涉及到异步，就涉及到线程的状态。既然阻塞要占据一条线程来工作，那么必然会有线程状态的管理。 非阻塞更多体现在等待层面，现实中我们等一个人，往往都是由时间限制的，难道我们要用一生的时间去街口等待一个人而荒废一生？总有跳出阻塞的路子。在nio里就是timeout。 我们讲的非阻塞都是相对的，具体某个任务该阻塞还是得阻塞。 Socket下同步/异步和阻塞/非阻塞:同步/异步是属于操作系统级别的，指的是操作系统在收到程序请求的IO之后，如果IO资源没有准备好的话，该如何响应程序的问题，同步的话就是不响应，直到IO资源准备好；而异步的话则会返回给程序一个标志，这个标志用于当IO资源准备好后通过事件机制发送的内容应该发到什么地方。 阻塞/非阻塞是属于程序级别的，指的是程序在请求操作系统进行IO操作时，如果IO资源没有准备好的话，程序该怎么处理的问题，阻塞的话就是程序什么都不做，一直等到IO资源准备好，非阻塞的话程序则继续运行，但是会时不时的去查看下IO到底准备好没有呢； 我们通常见到的BIO是同步阻塞式的，同步的话说明操作系统底层是一直等待IO资源准备直到ok的，阻塞的话是程序本身也在一直等待IO资源准备直到ok，具体来讲程序级别的阻塞就是accept和read造成的，我们可以通过改造将其变成非阻塞式，但是操作系统层次的阻塞我们没法改变。 我们的NIO是同步非阻塞式的，其实它的非阻塞实现原理和我们上面的讲解差不多的，就是为了改善accept和read方法带来的阻塞现象，所以引入了Channel和Buffer的概念。]]></content>
      <categories>
        <category>Architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件锁]]></title>
    <url>%2F2019%2F01%2F17%2F%E6%96%87%E4%BB%B6%E9%94%81%2F</url>
    <content type="text"><![CDATA[背景我们都知道，Nginx是多进程程序，80端口是各进程所共享的，多进程同时listen 80端口，势必会产生竞争，也产生了所谓的“惊群”效应。当内核accept一个连接时，会唤醒所有等待中的进程，但实际上只有一个进程能获取连接，其他的进程都是被无效唤醒的。所以Nginx采用了自有的一套accept加锁机制，避免多个进程同时调用accept。Nginx多进程的锁在底层默认是通过CPU自旋锁来实现。如果操作系统不支持自旋锁，就采用文件锁。 Tips：查看占用某端口的进程命令lsof -i:80（更准确，master进程和woreker进程都显示了出来） 或者netstat -tunlp | grep 80（只显示出了worker进程） 这里提到了文件锁。那么什么是文件锁呢？ 文件锁在多任务操作系统环境中，如果一个进程尝试对正在被其他进程读取的文件进行写操作，可能会导致正在进行读操作的进程读取到一些被破坏或者不完整的数据；如果两个进程并发对同一个文件进行写操作，可能会导致该文件遭到破坏。因此，为了避免发生这种问题，必须要采用某种机制来解决多个进程并发访问同一个文件时所面临的同步问题，由此而产生了文件加锁方面的技术。文件锁是一种文件读写机制。在不论什么特定的时间仅仅同意一个进程访问一个文件。利用这样的机制可以使读写单个文件的过程变得更安全。 我们为什么需要文件锁？想像以下场景： 进程“A”打开和读取一个文件，此文件包括账户相关的一些信息。 进程“B”也打开了这个文件。并读取了文件里的信息。 如今，进程“A”更改了其副本中的一条剩余金额记录，并将其写入文件。 此时，进程“B”并不知道上次读取的文件已经被更改。它还保存着原始的文件副本。然后。进程“B”更改了“A”操作的那条同样的记录，并将记录写入文件。 此时。文件里将仅仅保存了进程“B”更改过的记录。 为了避免这样的事情发生，就要使用文件锁来确保操作的“序列化”。 Linux系统中两种经常使用的文件锁协同锁协同锁要求參与操作的进程之间协同合作。 如果进程“A”获得一个WRITE锁，并開始向文件里写入内容；此时，进程“B”并没有试图获取一个锁，它仍然能够打开文件并向文件里写入内容。 在此过程中，进程“B”就是一个非合作进程。如果进程“B”试图获取一个锁，那么整个过程就是一个合作的过程，从而能够保证操作的“序列化”。 仅仅有当參与操作的进程是协同合作的时候，协同锁才干发挥作用。协同锁有时也被称为“非强制”锁 强制锁强制锁不须要參与操作的进程之间保持协同合作。它利用内核来查检每一个打开、读取、写入操作，从而保证在调用这些操作时不违反文件上的锁规则。关于强制锁的很多其它信息，能够在kernal.org上找到。 为了能使用Linux中的强制锁功能。你须要在文件系统级别上打开它。同时在单个文件上打开它。其步骤是： 挂载文件系统时使用“-o mand”參数。 对于要打开强制锁功能的文件lock_file。必须打开set-group-ID位。关闭group-execute位。 （选择此方法的原因是，当你关闭group-execute时，设置set-group-ID就没有实际的意义了） ###代码1234567891011121314151617181920212223242526272829303132#include&lt;stdio.h&gt;#include&lt;fcntl.h&gt;#include&lt;stdlib.h&gt;int main(int argc, char **argv) &#123; if(argc &gt; 1) &#123; int fd = open(argv[1], O_WRONLY); if(fd == -1)&#123; printf("Unable to open the file\n"); exit(1); &#125; static struct flock lock; lock.l_type = F_WRLCK; lock.l_start = 0; lock.l_whence = SEEK_SET; lock.l_len = 0; lock.l_pid = getpid(); int ret = fcntl(fd, F_SETLKW, &amp;lock); printf("Return value of fcntl:%d\n", ret); if(ret == 0) &#123; while(1)&#123; scanf("%c", NULL);&#125; &#125; &#125;&#125; 12345678910111213141516gcc -o file_lock file_lock.cmount -oremount,mand / (使用mount命令带“mand”參数来又一次挂载根文件系统，例如以下所看到的。这将在文件系统级别使能强制锁功能。)touch advisory.txttouch mandatory.txtchmod g+s,g-x mandatory.txt./file_lock advisory.txtls &gt;&gt;advisory.txt在上面的样例中，ls命令会将其输出写入到advisory.txt文件中。即使我们获得了一个写入锁，仍然会有一些进程（非合作）可以往文件中写入数据。这就是所谓的“协同”锁。./file_lock mandatory.txtls &gt;&gt;mandatory.txt (ls命令在将其输出写入到mandatory.txt文件之前。会等待文件锁被删除。尽管它仍然是一个非合作进程。但强制锁起了作用) flock的使用场景：检测进程是否已经存在12345678910111213141516171819int checkexit(char* pfile)&#123; if (pfile == NULL) &#123; return -1; &#125; int lockfd = open(pfile,O_RDWR); if (lockfd == -1) &#123; return -2; &#125; int iret = flock(lockfd,LOCK_EX|LOCK_NB); if (iret == -1) &#123; return -3; &#125; return 0;&#125; flock()的限制flock()放置的锁有如下限制 只能对整个文件进行加锁。这种粗粒度的加锁会限制协作进程间的并发。假如存在多个进程，其中各个进程都想同时访问同一个文件的不同部分。通过flock()只能放置劝告式锁。很多NFS实现不识别flock()放置的锁。注释：在默认情况下，文件锁是劝告式的，这表示一个进程可以简单地忽略另一个进程在文件上放置的锁。要使得劝告式加锁模型能够正常工作，所有访问文件的进程都必须要配合，即在执行文件IO之前先放置一把锁。 加锁的原理从内核实现的角度来看，每当创建一把文件锁的时候，系统就会实例化一个struct file_lock对象，这个file_lock对象会记录锁的相关信息：如锁的类型（共享锁，独占锁）、拥有这把锁的进程号、锁的标识（租赁锁，阻塞锁，POSIX锁，FLOCK锁），等等。最后把这个file_lock对象插入到被锁文件的inode.i_flock链表中，就完成了对该文件的加锁功能。要是其它进程想要对同一个文件加锁，那么它在将file_lock对象插入到inode.i_flock之前，会遍历该链表，如果没有发现冲突的锁，就将其插入到链表尾，表示加锁成功，否则失败。至于为什么要将inode与file_lock以链表的形式关联起来，主要是考虑到用户有时可以对同一个文件加多个文件锁。例如：我们可以对同一个文件加多个共享锁；或者我们可以同时对文件加POSIX锁和FLOCK锁，这两种锁分别对应flock()和fcntl()两种系统调用函数；再或者可以通过多次调用fcntl()对同一个文件中的多个内容块加上POSIX记录锁。 POSIX锁和FLOCK锁的区别： POSIX锁和FLOCK锁分别是通过fcntl()和flock()系统调用完成的。虽然实现的原理上都差不多，都是生成一个file_lock对象并插入inode文件锁链表，但是POSIX锁是支持针对某一段文件内容进行加锁的，而FLOCK锁不支持。 POSIX锁可以重复加锁，即同一个进程，可以对同一个文件多次加同样一把锁。例如：第一次我对A文件的一个0~10的内容块加了一把独占锁，那么第二次同一个进程中我一样可以对这个A文件的0~10的内容块再加一把独占锁，这个有点像是递归加锁，但是我解锁时只需要解一次。FLOCK锁则不同，如果你第一次对A文件加了一把独占锁，那么在同一个进程中你就不能对A文件再加一把锁了。这个区别其实只不过是在加锁的时候，遍历inode.i_flock链表时，发现存在PID相同的锁时，系统对于POSIX锁和FLOCK锁的具体处理手段不一样罢了。 通过第2点，我们可以想象一下，POSIX锁和FLOCK锁在多线程环境下的不同。我们知道从Linux内核的视角来看，它是不区分所谓的进程和线程的，都不过是CPU调度队列中的一个个task_struct实例而已，所以不会对线程的场景进行专门的处理，也正以为如此，平时我们用的NPTL线程库也都是在用户态环境中模拟出来的，Linux内核并不直接支持。回到刚刚的话题，因为内核它在加锁的时候是看PID的，所以在内核看来多线程的加锁只不过是同一个进程（因为每个线程的PID都是一样的）在对同一个文件加多把锁。这样，多线程环境下的加锁行为就表现为：同一个进程中的多个线程可以对同一个文件加多次POSIX独占或共享锁，但是不可以对同一个文件加多次FLOCK独占锁（不过共享锁是可以加多次的）。 在一个项目中使用了GPFS共享文件系统，我们在开发过程中发现，对于FLOCK锁只支持本地，而POSIX锁则可以支持跨主机加锁。例如：我们有两台独立的机器A和B，在A机器上有某个进程对文件f加POSIX独占锁，然后在B机器上当有某个进程想对f加POSIX独占锁时，就会失败。可是当我们使用FLOCK锁时，就发现两台机器对同一个文件加FLOCK锁是互不影响的，即A和B机器都可以对f加独占锁。 参考文献https://www.ibm.com/developerworks/cn/linux/l-cn-filelock/]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你知道女巫攻击吗？]]></title>
    <url>%2F2018%2F12%2F27%2F%E4%BD%A0%E7%9F%A5%E9%81%93%E5%A5%B3%E5%B7%AB%E6%94%BB%E5%87%BB%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[概述女巫攻击(Sybil Attack)是2002年由John R. Douceur在《the Sybil Attack》[1]文中提出的，它是作用于对等（Peer-to-Peer,简称P2P）网络中的一种攻击形式:攻击者利用单个节点来伪造多个身份存在于P2P网络中，从而达到削弱网络的冗余性，降低网络健壮性，监视或干扰网络正常活动等目的。在P2P网络中，为了解决来自恶意节点或者节点失效带来的安全威胁，通常会引入冗余备份机制，将运算或存储任务备份到多个节点上，或者将一个完整的任务分割存储在多个节点上。正常情况下，一个设备实体代表一个节点，一个节点由一个ID来标识身份。然而，在缺少可信赖的节点身份认证机构的P2P网络中，难以保证所备份的多个节点是不同的实体。攻击者可以通过只部署一个实体，向网络中广播多个身份ID，来充当多个不同的节点，这些伪造的身份一般被称为Sybil节点[2,3]。Sybil节点为攻击者争取了更多的网络控制权，一旦用户查询资源的路径经过这些Sybil节点，攻击者可以干扰查询、返回错误结果，甚至拒绝回复。 应用案例Sybil Attack的思想被广泛用于对抗P2P僵尸网络。以知名P2P僵尸网络Strom[2]为例,其采用了基于Kademlia的Overnet协议，正常节点的行为:1、每个加入网络中的节点会生成一个ID号用以标识自身；2、节点通过预设的算法每天生成32个不同key来查询控制命令；3、控制者会提前在网络中发布这32个key对应的命令&lt;key,command&gt;以供节点查询；4、根据Overnet协议，&lt;key,command&gt;会存放在K个与该key相邻ID的节点中，并通过递归的方式进行查询。Sybil节点行为：1、根据待攻击的key空间生成相应的ID（接近key的哈希值），使得查询请求能有较高概率被路由到Sybil节点；2、主动向网络中的其他节点广播自己的ID，使其出现在其他节点的路由表中；3、当查询key的路径经过Sybil节点时，Sybil节点返回错误信息，或者重路由到其他Sybil节点，使得正常节点无法进行C&amp;C通信获取控制命令。 怎么解决女巫攻击？一种方法是工作量证明机制，即证明你是一个节点，别只说不练，而是要用计算能力证明，这样极大地增加了攻击的成本。另一种方法是身份认证（相对于PoW协议，女巫攻击是基于BFT拜占庭使用容错协议的Blockchain需要考虑的问题，需要采用相应的身份认证机制）。认证机制分为二类：1）基于第三方的身份认证每加入一个新的节点都需要与某一个可靠的第三方节点进行身份验证。2）纯分布式的身份认证每加入一个新的节点都需要获得当前网络中所有可靠节点的认证，这种方法采用了随机密钥分发验证的公钥体制的认证方式，需要获得网络中大多数节点的认证才能加入该网络。 大话女巫攻击女巫攻击：分身诈骗术应对方法：1.干活 你即便分身千千万，唯有真心能干活。分心是虚幻的，没有力气，pow证明。2.发身份证 可靠第三方公安局给你发身份证，没有身份证都是分身妖怪。3.熟人社会 你迁户口到一个新的村子里，必须得到村子里，大部分人的认证，这就是中国传统社会的身份认证方法。群众的眼睛就是火眼金睛，照出一切妖魔鬼怪。]]></content>
      <categories>
        <category>Information Safety</category>
      </categories>
      <tags>
        <tag>Information Safety</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你知道可信计算吗]]></title>
    <url>%2F2018%2F12%2F19%2F%E4%BD%A0%E7%9F%A5%E9%81%93%E5%8F%AF%E4%BF%A1%E8%AE%A1%E7%AE%97%E5%90%97%2F</url>
    <content type="text"><![CDATA[安全和可信的区别？？安全分两条，有功能性和保障性 （保密性 完整性 可用性 可查性）可信本质是可预期 ，是保障安全四个特性的可预期 。利用密码学通过保障硬件系统的可预期 来保障 上层的可预期。安全就是加密 ，可信就是加密的程度 如何密。 TPCM（对标TPM）TPCM应该包含tcm模块和一个计算芯片，也就是说TPCM应该是包含可信根的，Cube-tcm 可以用来管理和调度虚拟可信根啥的，调度句柄 和上下文操作。Tpcm调用tcm密码模块（sm3）。在计算机 启动过程中， 先起这个TPCM，再起cpu。Tpcm里边有一个完整的访问策略，是一个核心的索引，必须通过他进行调用，保存的策略可能存在硬盘等其他地方，但是必须通过索引来访问。把TPCm放在哪呢？可以把 八核中的一核作为tpcm。Tpcm管理的是 人 、机器、 和密码之间的关联关系。Tcm空间 很有限，在里边解密 ，秘钥迁移过程 比如只能放4 个秘钥，但是现在要管理10个 可以用根密码 加密之后 放在外边。还有 秘钥授权 和权限管理 ，这一部分是 可信度量的部分先从 tcm里取出一个 放到内存里 和用户建设一个会话 才能使用 （类似于操作系统的资源调度算法进行切换）只不过是更严格。 什么是二进制证明？由于 PCR 中所存储的度量值是利用散列函数获得的二 进制摘要值, 因此 TCG 提供的这种对平台证明的方 式称为二进制证明。 等级保护？假设一个人想要一个很安全的地方。首先要有房子，修门、 锁 ，围墙，等级保护的意义就在这 ，安全严格就能，这样能让房子更加结实，房子更加坚固。可信加固技术。可信计算并不是新东西，可信也采用了很多过去的技术，可信就是老老实实的。其实可信计算不是原先没有，而且对原先技术的体系优化和构建化。利用防控 和加密机制进行防控。 Cube之改造？制定一个安全策略，投入产出不平衡的领域，可以利用区块链技术把cube 改成区块链形式的。区块上放的是配置文件。我们的东西 ，比区块链纯密码学的更灵活的多，]]></content>
      <categories>
        <category>TrustComputing</category>
      </categories>
      <tags>
        <tag>TrustComputing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[当SDN遇见NFV]]></title>
    <url>%2F2018%2F12%2F19%2F%E5%BD%93SDN%E9%81%87%E8%A7%81NFV%2F</url>
    <content type="text"><![CDATA[SDN从2012年开始，在学术界受到了广泛的关注。在阅读了部分国外大牛写的相关综述性文章若干之后，发现其中似乎并没有看到NFV的影子。提到SDN，能想到的基本上绕不过“控制转发分离、可编程接口、集中控制”，这三个特点。固然这三个特定很重要，也是SDN存在的价值。但除此之外，伴随着SDN一起成长的还有NFV，即网络功能虚拟化。 SDN出身于斯坦福实验室，算是学术界吧。而NFV出身于工业界，相对而言，NFV是一种技术。 SDN和NFV是可以相互独立存在的，据相关研究表明，二者结合起来的效果更优，但是需要处理的问题也更多。 从大的方面讲，SDN和NFV都提出将软件和硬件分离的概念。但是细化之后： SDN侧重于将设备层面的控制模块分离出来，简化底层设备，进行集中控制，底层设备仅仅只负责数据的转发。目的在于降低网络管理的复杂度、协议部署的成本和灵活、以及网络创新。而NFV则看中将设备中的功能提取出来，通过虚拟化的技术在上层提供虚拟功能模块。也就是，NFV希望能够使用通用的x86体系结构的机器替代底层的各种异构的专用设备，然后通过虚拟化技术，在虚拟层提供不同的功能，允许功能进行组合和分离。 SDN中也存在虚拟化技术，但是和NFV有本质上的区别。SDN虚拟的是设备，而NFV虚拟的是功能，当然NFV也包括对基础设备的虚拟，即NFVI。 目前ETSI组织已经于2015-1完成了对NFV的第一阶段的工作，主要包括对NFV的架构设计，各层之间的接口以及管理。并且计划在未来两年内实现对NFV第二阶段的规划，据ETSI ISG给出的白皮书介绍，第二阶段将主要关注于解决NFV中的互操作性问题（应该是VNF之间的以及与VM之间的通信、协作等关系）。]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌之Percolator模型]]></title>
    <url>%2F2018%2F12%2F15%2F%E8%B0%B7%E6%AD%8C%E4%B9%8BPercolator%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[论文今天读了一篇论文https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf 思考 在谷歌的索引系统中。通过MapReduce将爬取下来的页面弄到Percolator中，该模型提供用户随机访问一个超大的数据库，避免了MapReduce的全局scan。该模型中因为有很多线程并发，所以提供了ACID。 Percolator由一系列observers组成。每个observer可以完成一个任务而且可以为下游的observers指派更多的任务。 Percolator使用于增量处理。 该模型如下图，A Percolator system由这三部分组成。还需要依赖两个服务the timestamp oracle and the lightweight lock service。该模型的事务：Percolator provides cross-row, cross-table transactions with ACID snapshot-isolation semantics. 提出了snapshot isolation。意思如图 这里边还讲了个很有意思的比喻。扫描线程一多可能会导致parallelism的减少，拿公交车来作比喻，公交车一慢，会导致等的乘客过多，从而导致车更慢。该模型中为了解决这个问题，采取了如下做法：当一个线程发现别的线程慢的时候，它选择一个随机的位置进行扫描。 TiDB通过查询知道TiKV 的事务采用的就是是 Percolator 模型，并且做了大量的优化。事务的细节这里不详述，大家可以参考论文。这里只提一点，TiKV 的事务采用乐观锁，事务的执行过程中，不会检测写写冲突，只有在提交过程中，才会做冲突检测，冲突的双方中比较早完成提交的会写入成功，另一方会尝试重新执行整个事务。当业务的写入冲突不严重的情况下，这种模型性能会很好，比如随机更新表中某一行的数据，并且表很大。但是如果业务的写入冲突严重，性能就会很差，举一个极端的例子，就是计数器，多个客户端同时修改少量行，导致冲突严重的，造成大量的无效重试。 Percolator原理比较简单，总体来说就是一个经过优化的二阶段提交的实现，进行了一个二级锁的优化。TiDB 的事务模型沿用了 Percolator 的事务模型。 总体的流程如下：123456789101112131415161718192021读写事务1) 事务提交前，在客户端 buffer 所有的 update/delete 操作。 2) Prewrite 阶段:首先在所有行的写操作中选出一个作为 primary，其他的为 secondaries。PrewritePrimary: 对 primaryRow 写入 L 列(上锁)，L 列中记录本次事务的开始时间戳。写入 L 列前会检查:1. 是否已经有别的客户端已经上锁 (Locking)。2. 是否在本次事务开始时间之后，检查 W 列，是否有更新 [startTs, +Inf) 的写操作已经提交 (Conflict)。在这两种种情况下会返回事务冲突。否则，就成功上锁。将行的内容写入 row 中，时间戳设置为 startTs。将 primaryRow 的锁上好了以后，进行 secondaries 的 prewrite 流程:1. 类似 primaryRow 的上锁流程，只不过锁的内容为事务开始时间及 primaryRow 的 Lock 的信息。2. 检查的事项同 primaryRow 的一致。当锁成功写入后，写入 row，时间戳设置为 startTs。3) 以上 Prewrite 流程任何一步发生错误，都会进行回滚：删除 Lock，删除版本为 startTs 的数据。4) 当 Prewrite 完成以后，进入 Commit 阶段，当前时间戳为 commitTs，且 commitTs&gt; startTs :1. commit primary：写入 W 列新数据，时间戳为 commitTs，内容为 startTs，表明数据的最新版本是 startTs 对应的数据。2. 删除L列。如果 primary row 提交失败的话，全事务回滚，回滚逻辑同 prewrite。如果 commit primary 成功，则可以异步的 commit secondaries, 流程和 commit primary 一致， 失败了也无所谓。事务中的读操作1. 检查该行是否有 L 列，时间戳为 [0, startTs]，如果有，表示目前有其他事务正占用此行，如果这个锁已经超时则尝试清除，否则等待超时或者其他事务主动解锁。注意此时不能直接返回老版本的数据，否则会发生幻读的问题。2. 读取至 startTs 时该行最新的数据，方法是：读取 W 列，时间戳为 [0, startTs], 获取这一列的值，转化成时间戳 t, 然后读取此列于 t 版本的数据内容。由于锁是分两级的，primary 和 seconary，只要 primary 的行锁去掉，就表示该事务已经成功 提交，这样的好处是 secondary 的 commit 是可以异步进行的，只是在异步提交进行的过程中 ，如果此时有读请求，可能会需要做一下锁的清理工作。 初体验TiDB 通过docker-compose来部署，目前为止，所以组件已经准备完毕，如图 123访问集群: mysql -h 127.0.0.1 -P 4000 -u root访问集群 Grafana 监控页面: http://localhost:3000 默认用户名和密码均为 admin。集群数据可视化： http://localhost:8010 效果如图：]]></content>
      <categories>
        <category>TiDB</category>
      </categories>
      <tags>
        <tag>TiDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VM与HOST之间传输文件]]></title>
    <url>%2F2018%2F12%2F12%2FVM%E4%B8%8EHOST%E4%B9%8B%E9%97%B4%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[今天老师有一个需求，是从host向qemu创建的虚拟机中传输文件，调研了几个方法，起初是通过网络传输，但是在新的这个平台上没有搭建网桥等设备，而且想还没有别的其他的方式。经过查询，主要有以下方式： 共享文件夹的方式Docker中也有此方法https://blog.csdn.net/zhongbeida_xue/article/details/80747212?utm_source=blogxgwz9 把数据存到usb设备（可真可假）中https://blog.csdn.net/kingtj/article/details/82952783 总结：qemu-kvm虚拟机与宿主机之间实现文件传输，大概两类方法： 虚拟机与宿主机之间，使用网络来进行文件传输。这个需要先在宿主机上配置网络桥架，在qemu-kvm启动配置网卡就可以实现文件传输。 使用9psetup协议实现虚拟机与宿主机之间文件传输。该方法先要宿主机需要在内核中配置了9p选项，即：12345CONFIG_NET_9P=yCONFIG_net_9P_VIRTIO=yCONFIG_NET_9P_DEBUG=y (可选项)CONFIG_9P_FS=yCONFIG_9P_FS_POSIX_ACL=y 另外，qemu在编译时需要支持ATTR/XATTR。 综上，两类方法配置起来都比较麻烦。其实有一个比较简单的方法123456789101112131415161718在虚拟机环境下，我们可能会遇到在宿主机和客户机之间传输文件的需求，目前有几种方法可以实现这个例如通过9p协议，或者为客户机和宿主机之间搭建一个网络等。这些都太不容易实现，下面我介绍一种简单的方法。1. 使用dd创建一个文件，作为虚拟机和宿主机之间传输桥梁dd if=/dev/zero of=/var/lib/libvirt/images/share.img bs=1M count=3502. 格式化share.img文件mkfs.ext4/var/lib/libvirt/images/share.img3. 在宿主机上创建一个文件夹，mkdir /tmp/sharemount -o loop/var/lib/libvirt/images/share.img /tmp/share这样，在宿主机上把需要传输给虚拟机的文件放到/tmp/share 下即可。4. 启动qemu-kvm虚拟机，可以额外为客户机添加上一块硬盘。-drive file=/var/lib/libvirt/images/share.img,if=virtio5. 在虚拟机中 mount上添加的一块硬盘。即可以获得宿主机上放在/tmp/share文件夹下的文件，具体做法是：通过dmesg的输出找到新挂在的硬盘是什么，然后将硬盘直接mount上来。mount -t ext4 /dev/vdb /mnt/ 当然，该方法虽然简单，但它也有缺点, 宿主机和虚拟机文件传输不能实时传输。如果需要传输新文件，需要重启虚拟机。 有没有其他的方式呢还？待补充。。。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国密算法之SM4]]></title>
    <url>%2F2018%2F12%2F12%2F%E5%9B%BD%E5%AF%86%E7%AE%97%E6%B3%95%E4%B9%8BSM4%2F</url>
    <content type="text"><![CDATA[为什么用SM4加密后文件会略长于明文文件？ 首先了解什么是SM4算法 参考： https://blog.csdn.net/Soul_Programmer_Swh/article/details/80263822 https://www.cnblogs.com/TaiYangXiManYouZhe/p/4317519.html https://blog.csdn.net/cg129054036/article/details/83016958 原因就在于sm4 算法加解密时，采用的是 TCM_ES_SM4_CBC 模式，该模式会填 充加密数据以保证其长度为 16 的整数倍，因此加密后文件会略长于明文文件，解 密后文件长度将恢复。 那么什么是又CBC？在密码学中，分组加密（英语：Block cipher），又称分块加密或块密码，是一种对称密钥算法。它将明文分成多个等长的模块（block），使用确定的算法和对称密钥对每组分别加密解密。分组加密是极其重要的加密协议组成，其中典型的如DES和AES作为美国政府核定的标准加密算法，应用领域从电子邮件加密到银行交易转帐，非常广泛。现代分组加密创建在迭代的思想上产生密文。其思想由克劳德·香农在他1949年的重要论文《保密系统的通信理论》（Communication Theory of Secrecy Systems）中提出，作为一种通过简单操作如替代和排列等以有效改善保密性的方法。[1] 迭代产生的密文在每一轮加密中使用不同的子密钥，而子密钥生成自原始密钥。DES加密在1977年由前美国国家标准局（今“美国国家标准与技术研究所”）颁布，是现代分组加密设计的基础思想。它同样也影响了密码分析的学术进展。 https://zh.wikipedia.org/wiki/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F#%E5%AF%86%E7%A0%81%E5%9D%97%E9%93%BE%E6%8E%A5%EF%BC%88CBC%EF%BC%89 SM9算法 SM9标识密码算法是由国密局发布的一种IBE(Identity-Based Encryption)算法。IBE算法以用户的身份标识作为公钥，不依赖于数字证书。 IBC(基于标示的密码技术) 基于证书的公钥体制在应用中面临诸多问题，特别是证书使用过程的复杂性使得不具备相关知识的普通用户难以驾驭。为了降低公钥系统中密钥管理和使用的复杂性，Shamir在1984[S84]年提出了基于标识的密码技术(Identity-Based Cryptography - IBC)：即用户的标识就可以用做用户的公钥（更加准确地说是用户的公钥可以从用户的标识和系统指定的一个方法计算得出）。 在这种情况下，用户不需要申请和交换证书，从而极大地简化了密码系统管理的复杂性。用户的私钥由系统中的一受信任的第三方（密钥生成中心）使用标识私钥生成算法计算生成。这样的系统具有天然的密码委托功能，适合于有监管的应用环境。 NTLS(下一代安全传输协议)]]></content>
      <categories>
        <category>TrustComputing</category>
      </categories>
      <tags>
        <tag>TrustComputing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker化我的秒杀项目]]></title>
    <url>%2F2018%2F12%2F09%2FDocker%E5%8C%96%E6%88%91%E7%9A%84%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[Docker化秒杀项目 首先构建jar包，因为该秒杀基于maven的，第一开始想把配置文件啥的都放一起，可以用一些eclipse插件啥的，但是后来一想这样不好，因为如果我想改配置的话需要重新构建，所以在网上找了个方法，构建好maven install 之后是这样子的，参考的这篇文章http://https://blog.csdn.net/qq_22857293/article/details/79416165，最后构建之后的结果如图，可以看出第三方依赖，配置文件，资源分离开来： （当把jar包通过Xshell上传文件的时候出现了不能上传的问题，这是因为目标目录没有相应写权限造成的，通过chmod o+w 赋予相应权限即可。） * 启动jar包的命令是java -jar -Dloader.path=.,config,resources,3rd-lib miaosha.jar然后我写了Dockerfile，内容如下：构建镜像 docker build -t sjt157/miaoshaapp:v2 .（注意后边有个.）运行docker容器：docker run -d -p 65534:65510 sjt157/miaoshaapp:v2 Docker化Rabbit1234首先pull官方镜像，Docker pull rabbitmq:3启动docker run -d --name miaosharabbit -p 5672:5672 -p 15672:15672 rabbitmq:3当时启动rabbit容器的时候出现了异常 An unexpected connection driver error occurred的话，执行这个 Docker化Mysql 首先拉取镜像，docker pull mysql:5.7 使用镜像创建容器 docker run -p 3306:3306 --name miaoshaMysql -e MYSQL_ROOT_PASSWORD=123 -d mysql:5.7 进入容器 docker exec -it miaoshaMysql bash 进入mysql -uroot -p 输入 GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123' WITH GRANT OPTION; FLUSH PRIVILEGES; 复制sql文件到容器 docker inspect -f '{{.ID}}' miaoshaMysql docker cp 本地路径 容器长ID:容器路径 我把文件考到了根目录下 docker cp /home/ubuntu16/docker/miaoshaMysql/seckill.sql 561e41a0347d:/ 首先进入mysql 创建数据库 create database miaosha; 在执行mysql -uroot -p miaosha &lt; miaosha.sql命令导入文件 我要把原镜像 重新弄一个我的数据库镜像 docker commit -m "added miaosha.sql" -a "sjt157" 561e41a0347d sjt157/miaoshamysql:v2 运行我自己的镜像 docker run -p 3306:3306 --name miaoshamysql -e MYSQL_ROOT_PASSWORD=123 -d sjt157/miaoshamysql:v2 此处有个疑问？？？为什么在官方mysql镜像上 我做了相应操作，存了文件，执行了命令，只有文件被保存了，但是 我做的其他命令 却没有保存上？？？比如创建数据库表等命令 这是为什么？那如果是用Dockerfile创建的自己的镜像会不会也是这样呢，相关命令不保存？？？还有一个，为什么容器已经是退出状态了，却也不能重名呢？？必须要rm掉吗。因为已经是退出状态了，所以不能kill。 Docker化Redis不用 redis.password=123456这个加密码的配置了，因为默认的官方镜像是没有的。docker pull redis:4（有个疑问。不能制定详细的版本信息吗？？应该可以把）启动redis容器docker run -p 6379:6379 –name miaosharedis -d redis最后可以看到4个容器均运行成功。 下一步工作这样太麻烦了，每次都要手动执行，能不能自动编排呢？利用compose来操作。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack-vm-cannot-ssh]]></title>
    <url>%2F2018%2F12%2F09%2Fopenstack-vm-cannot-ssh%2F</url>
    <content type="text"><![CDATA[云之迷雾 今天发现了一件奇事，过程是这样的，我想SSH一个虚拟机，但是怎么也出不来，排除了防火墙等等一系列原因都无果，结果想到了在VNC界面上查看一下，不看还好，一看吓了自己一跳，为什么在3月份创建虚拟机的时候明明指定的IP是172.21.4.68，但是不知道怎么自己偷摸摸的变成了172.21.4.197。我也不能在现在再改该虚拟机IP，因为按openstack的规定：虚拟机的IP默认都是DHCP分配的，如果要设置固定IP，需要在创建虚拟机时就指定，直接在虚拟机上更改IP是会被过滤的，所以此法无效。 现在的情况就是除了通过在VNC界面查看ip是172.21.4.197 以外 ， 在电科华云界面上 和 通过openstack的命令查看的ip 都是 172.21.4.68 ，也就是说虚拟机的IP是真的改了，但是openstack还未知道。到底是哪的原因呢？按照重启大法重启了两次，发现自己又变成了172.21.4.68的网址，后来左思右想都不对，再仔细一看，原来Bcast的地方变成了172.21.6.255，按道理来讲正常应该为172.21.4.255，为什么会变成172.21.6.255呢？ 首先，我查了一下什么是Bcast：broadcast address 即广播地址。Broadcast Address(广播地址)是专门用于同时向网络中所有工作站进行发送的一个地址。在使用TCP/IP 协议的网络中，主机标识段host ID 为全1 的IP 地址为广播地址，广播的分组传送给host ID段所涉及的所有计算机。例如，对于172.21.4.0（255.255.255.0 ）网段，其广播地址为172.21.4.255 （255 即为2 进制的11111111 ），当发出一个目的地址为172.21.4.255 的分组（封包）时，它将被分发给该网段上的所有计算机。按正常来讲，这些信息都是由DHCP服务器来分配的，那么是不是也就是说可能存在别的DHCP服务器（比如172.21.6.X）扰乱了这个虚拟机的网络，而且按正常来讲，B类私有网址（172.21.4.X）的网络掩码应该是255.255.0.0，现在是255.255.255.0，这样做是为了能多一些子网。多8位掩码，就是多了2的8次方个子网（256个），毕竟学校没有那么多网络资源。在虚拟机正常的情况下我查看了一下该虚拟机上的syslog情况，发现了如下： 可知该虚拟机正常情况下与172.21.4.3这个dhcp服务器进行了 交互，DHCP租约过程就是DHCP客户机动态获取IP地址的过程。DHCP租约过程分为4步：①客户机请求IP（客户机发DHCPDISCOVER广播包）；②服务器响应（服务器发DHCPOFFER广播包）；③客户机选择IP（客户机发DHCPREQUEST广播包）；④服务器确定租约（服务器发DHCPACK/DHCPNAK广播包）。我又查看了一下出问题的这个虚拟机的日志（出问题的时候）发现了问题 可以发现这个出问题的虚拟机早先通过了172.21.4.254进行了DHCP交互，获得了有问题的IP地址，因为这个iP地址是它分配的，所以也ping不通就很正常了，因为172.21.4.254也ping不通，这个是我们学校的网关，还有一个网关是172.21.6.254，可得出结论：172.21.4.254不仅是一个网关还是一个dhcp服务器，还有一张图，如下 172.21.201.1 是一个DHCP服务器也。而且不单单是4网段的会与之交互，连6网段的也会与之交互，难道说172.21.201.1是一个学校总的DHCp服务器？经过查看别的服务器可确定172.21.201.1确实是一个DHCP服务器。是不是可能172.21.4.254是一个中继DHCP服务呢？DHCP服务器是可以分配不同网段的IP地址的，可以通过两个网卡，比如一个网卡可以提供4网段的，一个可以提供6网段的，这样也和日志上的证据对上了。 最后，经过查看一批虚拟机发现所有的都会与172.21.4.3（既有DNS也有DHCP）交互，难道是那个有问题的虚拟机与172.21.4.254，然后再与172.21.201.1 进行DHCP交互，扰乱了正常的应该与172.21.4.3的交互？最后经与云提供商询问，可能就是这个原因 结论 最后的猜想：是不是因为172.21.201.1扰乱了我们的虚拟机，毕竟广播地址是172.21.6.255，现在我有个问题就是Bcast由谁来决定？？？？？]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BloomFilter]]></title>
    <url>%2F2018%2F09%2F14%2FBloomFilter%2F</url>
    <content type="text"><![CDATA[简介BloomFilter（布隆过滤器）是一种可以高效地判断元素是否在某个集合中的算法。 在很多日常场景中，都大量存在着布隆过滤器的应用。例如：检查单词是否拼写正确、网络爬虫的URL去重、黑名单检验，微博中昵称不能重复的检测。在工业界中，Google著名的分布式数据库BigTable也用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的IO次数；Google Chrome浏览器使用BloomFilter来判断一个网站是否为恶意网站。 对于以上场景，可能很多人会说，用HashSet甚至简单的链表、数组做存储，然后判断是否存在不就可以了吗？ 当然，对于少量数据来说，HashSet是很好的选择。但是对于海量数据来说，BloomFilter相比于其他数据结构在空间效率和时间效率方面都有着明显的优势。 但是，布隆过滤器具有一定的误判率，有可能会将本不存在的元素判定为存在。因此，对于那些需要“零错误”的应用场景，布隆过滤器将不太适用。具体的原因将会在第二部分中介绍。 在本文的第二部分，本文将会介绍BloomFilter的基本算法思想；第三部分将会基于Google开源库Guava来讲解BloomFilter的具体实现；在第四部分中，将会介绍一些开源的BloomFilter的扩展，以解决目前BloomFilter的不足。 算法讲述布隆过滤器是基于Hash来实现的，在学习BloomFilter之前，也需要对Hash的原理有基本的了解。个人认为，BloomFilter的总体思想实际上和bitmap很像，但是比bitmap更节省空间，误判率也更低。 BloomFilter的整体思想并不复杂，主要是使用k个Hash函数将元素映射到位向量的k个位置上面，并将这k个位置全部置为1。当查找某元素是否存在时，查找该元素所对应的k位是否全部为1即可说明该元素是否存在。 缺点BloomFilter 由于并不存储元素，而是用位的01来表示元素是否存在，并且很有可能一个位时被多个元素同时使用。所以无法通过将某元素对应的位置为0来删除元素。 幸运的是，目前学术界和工业界都有很多方法扩展已解决以上问题。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#include "bloomfilter.h"#include "hashs.h"//#include "md5.h" #include "crc32.h"//#include "sha1.h"#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#define HASH_FUNC_NUM 8#define BLOOM_SIZE 1000000#define BITSIZE_PER_BLOOM 32#define LIMIT (BLOOM_SIZE * BITSIZE_PER_BLOOM)/* * m=10n, k=8 when e=0.01 (m is bitsize, n is inputnum, k is hash_func num, e is error rate) * here m = BLOOM_SIZE*BITSIZE_PER_BLOOM = 32,000,000 (bits) * so n = m/10 = 3,200,000 (urls) * enough for crawling a website */static int bloom_table[BLOOM_SIZE] = &#123;0&#125;;pthread_mutex_t bt_lock = PTHREAD_MUTEX_INITIALIZER;//static MD5_CTX md5;//static SHA1_CONTEXT sha; static unsigned int encrypt(char *key, unsigned int id)&#123; unsigned int val = 0; switch(id)&#123; case 0: val = times33(key); break; case 1: val = timesnum(key,31); break; case 2: val = aphash(key); break; case 3: val = hash16777619(key); break; case 4: val = mysqlhash(key); break; case 5: //basically multithreads supported val = crc32((unsigned char *)key, strlen(key)); break; case 6: val = timesnum(key,131); break; /* int i; unsigned char decrypt[16]; MD5Init(&amp;md5); MD5Update(&amp;md5, (unsigned char *)key, strlen(key)); MD5Final(&amp;md5, decrypt); for(i = 0; i &lt; 16; i++) val = (val &lt;&lt; 5) + val + decrypt[i]; break; */ case 7: val = timesnum(key,1313); break; /* sha1_init(&amp;sha); sha1_write(&amp;sha, (unsigned char *)key, strlen(key)); sha1_final(&amp;sha); for (i=0; i &lt; 20; i++) val = (val &lt;&lt; 5) + val + sha.buf[i]; break; */ default: // should not be here abort(); &#125; return val;&#125;int search(char *url)&#123; unsigned int h, i, index, pos; int res = 0; pthread_mutex_lock(&amp;bt_lock); for (i = 0; i &lt; HASH_FUNC_NUM; i++) &#123; h = encrypt(url, i); h %= LIMIT; index = h / BITSIZE_PER_BLOOM; pos = h % BITSIZE_PER_BLOOM; if (bloom_table[index] &amp; (0x80000000 &gt;&gt; pos)) res++; else bloom_table[index] |= (0x80000000 &gt;&gt; pos); &#125; pthread_mutex_unlock(&amp;bt_lock); return (res == HASH_FUNC_NUM);&#125;]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux可以Ping通但不能traceroute]]></title>
    <url>%2F2018%2F07%2F10%2FLinux%E5%8F%AF%E4%BB%A5Ping%E9%80%9A%E4%BD%86%E4%B8%8D%E8%83%BDtraceroute%2F</url>
    <content type="text"><![CDATA[今天闲来无事，想弄清楚学校至百度服务器的网络问题，结果不试不知道，一试吓一跳。完全出乎我的意料。我们学校的网关是172.21.6.254,172.21.4.254和172.21.7.254。发现可以ping通学校网关，却不能traceroute。如下图： 这是为什么？查了一下资料： windows的tracert预设是走ICMP协议，而linux的traceroute则预设走UDP协议，若两端点之间的UDP connection被任何firewall挡掉, 那 traceroute 就不行了. 原因好像大概知道了，就是有firewall把udp给挡掉了。解决方法：traceroute -I 加I参数改用ICMP协议。即下图，果然成功了。可以发现，从我的服务器到达百度服务器经过了21跳。 12345678910111213141516171819202122traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets 1 192.168.1.1 (192.168.1.1) 实验室路由器 2 172.21.6.254 (172.21.6.254) 学校网关内接口 3 172.21.200.5 (172.21.200.5) 学校网关外接口 4 172.30.201.6 (172.30.201.6) 本地局域网 5 211.71.94.251 (211.71.94.251) 北京市朝阳区 教育网 6 124.207.38.253 (124.207.38.253) 北京市 鹏博士宽带 7 * * * (有的就是这么设置，便于隐藏) 8 10.10.1.1 (10.10.1.1) 4.997 ms 本地局域网 9 218.241.251.105 (218.241.251.105) 北京市 鹏博士宽带10 218.241.253.241 (218.241.253.241) 北京市 鹏博士宽带11 218.241.245.181 (218.241.245.181) 北京市 鹏博士宽带12 202.99.1.173 (202.99.1.173) 北京市 鹏博士宽带13 * * *14 * * *15 202.106.42.97 (202.106.42.97) 北京市北京市 联通16 61.148.154.97 (61.148.154.97) 北京市 联通17 * * *18 61.148.146.194 (61.148.146.194) 北京市 联通19 61.49.168.98 (61.49.168.98) 北京市 联通20 * * *21 123.125.115.110 (123.125.115.110) 北京市 联通 (百度服务器) 那么我们就来了解一下traceroute的工作原理：Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。前面说到，尽管ping工具也可以进行侦测，但是，因为ip头的限制，ping不能完全的记录下所经过的路由器。所以Traceroute正好就填补了这个缺憾。Traceroute的原理是非常非常的有意思，它受到目的主机的IP后，首先给目的主机发送一个TTL=1（还记得TTL是什么吗？）的UDP(后面就 知道UDP是什么了)数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器ip。从而避开了ip头只能记录有限路由IP的问题。有人要问，我怎么知道UDP到没到达目的主机呢？这就涉及一个技巧的问题，TCP和UDP协议有一个端口号定义，而普通的网络程序只监控少数的几个号码较 小的端口，比如说80,比如说23,等等。而traceroute发送的是端口号&gt;30000(真变态)的UDP报，所以到达目的主机的时候，目的 主机只能发送一个端口不可达的ICMP数据报给主机。主机接到这个报告以后就知道，主机到了，所以，说Traceroute是一个骗子一点也不为过Traceroute程序里面提供了一些很有用的选项，甚至包含了IP选路的选项。 当我以为终于弄懂得时候，我发现还是太年轻了，在windows我又手贱的试了一下，又发现了问题。为什么windows下也能ping通，但不能traceroute呢？ 欲知结果如何，还是待我知道以后。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器不能上网之谜]]></title>
    <url>%2F2018%2F05%2F11%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8D%E8%83%BD%E4%B8%8A%E7%BD%91%E4%B9%8B%E8%B0%9C%2F</url>
    <content type="text"><![CDATA[因为服务器一重启很多配置就要重新配，很麻烦，那么有没有一种方式可以实现开机自启动。当然有了，那就是配置rc.local文件了！ 那什么是rc.local脚本嗯？rc.local脚本是一个Ubuntu开机后会自动执行的脚本，我们可以在该脚本内添加命令行指令。该脚本位于/etc/路径下，需要root权限才能修改。该脚本具体格式如下： 1234567891011121314#!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will "exit 0" on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.exit 0 注意: 一定要将命令添加在exit 0之前。里面可以直接写命令或者执行Shell脚本文件sh。 下面这个是用来开机自启动网络的命令 12345678# add by SongJianTao 2018-5-8# use to config network autoip addr del dev enp11s0 192.168.1.50/24tunctl -t tap0brctl addif be-ex tap0ifconfig tap0 0.0.0.0 promisc up#end by SongJianTao 注意如果不生效的话，可以尝试rc.local文件头部/bin/sh修改为/bin/bash，还可以增加日志输出功能，来查看最终为什么这个脚本不启动的原因，代码如下所示： 12345#logexec 2&gt; /tmp/rc.local.log # send stderr from rc.local to a log file exec 1&gt;&amp;2 # send stdout to the same log file set -x # tell sh to display commands before execution 今天正在奋笔疾书、焦头烂额的写报告，老胡说他要上网，但是服务器怎么也上不去网，查了很多原因也不知道（mmp，原来没出现过这种情况啊），经过层层排查，最后可能是因为交换机长期没有关的的问题，导致不能用（交换机的质量这么差的吗）， 所以直接把网线接在了路由器上，那就要更改配置了，不要直接在/etc/resolve.conf那设置，因为重启会消失，要在/etc/resolvconf/resolv.conf.d/base 这个文件下改，加上nameserver 192.168.1.1 这样就可以了，然后果然可以了，所以这个不能赖我了，要赖交换机！这个锅我不背！]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2F2018%2F04%2F27%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序的基本思想快速排序（Quicksort）是对冒泡排序的一种改进。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 快速排序的三个步骤1.选择基准：在待排序列中，按照某种方式挑出一个元素，作为 “基准”（pivot）；2.分割操作：以该基准在序列中的实际位置，把序列分成两个子序列。此时，在基准左边的元素都比该基准小，在基准右边的元素都比基准大；3.递归地对两个序列进行快速排序，直到序列为空或者只有一个元素； 选择基准元的方式对于分治算法，当每次划分时，算法若都能分成两个等长的子序列时，那么分治算法效率会达到最大。也就是说，基准的选择是很重要的。选择基准的方式决定了两个分割后两个子序列的长度，进而对整个算法的效率产生决定性影响。最理想的方法是，选择的基准恰好能把待排序序列分成两个等长的子序列。1.固定基准元：如果输入序列是随机的，处理时间是可以接受的。如果数组已经有序时，此时的分割就是一个非常不好的分割。因为每次划分只能使待排序序列减一，此时为最坏情况，快速排序沦为冒泡排序，时间复杂度为Θ(n^2)。而且，输入的数据是有序或部分有序的情况是相当常见的。因此，使用第一个元素作为基准元是非常糟糕的，应该立即放弃这种想法。2.随机基准元：这是一种相对安全的策略。由于基准元的位置是随机的，那么产生的分割也不会总是会出现劣质的分割。在整个数组数字全相等时，仍然是最坏情况，时间复杂度是O(n^2）。实际上，随机化快速排序得到理论最坏情况的可能性仅为1/(2^n）。所以随机化快速排序可以对于绝大多数输入数据达到O(nlogn）的期望时间复杂度。3.三数取中:引入的原因：虽然随机选取基准时，减少出现不好分割的几率，但是还是最坏情况下还是O(n^2），要缓解这种情况，就引入了三数取中选取基准。分析：最佳的划分是将待排序的序列分成等长的子序列，最佳的状态我们可以使用序列的中间的值，也就是第N/2个数。可是，这很难算出来，并且会明显减慢快速排序的速度。这样的中值的估计可以通过随机选取三个元素并用它们的中值作为基准元而得到。事实上，随机性并没有多大的帮助，因此一般的做法是使用左端、右端和中心位置上的三个元素的中值作为基准元。显然使用三数中值分割法消除了预排序输入的不好情形，并且减少快排大约5%的比较次数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576 #include&lt;stdio.h&gt; //交换子表的记录，使枢轴记录到位，并返回枢轴所在的位置 int Partition(int array[], int low, int high)&#123; /*三数中值分割法*/ int m = low + (high - low) / 2;//数组中间元素的下标 if (array[low]&gt;array[high]) //保证左端较小 swap(array, low, high); if (array[m] &gt; array[high]) //保证中间较小 swap(array, high, m); if (array[m] &gt; array[low]) swap(array, m, low); //保证左端最小 //此时array[low]已经为整个序列左中右三个关键字的中间值 int pivotkey = array[low]; /*固定基准元 int pivotkey = array[low]; */ /*随机基准元 int randomIndex = rand() % (high - low) + low;//取数组中随机下标 swap(array, randomIndex, low); //与第一个数交换 int pivotkey = array[low]; */ int i = low, j = high; while(i&lt;j) //从表的两端交替向中间扫描,当没有相遇 &#123; while (array[j] &gt;= pivotkey&amp;&amp;i&lt;j)&#123; j--; &#125; while (array[i] &lt;= pivotkey&amp;&amp;i&lt;j)&#123; i++; &#125; if (i&lt;j) &#123; swap(array, i, j); &#125; &#125; //最终将基准数归位 swap(array, low, i); return i; //返回枢轴所在的位置 &#125; void QSort(int array[], int low, int high)&#123; int pivot; if (low&lt;high) &#123; pivot = Partition(array, low, high);//算出枢轴值 QSort(array, low, pivot - 1); //对低子表递归排序 QSort(array, pivot + 1, high); //对高子表递归排序 &#125; &#125; void swap(int array[], int i, int j)&#123; //0∧0=0,0∧1=1,1∧1=0 //i,j为需要交换数值的数组下标 if(i == j) return;//下标相同直接返回 array[i] = array[i]^array[j]; array[j] = array[i]^array[j]; array[i] = array[i]^array[j];&#125;//对array做快速排序 int main()&#123; int array[] = &#123;9, 2, 4, 3, 5, 1, 0, 7, 8, 6&#125;; int i; int n = sizeof(array)/sizeof(int); QSort(array, 0, n - 1); for( i = 0; i &lt; n; i++) printf("%d", array[i]); return 0;&#125; 快速排序的优化对于很小的数组（N&lt;=20）,快速排序不如插入排序好。不仅如此，因为快速排序是递归的，所以这样的情况经常发生。通常的解决办法是对于小的数组不递归的使用快速排序，而代之以诸如插入排序这样的对小数组有效的排序算法。使用这种策略实际上可以节省大约15%的（相对于自始至终使用快速排序时）的运行时间。一种好的截止范围是N=10，虽然在5到20之间任一截止范围都有可能产生类似的结果。下面是代码： 123456789101112 void QSort(int array[], int low, int high)&#123; int pivot; if (high-low+1&gt;=10) &#123; pivot = Partition(array, low, high);//算出枢轴值 QSort(array, low, pivot - 1); //对低子表递归排序 QSort(array, pivot + 1, high); //对高子表递归排序 &#125; else&#123; InsertSort(array+low, high-low+1); //插入排序 &#125; &#125; 插入排序代码： 123456789101112void InsertSort(int array[], int n)&#123;int j;for (int i = 1; i &lt; n;++i)&#123; int key = array[i]; for (j = i; j&gt;0 &amp;&amp; array[j - 1] &gt; key;j--) &#123; array[j] = array[j - 1]; &#125; array[j] = key;&#125;&#125;]]></content>
      <categories>
        <category>Interview</category>
      </categories>
      <tags>
        <tag>InterView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[守护进程]]></title>
    <url>%2F2018%2F04%2F21%2F%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[什么是守护进程 守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是一种很有用的进 程。 Linux的大多数服务器就是用守护进程实现的。比如，Internet服务器inetd，Web服务器httpd等。同时，守护进程完成许多系统任务。 比如，作业规划进程crond，打印进程lpd等。 守护进程最重要的特性是后台运行。在这一点上DOS下的常驻内存程序TSR与之相似。其次，守护进程必须与其运行前的环境隔离开来。这些环 境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩模等。这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下 来的。最后，守护进程的启动方式有其特殊之处。它可以在Linux系统启动时从启动脚本/etc/rc.d中启动，可以由作业规划进程crond启动，还 可以由用户终端（通常是 shell）执行。 一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，所以它是一个由init继承的孤儿进程。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理。实现守护进程要注意的地方 在后台运行为避免挂起控制终端将Daemon放入后台执行。方法是在进程中调用fork使父进程终止，让Daemon在子进程中后台执行。if(pid=fork())exit(0); //是父进程，结束父进程，子进程继续 脱离控制终端，登录会话和进程组 有必要先介绍一下Linux中的进程与控制终端，登录会话和进程组之间的关系：进程属于一个进程组，进程组号（GID）就是进程组长的进程号（PID）。登录会话可以包含多个进程组。这些进程组共享一个控制终端。这个控制终端通常是创建进程的登录终端。 控制终端，登录会话和进程组通常是从父进程继承下来的。我们的目的就是要摆脱它们，使之不受它们的影响。方法是在第1点的基础上，调用setsid()使进程成为会话组长： setsid(); 说明：当进程是会话组长时setsid()调用失败。但第一点已经保证进程不是会话组长。setsid()调用成功后，进程成为新的会话组长和新的进程组长，并与原来的登录会话和进程组脱离。由于会话过程对控制终端的独占性，进程同时与控制终端脱离。 禁止进程重新打开控制终端现在，进程已经成为无终端的会话组长。但它可以重新申请打开一个控制终端。可以通过使进程不再成为会话组长来禁止进程重新打开控制终端： if(pid=fork()) exit(0); //结束第一子进程，第二子进程继续（第二子进程不再是会话组长） 关闭打开的文件描述符 进程从创建它的父进程那里继承了打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。按如下方法关闭它们： for(i=0;i 关闭打开的文件描述符close(i); 改变当前工作目录进程活动时，其工作目录所在的文件系统不能卸下。一般需要将工作目录改变到根目录。对于需要转储核心，写运行日志的进程将工作目录改变到特定目录如 /tmpchdir(“/“) 重设文件创建掩模进程从创建它的父进程那里继承了文件创建掩模。它可能修改守护进程所创建的文件的存取位。为防止这一点，将文件创建掩模清除：umask(0); 处理SIGCHLD信号处理SIGCHLD信号并不是必须的。但对于某些进程，特别是服务器进程往往在请求到来时生成子进程处理请求。如果父进程不等待子进程结 束，子进程将成为僵尸进程（zombie）从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下 可以简单地将 SIGCHLD信号的操作设为SIG_IGN。 signal(SIGCHLD,SIG_IGN); 这样，内核在子进程结束时不会产生僵尸进程。这一点与BSD4不同，BSD4下必须显式等待子进程结束才能释放僵尸进程。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;stdio.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;fcntl.h&gt;int Create_Daemon()&#123; int pid; //屏蔽一些控制终端信号 signal(SIGTTOU,SIG_IGN); signal(SIGTTIN,SIG_IGN); signal(SIGTSTP,SIG_IGN); signal(SIGHUP ,SIG_IGN); //设置文件掩码 umask(0); //调用fork函数，父进程退出 pid = fork(); if(pid &lt; 0 ) &#123; printf("error fork"); return -1; &#125; else if(pid &gt; 0) &#123;//father exit(0); &#125; //设置新会话 setsid(); //处理SIGCHlD信号 signal(SIGCHLD,SIG_IGN); //禁止进程重新打开控制终端 if(pid = fork()) &#123;//father exit(0); &#125; else if(pid &lt;0) &#123; perror("fork"); exit(-1); &#125; //关闭打开的文件描述符 close(0);close(1);close(2); //改变当前的工作目录 chdir("/"); return 0;&#125;int main()&#123; Create_Daemon(); while(1); return 0;&#125; 总结创建过程： 创建子进程，父进程退出。 即创建子进程后，显示退出父进程，造成在终端这一进程已运行完毕的假象。之后的操作都由子进程完成。形式上做到与控制终端脱离。 孤儿进程：父进程先于子进程退出，则称为孤儿进程。系统发现一个孤儿进程后，就自动有1号进程（init进程）收养，即该子进程称为init进程的子进程。 在子进程中创建新会话。 继承：调用fork()函数，子进程会拷贝父进程的所有会话期、进程组、控制终端等。需要重设这些，才使子进程真正的与控制终端脱离。 进程组：一个或多个进程集合。每个进程有进程pid，进程组有组ID。pid和进程组ID都是一个进程的必备属性。每个进程组都有组长进程，其进程号等于进程组ID。当进程组ID不受组长进程退出的影响。 会话期：一个或多个进程组集合。通常，一个会话始于用户登录，终于用户退出，这之间的所有进程都属于该会话期。 setsid：创建新会话，并担任该会话组组长。有3个作用：让进程摆脱原会话的控制让进程摆脱原会话组的控制让进程摆脱原控制终端的控制 改变当前目录为根目录 继承：fork()创建的子进程还拷贝了父进程的当前工作目录。需要重设。 进程运行中，当前目录所在文件系统是不能卸载的，即原工作目录无法卸载。可能造成很多麻烦，如需要进入单用户模式。所以必须重设当前目录。 chdir(“/“)：重设为根目录 重设文件权限掩码 文件权限掩码：屏蔽掉文件权限中的对应位。有个文件权限掩码是050，它就屏蔽了文件组拥有者的可读与可执行权限。 继承：fork()创建的子进程还继承了父进程的文件权限掩码。 umask(0)：重设为0，灵活性更强。 关闭文件描述符 继承：fork()创建的子进程从父进程继承了一些已经打开了的文件。被打开的进程可能永远不会被守护进程使用，却消耗资源。所以必须手动关闭文件描述符为0、1和2 的3个文件（常说的输入、输出和报错）。 守护进程退出处理 可能需要支持用户在外部手动停止守护进程运行，通常使用kill命令。编码实现kill发出的signal信号处理，达到线程正常退出。 创建进程Linux上创建子进程的方式有三种(极其重要的概念)：一种是fork出来的进程，一种是exec出来的进程，一种是clone出来的进程。 fork是复制进程，它会复制当前进程的副本(不考虑写时复制的模式)，以适当的方式将这些资源交给子进程。所以子进程掌握的资源和父进程是一样的，包括内存中的内容，所以也包括环境变量和变量。但父子进程是完全独立的，它们是一个程序的两个实例。 exec是加载另一个应用程序，替代当前运行的进程，也就是说在不创建新进程的情况下加载一个新程序。exec还有一个动作，在进程执行完毕后，退出exec所在环境(实际上是进程直接跳转到exec上，执行完exec就直接退出。而非exec加载程序的方式是：父进程睡眠，然后执行子进程，执行完后回到父进程，所以不会立即退出当前环境)。所以为了保证进程安全，若要形成新的且独立的子进程，都会先fork一份当前进程，然后在fork出来的子进程上调用exec来加载新程序替代该子进程。例如在bash下执行cp命令，会先fork出一个bash，然后再exec加载cp程序覆盖子bash进程变成cp进程。但要注意，fork进程时会复制所有内存页，但使用exec加载新程序时会初始化地址空间，意味着复制动作完全是多余的操作，当然，有了写时复制技术不用过多考虑这个问题。 clone用于实现线程。clone的工作原理和fork相同，但clone出来的新进程不独立于父进程，它只会和父进程共享某些资源，在clone进程的时候，可以指定要共享的是哪些资源。 如何创建一个子进程？每次fork一个进程的时候，虽然调用一次fork()，会分别为两个进程返回两个值：对子进程的返回值为0，对父进程的返回值是子进程的pid。所以，可以使用下面的shell伪代码来描述运行一个ls命令时的过程：123456fpid=`fork()`if [ $fpid = 0 ]&#123; exec(ls) || echo "Can't exec ls" exit&#125;wait($fpid) 假设上面是在shell脚本中执行ls命令，那么fork的是shell脚本进程。fork后，父进程将继续执行，且if语句判断失败，于是执行wait；而子进程执行时将检测到fpid=0，于是执行exec(ls)，当ls执行结束，子进程因为exec的原因将退出。于是父进程的wait等待完成，继续执行后面的代码。 如果在这个shell脚本中某个位置，执行exec命令(exec命令调用的其实就是exec家族函数)，shell脚本进程直接切换到exec命令上，执行完exec命令，就表示进程终止，于是exec命令后面的所有命令都不会再执行。123456789101112131415161718192021222324252627282930313233+--------+| pid=7 || ppid=4 || bash |+--------+ | | calls fork V+--------+ +--------+| pid=7 | forks | pid=22 || ppid=4 | ----------&gt; | ppid=7 || bash | | bash |+--------+ +--------+ | | | waits for pid 22 | calls exec to run ls | V | +--------+ | | pid=22 | | | ppid=7 | | | ls | V +--------++--------+ || pid=7 | | exits| ppid=4 | &lt;---------------+| bash |+--------+ | | continues V一般情况下，兄弟进程之间是相互独立、互不可见的，但有时候通过特殊手段，它们会实现进程间通信。例如管道协调了两边的进程，两边的进程属于同一个进程组，它们的PPID是一样的，管道使得它们可以以&quot;管道&quot;的方式传递数据。进程是有所有者的，也就是它的发起者，某个用户如果它非进程发起者、非父进程发起者、非root用户，那么它无法杀死进程。且杀死父进程(非终端进程)，会导致子进程变成孤儿进程，孤儿进程的父进程总是init/systemd。 进程信号123456789101112131415161718192021222324252627282930313233343536- SIGHUP 数值1 终端退出时，此终端内的进程都将被终止- SIGQUIT 数值2 从键盘输入 Ctrl+&apos;\&apos;可以产生此信号- SIGILL 数值4 非法指令- SIGABRT 数值6 abort调用- SIGSEGV 数值11 非法内存访问- SIGTRAP 数值5 调试程序时使用的断点- SIGINT 2 中断进程，可被捕捉和忽略，几乎等同于sigterm，所以也会尽可能的释放执行clean-up，释放资源，保存状态等(CTRL+C)- SIGQUIT 3 从键盘发出杀死(终止)进程的信号- SIGKILL 9 强制杀死进程，该信号不可被捕捉和忽略，进程收到该信号后不会执行任何clean-up行为，所以资源不会释放，状态不会保存- SIGTERM 15 杀死(终止)进程，可被捕捉和忽略，几乎等同于sigint信号，会尽可能的释放执行clean-up，释放资源，保存状态等- SIGCHLD 17 当子进程中断或退出时，发送该信号告知父进程自己已完成，父进程收到信号将告知内核清理进程列表。所以该信号可以解除僵尸进程，也可以让非正常退出的进程工作得以正常的clean-up，释放资源，保存状态等。 - SIGSTOP 19 该信号是不可被捕捉和忽略的进程停止信息，收到信号后会进入stopped状态- SIGTSTP 20 该信号是可被忽略的进程停止信号(CTRL+Z)- SIGCONT 18 发送此信号使得stopped进程进入running，该信号主要用于jobs，例如bg &amp; fg 都会发送该信号。可以直接发送此信号给stopped进程使其运行起来 - SIGUSR1 10 用户自定义信号1- SIGUSR2 12 用户自定义信号2 其中SIGSEGV应该是我们最常接触的，尤其是使用C/C++程序的同学更是常见。main.c#include &lt;stdio.h&gt;int main()&#123; int *p = NULL; printf(&quot;hello world! \n&quot;); printf(&quot;this will cause core dump p %d&quot;, *p);&#125;使用下面命名编译即可产生运行时触发非法内存访问SIGSEGV信号，其中-g选项是编译添加调试信息，对于gdb调试非常有用。# gcc -g main.c -o test除了上述产生信号的方法外，使用我们经常使用的kill命令可以非常方便的产生这些信号，另外还有gcore命令可以在不终止进程的前提下产生core文件。 参考https://www.cnblogs.com/f-ck-need-u/p/7058920.html#auto_id_0]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之闭包]]></title>
    <url>%2F2018%2F04%2F17%2Fpython%E4%B9%8B%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[无意间，看到这么一道Python面试题：以下代码将输出什么？12345def Fun(): temp = [lambda x:i*x for i in range(4)] return tempfor everyLambda in Fun(): print(everyLambda(2)) 不是0,2,4,6，而是6,6,6,6 Python 的闭包的后期绑定导致的 late binding，这意味着在闭包中的变量是在内部函数被调用的时候被查找。因为在 for 里面 i 的值是不断改写的，但是 lambda 里面只是储存了 i 的符号，调用的时候再查找。所以结果是，当任何 testFun() 返回的函数被调用，在那时，i 的值是在它被调用时的周围作用域中查找，到那时，无论哪个返回的函数被调用，for 循环都已经完成了，i 最后的值是 3，因此，每个返回的函数 testFun 的值都是 3。因此一个等于 2 的值被传递进以上代码，它们将返回一个值 6 （比如： 3 x 2）。 那如何才能是0,2,4,6呢？ 创建一个闭包，通过使用默认参数立即绑定它的参数。为什么你加了默认参数就成功了呢？因为在创建函数的时候就要获取默认参数的值，放到 lambda 的环境中，所以这里相当于存在一个赋值，从而 lambda 函数环境中有了一个独立的 i。 12345 def Fun(): temp = [lambda x,i=i:i*x for i in range(4)] return tempfor everyLambda in Fun(): print(everyLambda(2)) 使用functools.partial 函数，把函数的某些参数（不管有没有默认值）给固定住（也就是相当于设置默认值） 123456 from functools import partialfrom operator import muldef Fun(): return [partial(mul,i) for i in range(4)]for everyLambda in Fun(): print(everyLambda(2)) 用生成器 1234 def Fun(): return (lambda x,i=i:i*x for i in range(4))for everyLambda in Fun(): print(everyLambda(2)) 利用yield的惰性求值的思想 12345 def Fun(): for i in range(4): yield lambda x: i*xfor everyLambda in Fun(): print(everyLambda(2))]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协议的简单C/S程序]]></title>
    <url>%2F2018%2F04%2F15%2F%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8D%95C-S%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[C/S 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#include &lt;string.h&gt; #define MAX_LINE 100 int main(int argc,char **argv)&#123; struct sockaddr_in sin; char buf[MAX_LINE]; int s_fd; int port = 8000; char *str = "test string"; char *serverIP = "127.0.0.1"; int n; if(argc &gt; 1) &#123; str = argv[1]; &#125; //服务器端填充 sockaddr结构 bzero(&amp;sin , sizeof(sin)); sin.sin_family = AF_INET; inet_pton(AF_INET,serverIP,(void *)&amp;sin.sin_addr); sin.sin_port = htons(port); int bReuseaddr=1; struct timeval nNetTimeout=&#123;0,1000&#125;;//1绉? if((s_fd = socket(AF_INET,SOCK_STREAM,0)) == -1) &#123; perror("fail to create socket"); exit(1); &#125; /*if(setsockopt(s_fd,SOL_SOCKET ,SO_REUSEADDR,&amp;bReuseaddr,sizeof(int)) == -1) &#123; perror("fail to set opt reuseaddr"); exit(1); &#125; */ if(setsockopt(s_fd,SOL_SOCKET ,SO_RCVTIMEO,&amp;nNetTimeout,sizeof(nNetTimeout)) == -1) &#123; perror("fail to set opt rcvtimeout"); exit(1); &#125; if(connect(s_fd,(struct sockaddr *)&amp;sin,sizeof(sin)) == -1) &#123; perror("fail to connect server"); exit(1); &#125; n = send(s_fd, str , strlen(str) + 1, 0); if(n == -1) &#123; perror("fail to send"); exit(1); &#125; n = recv(s_fd ,buf , MAX_LINE, 0); if(n == -1) &#123; perror("fail to recv"); exit(1); &#125; printf("the length of str = %s\n" , buf); if(close(s_fd) == -1) &#123; perror("fail to close"); exit(1); &#125; return 0;&#125; server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt; #define INET_ADDR_STR_LEN 1024#define MAX_LINE 100 int main(int argc,char **argv)&#123; struct sockaddr_in sin; struct sockaddr_in cin; int l_fd; int c_fd; socklen_t len; char buf[MAX_LINE]; char addr_p[INET_ADDR_STR_LEN]; int port = 8000; int n; bzero(&amp;sin , sizeof(sin)); sin.sin_family = AF_INET; sin.sin_addr.s_addr = INADDR_ANY; sin.sin_port = htons(port); //参数设置 int bReuseaddr=1; struct timeval nNetTimeout=&#123;0,10000&#125;;//10秒 if((l_fd = socket(AF_INET,SOCK_STREAM,0)) == -1) &#123; perror("fail to create socket"); exit(1); &#125; if(setsockopt(l_fd,SOL_SOCKET ,SO_REUSEADDR,&amp;bReuseaddr,sizeof(int)) == -1) &#123; perror("fail to set opt reuseaddr"); exit(1); &#125; if(setsockopt(l_fd,SOL_SOCKET ,SO_RCVTIMEO,&amp;nNetTimeout,sizeof(nNetTimeout)) == -1) &#123; perror("fail to set opt rcvtimeout"); exit(1); &#125; if(bind(l_fd,(struct sockaddr *)&amp;sin ,sizeof(sin) ) == -1) &#123; perror("fail to bind"); exit(1); &#125; if(listen(l_fd,10) == -1) &#123; perror("fail to listen"); exit(1); &#125; printf("waiting.....\n"); while(1) &#123; //if((c_fd = accept(l_fd,(struct sockaddr *)&amp;cin, &amp;len)) == -1) if((c_fd = accept(l_fd,NULL, 0)) == -1) &#123; // perror("fail to accept"); // exit(1); continue; &#125; n = recv(c_fd , buf, MAX_LINE, 0); if(n == -1) &#123; perror("fail to recv"); exit(1); &#125; else if(n == 0) &#123; printf("the connect has been closed\n"); close(c_fd); continue; &#125; //inet_ntop(AF_INET,&amp;cin.sin_addr,addr_p,sizeof(addr_p)); printf("content is : %s\n",buf); n = strlen(buf); sprintf(buf,"%d",n); n = send(c_fd , buf, sizeof(buf) + 1 , 0); if( n == -1) &#123; perror("fail to send"); exit(1); &#125; if(close(c_fd) == -1) &#123; perror("fail to close"); exit(1); &#125; &#125; if(close(l_fd) == -1) &#123; perror("fail to close"); exit(1); &#125; return 0;&#125; linux下基于简单socket编程实现C/S12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;netinet/in.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt; #define MAX_LINE 1024#define INET_ADDR_STR 16 void my_fun(char *p)&#123; if(p == NULL) &#123; return; &#125; for( ; *p != '\0' ; p++) &#123; if((*p &gt;= 'a') &amp;&amp; (*p &lt;= 'z')) &#123; *p = *p - 32; &#125; &#125; return;&#125;int main(int argc,char **argv)&#123; struct sockaddr_in sin; //服务器通信地址结构 struct sockaddr_in cin; //保存客户端通信地址结构 int l_fd; int c_fd; socklen_t len; char buf[MAX_LINE]; //存储传送内容的缓冲区 char addr_p[INET_ADDR_STR]; //存储客户端地址的缓冲区 int port = 8000; int n; bzero((void *)&amp;sin,sizeof(sin)); sin.sin_family = AF_INET; //使用IPV4通信域 sin.sin_addr.s_addr = INADDR_ANY; //服务器可以接受任意地址 sin.sin_port = htons(port); //端口转换为网络字节序 l_fd = socket(AF_INET,SOCK_STREAM,0); //创建套接子,使用TCP协议 bind(l_fd,(struct sockaddr *)&amp;sin,sizeof(sin)); listen(l_fd,10); //开始监听连接 printf("waiting ....\n"); while(1) &#123; c_fd = accept(l_fd,(struct sockaddr *)&amp;cin,&amp;len); n = read(c_fd,buf,MAX_LINE); //读取客户端发送来的信息 inet_ntop(AF_INET,&amp;cin.sin_addr,addr_p,INET_ADDR_STR); //将客户端传来地址转化为字符串 printf("client IP is %s,port is %d\n",addr_p,ntohs(cin.sin_port)); printf("content is : %s\n", buf); //打印客户端发送过来的数据 my_fun(buf); write(c_fd,buf,n); //转换后发给客户端 close(c_fd); &#125; printf("buf = %s\n",buf); if((close(l_fd)) == -1) &#123; perror("fail to close\n"); exit(1); &#125; return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt;#include &lt;netinet/in.h&gt; #define MAX_LINE 1024 int main(int argc,char **argv)&#123; struct sockaddr_in sin; //服务器的地址 char buf[MAX_LINE]; int sfd; int port = 8000; char *str = "test string"; char *serverIP = "127.0.0.1"; if(argc &gt; 1) &#123; str = argv[1]; //读取用户输入的字符串 &#125; bzero((void *)&amp;sin,sizeof(sin)); sin.sin_family = AF_INET; //使用IPV4地址族 inet_pton(AF_INET,serverIP,(void *)&amp;(sin.sin_addr)); sin.sin_port = htons(port); /*理论上建立socket时是指定协议，应该用PF_xxxx，设置地址时应该用AF_xxxx。当然AF_INET和PF_INET的值是相同的，混用也不会有太大的问题。也就是说你socket时候用PF_xxxx，设置的时候用AF_xxxx也是没关系的，这点随便找个TCPIP例子就可以验证出来了。如下，不论是AF_INET还是PF_INET都是可行的，只不过这样子的话，有点不符合规范。*/ sfd = socket(AF_INET,SOCK_STREAM,0); connect(sfd,(struct sockaddr *)&amp;(sin),sizeof(sin)); printf("str = %s\n" , str); write(sfd , str , strlen(str) + 1); read(sfd , buf , MAX_LINE); printf("recive from server: %s\n" , buf); close(sfd); return 0;&#125;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack中的RPC请求分析]]></title>
    <url>%2F2018%2F04%2F08%2Fopenstack%E4%B8%AD%E7%9A%84RPC%E8%AF%B7%E6%B1%82%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[openstack中的RPC请求分析 首先，什么是RPC请求？我们都知道，rpc就是远程过程调用，是Openstack中一种用来实现跨进程(或者跨机器)的通信机制。Openstack中同项目内(如nova, neutron, cinder…)各服务(service)及通过RPC实现彼此间通信。Openstack中还有另外两种跨进程的通信方式：数据库和Rest API。一般情况下，openstack各个项目之间通过RestAPI接口进行相互访问，而项目内部服务之间则通过RPC请求的方式进行通信。 其他参考官网详细介绍了Openstack RPC中的基本概念及API设计http://https://wiki.openstack.org/wiki/Oslo/Messaging，其实它的rpc的设计参考了Sun RPC的设计，Sun RPC的介绍可以参看http://http://en.wikipedia.org/wiki/Open_Network_Computing_Remote_Procedure_Call这篇文章。 RPC的使用场景 随机调用某server上的一个方法：Invoke Method on One of Multiple Servers这个应该是Openstack中最常用的一种RPC调用，每个方法都会有多个server来提供，client调用时由底层机制选择一个server来处理这个调用请求。像nova-scheduler, nova-conductor都可以以这种多部署方式提供服务。这种场景通过AMQP的topic exchange实现。所有server在binding中为binding key指定一个相同的topic， client在调用时使用这个topic既可实现。 调用某特定server上的一个方法：Invoke Method on a Specific Server 一般Openstack中的各种scheduler会以这种方式调用。通常scheduler都会先选定一个节点，然后调用该节点上的服务。这种场景通过AMQP的topic exchange实现。每个server在binding中为其binding key指定一个自己都有的topic， client在调用时使用这个topic既可实现。 调用所有server上的一个方法：Invoke Method on all of Multiple Servers 这种其实就是一个广播系统。就像开会议，台上的人讲话，台下的人都能听到。Openstack中有些rpcapi.py的某些方法带有fanout=True参数，这些都是让所有server处理某个请求的情况。例子： neutron中所有plugin都会有一个AgentNotifierApi，这个rpc是用来调用安装在compute上的L2 agent。因为存在多个L2 agent(每个compute上都会有)，所以要用广播模式。这种场景通过AMQP的fanout exchange实现。每个server在binding中将其队列绑定到一个fanout exchange， client在调用时指定exchange类型为fanout即可。server和client使用同一个exchange。 rpc.call和rpc.cast的区别： RPC.call：发送请求到消息队列，等待返回最终结果。 RPC.cast：发送请求到消息队列，不需要等待最终返回的结果。其实还有一种rpc调用，也就是RPC.Notifier:发送各类操作消息到队列，不需要等待最终的返回结果。RPC.call、RPC.cast一般用于同一个项目下的服务之间进行的“内部“请求；RPC.Notifier发送的操作消息，目前被ceilometer notification服务所接收。 举个栗子：比如虚拟机创建过程，创建虚拟机等TaskAPI任务，已经由nova-conductor承担，因此nova-api监听到创建虚拟机的HTTP请求后，会通过RPC调用（是cast）nova.conductor.manager.ComputeTaskManager中的build_instance()方法。nova-conductor会在build_instances()中生成request_spec字典，其中包括了详细的虚拟机信息，nova-conductor通过rpc.call方法向nova-scheduler发出请求，nova-scheduler依据这些信息为虚拟机选择一个最佳的主机，然后返回给nova-conductor。（为什么有返回，因为是call）然后nova-conductor再通过nova-compute创建虚拟机。nova-compute首先会使用Resource Tracker的Claim机制检测一下主机的可用资源是否能够满足新建虚拟机的需要，然后通过具体的virt Driver创建虚拟机。]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之intern机制]]></title>
    <url>%2F2018%2F04%2F08%2Fpython%E4%B9%8Bintern%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[python之intern机制(字符串驻留机制) 在主流面向对象的编程语言中intern 机制对于处理字符串已经成为一种标配，通过 intern 机制可以提高字符串的处理效率，当然，解释器内部很对 intern 机制的使用策略是有考究的，有些场景会自动使用 intern ，有些地方需要通过手动方式才能启动。python中如果创建的对象一样，那么就会自动启动intern机制，所有对象会指向同一个地址。先看个栗子：123456a = "helloworld"b = "helloworld"c = "helloworld"print(id(a))print(id(b))print(id(c)) # 三个对象的内存地址一样 其实这就是python的intern机制，这样可以节省内存。看一下源码12345678910111213141516171819202122232425262728293031323334353637static PyObject *interned;void PyString_InternInPlace(PyObject **p)&#123; register PyStringObject *s = (PyStringObject *)(*p); PyObject *t; if (s == NULL || !PyString_Check(s)) Py_FatalError("PyString_InternInPlace: strings only please!"); /* If it's a string subclass, we don't really know what putting it in the interned dict might do. */ if (!PyString_CheckExact(s)) return; if (PyString_CHECK_INTERNED(s)) return; if (interned == NULL) &#123; interned = PyDict_New(); if (interned == NULL) &#123; PyErr_Clear(); /* Don't leave an exception */ return; &#125; &#125; t = PyDict_GetItem(interned, (PyObject *)s); if (t) &#123; Py_INCREF(t); Py_DECREF(*p); *p = t; return; &#125; if (PyDict_SetItem(interned, (PyObject *)s, (PyObject *)s) &lt; 0) &#123; PyErr_Clear(); return; &#125; /* The two references in interned are not counted by refcnt. The string deallocator will take care of this */ Py_REFCNT(s) -= 2; PyString_CHECK_INTERNED(s) = SSTATE_INTERNED_MORTAL;&#125; 可以看到interned的定义是一个PyObject,但从下面的代码可以看出，在interned=nul的时候，interned = PyDict_New();所以它实际上是一个PyDictObject，我们可以暂时理解为c++里面的map对象。对一个PyStringObject对象进行intern机制处理的时候，会通过PyDict_GetItem去从Interned对象中查找有没有一样的已经创建的对象，有的话就直接拿来用，没有的话就说明这种对象是第一次创建，用PyDict_SetItem函数把相应的信息存到interned里面，下次再创建一样的就能从中找到了。 Python解释器会缓冲256个字符串, 第257个字符串多次赋值不同的变量名, id()查看的结果就不同了。 intern机制的优点是。须要值同样的字符串的时候（比方标识符）。直接从池里拿来用。避免频繁的创建和销毁。提升效率，节约内存。缺点是，拼接字符串、对字符串改动之类的影响性能。 由于是不可变的。所以对字符串改动不是inplace操作。要新建对象。 这也是为什么拼接多字符串的时候不建议用+而用join()。join()是先计算出全部字符串的长度，然后一一拷贝，仅仅new一次对象。 须要小心的坑。并非全部的字符串都会採用intern机制。仅仅包括下划线、数字、字母的字符串才会被intern。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之协程]]></title>
    <url>%2F2018%2F04%2F07%2Fpython%E4%B9%8B%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Generator 其中一个特性就是不是一次性生成数据，而是生成一个可迭代的对象，在迭代时，根据我们所写的逻辑来控制其启动时机。 Generator 另一个很大作用可以说就是当做协程使用。协程就是你可以暂停执行的函数。简而言之，协程是比线程更为轻量的一种模型，我们可以自行控制启动与停止的时机。知乎上说的，最易懂的解释：你行你就上，不行旁边等着让别人上，啥时候行了你再上。在 Python 中其实没有专门针对协程的这个概念，社区一般而言直接将 Generator 作为一种特殊的协程看待，想想，我们可以用 next 或 next() 方法或者是 send() 方法唤醒我们的 Generator ，在运行完我们所规定的代码后， Generator 返回并将其所有状态冻结。这是不是很让我们 Excited 呢！！ 总而言之，协程比线程更节省资源，效率更高，并且更安全。如果使用线程做过重要的编程，你就知道写出程序有多么困难，因为调度程序任何时候都能中断线程。必须记住保留锁，去保护程序中的重要部分，防止多步操作在执行的过程中中断，防止数据处于无效状态。而协程默认会做好全方位保护，以防止中断。我们必须显式产出才能让程序的余下部分运行。对协程来说，无需保留锁，在多个线程之间同步操作，协程自身就会同步，因为在任意时刻只有一个协程运行。想交出控制权时，可以使用 yield 或 yield from 把控制权交还调度程序。这就是能够安全地取消协程的原因：按照定义，协程只能在暂停的 yield处取消，因此可以处理 CancelledError 异常，执行清理操作。 这是一个异步编程的例子，将代码与事件循环及其相关的函数一一对应起来。这个例子里包含的几个协程，代表着火箭发射的倒计时，并且看起来是同时开始的。这是通过并发实现的异步编程；3个不同的协程将分别独立运行，并且都在同一个线程内完成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128import datetimeimport heapqimport typesimport timeclass Task: """Represent how long a coroutine should before starting again. Comparison operators are implemented for use by heapq. Two-item tuples unfortunately don't work because when the datetime.datetime instances are equal, comparison falls to the coroutine and they don't implement comparison methods, triggering an exception. Think of this as being like asyncio.Task/curio.Task. """ def __init__(self, wait_until, coro): self.coro = coro self.waiting_until = wait_until def __eq__(self, other): return self.waiting_until == other.waiting_until def __lt__(self, other): return self.waiting_until &lt; other.waiting_untilclass SleepingLoop: """An event loop focused on delaying execution of coroutines. Think of this as being like asyncio.BaseEventLoop/curio.Kernel. """ def __init__(self, *coros): self._new = coros self._waiting = [] def run_until_complete(self): # Start all the coroutines. for coro in self._new: wait_for = coro.send(None) heapq.heappush(self._waiting, Task(wait_for, coro)) # Keep running until there is no more work to do. while self._waiting: now = datetime.datetime.now() # Get the coroutine with the soonest resumption time. task = heapq.heappop(self._waiting) if now &lt; task.waiting_until: # We're ahead of schedule; wait until it's time to resume. delta = task.waiting_until - now time.sleep(delta.total_seconds()) now = datetime.datetime.now() try: # It's time to resume the coroutine. wait_until = task.coro.send(now) heapq.heappush(self._waiting, Task(wait_until, task.coro)) except StopIteration: # The coroutine is done. pass@types.coroutinedef sleep(seconds): """Pause a coroutine for the specified number of seconds. Think of this as being like asyncio.sleep()/curio.sleep(). """ now = datetime.datetime.now() wait_until = now + datetime.timedelta(seconds=seconds) # Make all coroutines on the call stack pause; the need to use `yield` # necessitates this be generator-based and not an async-based coroutine. actual = yield wait_until # Resume the execution stack, sending back how long we actually waited. return actual - nowasync def countdown(label, length, *, delay=0): """Countdown a launch for `length` seconds, waiting `delay` seconds. This is what a user would typically write. """ print(label, 'waiting', delay, 'seconds before starting countdown') delta = await sleep(delay) print(label, 'starting after waiting', delta) while length: print(label, 'T-minus', length) waited = await sleep(1) length -= 1 print(label, 'lift-off!')def main(): """Start the event loop, counting down 3 separate launches. This is what a user would typically write. """ loop = SleepingLoop(countdown('A', 5), countdown('B', 3, delay=2), countdown('C', 4, delay=1)) start = datetime.datetime.now() loop.run_until_complete() print('Total elapsed time is', datetime.datetime.now() - start)if __name__ == '__main__': main()# A waiting 0 seconds before starting countdown#B waiting 2 seconds before starting countdown#C waiting 1 seconds before starting countdown#A starting after waiting 0:00:00.001000#A T-minus 5#C starting after waiting 0:00:01.000058#C T-minus 4#A T-minus 4#B starting after waiting 0:00:02.000115#B T-minus 3#C T-minus 3#A T-minus 3#B T-minus 2#C T-minus 2#A T-minus 2#B T-minus 1#C T-minus 1#A T-minus 1#B lift-off!#C lift-off!#A lift-off!#Total elapsed time is 0:00:05.001286 但是基于async的协程和基于生成器的协程会在对应的暂停表达式上面有所不同？主要原因是出于最优化Python性能的考虑，确保你不会将刚好有同样API的不同对象混为一谈。由于生成器默认实现协程的API，因此很有可能在你希望用协程的时候错用了一个生成器。而由于并不是所有的生成器都可以用在基于协程的控制流中，你需要避免错误地使用生成器。但是由于 Python 并不是静态编译的，它最好也只能在用基于生成器定义的协程时提供运行时检查。这意味着当用types.coroutine时，Python 的编译器将无法判断这个生成器是用作协程还是仅仅是普通的生成器（记住，仅仅因为types.coroutine这一语法的字面意思，并不意味着在此之前没有人做过types = spam的操作），因此编译器只能基于当前的情况生成有着不同限制的操作码。关于基于生成器的协程和async定义的协程之间的差异，我想说明的关键点是只有基于生成器的协程可以真正的暂停执行并强制性返回给事件循环。你可能不了解这些重要的细节，因为通常你调用的像是asyncio.sleep() function 这种事件循环相关的函数，由于事件循环实现他们自己的API，而这些函数会处理这些小的细节。对于我们绝大多数人来说，我们只会跟事件循环打交道，而不需要处理这些细节，因此可以只用async定义的协程。但是如果你和我一样好奇为什么不能在async定义的协程中使用asyncio.sleep()，那么这里的解释应该可以让你顿悟。 Generator迭代的就是通过内建的next（）或next()方法调用内建的send（）方法。 与其它特性一起，PEP 342 为生成器引入了 send() 方法。这让我们不仅可以暂停生成器，而且能够传递值到生成器暂停的地方。还是以我们的 range() 为例，你可以让序列向前或向后跳过几个值。 123456789101112131415161718192021def jumping_range(up_to): """Generator for the sequence of integers from 0 to up_to, exclusive. Sending a value into the generator will shift the sequence by that amount. """ index = 0 while index &lt; up_to: jump = yield index if jump is None: jump = 1 index += jumpif __name__ == '__main__': iterator = jumping_range(5) print(next(iterator)) # 0 print(iterator.send(2)) # 2 print(next(iterator)) # 3 print(iterator.send(-1)) # 2 for x in iterator: print(x) # 3, 4 openstack中就是用了协程模型，利用Python库Eventlet可以产生很多协程，这些协程之间只有在调用到了某些特殊的Eventlet库函数的时候（比如睡眠sleep、IO调用等）才会发生切换。协程的实现主要是在协程休息时把当前的寄存器保存起来，然后重新工作时将其恢复，可以简单的理解为，在单个线程内部有多个栈去保存切换时的线程上下文，因此，协程可以理解为一个线程内的伪并发方式。但是由于Eventlet本身的一些局限性，目前openstack考虑用AsynclIO来代替他。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C之内存对齐]]></title>
    <url>%2F2018%2F04%2F06%2FC%E4%B9%8B%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%2F</url>
    <content type="text"><![CDATA[内存对齐123456789101112131415161718192021222324252627282930313233#include&lt;stdio.h&gt;typedef struct bb&#123; int id; //[0]-[3] 第一个数据成员放在offset为0的地方 double weight;//从该成员的大小的整数倍位置开始存，也就是[8]-[15] float height; //[16]-[19],结构体的总大小必须是内部最大成员的整数倍，不足的补齐，所以补上[20]-[23] &#125;BB;typedef struct aa&#123; char name[2]; //[0]-[1] int id; //[4]-[7] double score; //[8]-[15] short grade; // [16]-[17] 从该成员的大小的整数倍开始存，也就是24 BB b; //[24]-[47] &#125;AA;int main()&#123; AA a; BB b; printf("%d\n",sizeof(a)); printf("%d",sizeof(b)); return 0;&#125;// #pragma pack(1) 不内存对齐 32 16 // #pragma pack(2) 32 16// #pragma pack(4) 36 16// #pragma pack(8) 48 24 如果#pragma pack (n)中指定的n大于结构体中最大成员的size，则其不起作用，结构体仍然按照size最大的成员进行对界。 为什么要进行内存对齐？ 一种提高内存访问速度的策略，cpu在访问未对其的内存需要经过两次内存访问，而经过内存对齐一次就可以了。 平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据，某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常 其实数据在内存中存放时，是否对齐并不重要，重要的是你怎样去访问它。memcpy的实现本身并不简单(你在源码里看到的通过while每次拷贝一个char的只是一个例子，并不是真实的memcpy)，它考虑了是否对齐。当检测到内存是对齐时，memcpy调用合适的指令(比较这里拷贝一个int，就调用LDR)，一次拷贝多个字节，以提高效率。当检测到不对齐时，先调用LDRB遂个字节拷贝，直到对齐部分后再调用合适的指令拷贝。因此，在上面的例子中，它是先调用LDRB的，因为LDRB是按1byte对齐(所有的内存都按这个对齐)，所以不会触发报错。但效率就要慢一点了，毕竟要拷贝几次。内存对齐本身对程序员来说是透明的，即程序员该取变量就取变量，该存就存，编译程序时编译器会把变量按本身的平台进行对齐。况且现在的CPU都很高级，别说服务器，台式机的CPU，ARM 7以上应该也支持内存不对齐访问了。但如果你要写一个内存池(boost的ordered_pool有对齐的例子)，或者使用了reinterpret_cast这种对内存直接进行操作的函数，这方面还是要注意一下，即使CPU支持，效率也会受到影响。 #pragma pack(push,1) #pragma pack(pop)强制把结构体按照1byte对齐。]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网易18实习算法题]]></title>
    <url>%2F2018%2F04%2F02%2F%E7%BD%91%E6%98%9318%E5%AE%9E%E4%B9%A0%E7%AE%97%E6%B3%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.小Q正在给一条长度为n的道路设计路灯安置方案。 为了让问题更简单,小Q把道路视为n个方格,需要照亮的地方用’.’表示, 不需要照亮的障碍物格子用’X’表示。 小Q现在要在道路上设置一些路灯, 对于安置在pos位置的路灯, 这盏路灯可以照亮pos - 1, pos, pos + 1这三个位置。 小Q希望能安置尽量少的路灯照亮所有’.’区域, 希望你能帮他计算一下最少需要多少盏路灯。123456789101112131415161718192021222324252627 # 算法思路 # x的位置也是可以放置路灯的 其实是贪心 #遍历路灯字符串，遇见“.”，就给计数器+1，然后往后挪 三个位置。如果遇到“X”，就直接往后挪一个位置。 #编程思路 #路灯个数放入数组n中，路灯对应的字符串放入数组#lantern中，要放路灯的个数放入lantern_count中。这三#个数组是一一对应的。双重循环来遍历lantern中的字符#串，如果遇到“.”，对应的lantern_count+=1，j+=3(挪三#个位置)。如果遇到“X”，j+=1(挪一个位置)。if __name__ =='__main__': count = int(input()) # 测试用例个数 n = [] lantern = [] for i in range(count): n_tmp = int(input()) # 路灯个数 n.append(n_tmp) lantern_tmp = input() # 路灯分布字符串 lantern.append(lantern_tmp) # ['.x.', '...xxx...xx'] lantern_count = [0 for i in range(count)] # [0, 0] for i in range(len(lantern)): j = 0 while (j &lt; len(lantern[i])): if lantern[i][j] == '.': j += 3 lantern_count[i] +=1 else: j += 1 print(lantern_count[0]) for i in range(len(lantern_count)-1): print(lantern_count[i+1]) 牛牛去犇犇老师家补课，出门的时候面向北方，但是现在他迷路了。虽然他手里有一张地图，但是他需要知道自己面向哪个方向，请你帮帮他。输入描述:每个输入包含一个测试用例。每个测试用例的第一行包含一个正整数，表示转方向的次数N(N&lt;=1000)。接下来的一行包含一个长度为N的字符串，由L和R组成，L表示向左转，R表示向右转。 1234567891011 # 比如输入3 LRL 输出Wn = input()m = input()dict1 = &#123;'1':'E','2':'S','3':'W','0':'N'&#125;init = 0for i in range(int(n)): if m[i]=='L': init-=1 else: init+=1print(dict1[str(init%4)]) # -1%4是3 牛牛总是睡过头，所以他定了很多闹钟，只有在闹钟响的时候他才会醒过来并且决定起不起床。从他起床算起他需要X分钟到达教室，上课时间为当天的A时B分，请问他最晚可以什么时间起床输入描述:每个输入包含一个测试用例。每个测试用例的第一行包含一个正整数，表示闹钟的数量N(N&lt;=100)。接下来的N行每行包含两个整数，表示这个闹钟响起的时间为Hi(0&lt;=A&lt;24)时Mi(0&lt;=B&lt;60)分。接下来的一行包含一个整数，表示从起床算起他需要X(0&lt;=X&lt;=100)分钟到达教室。接下来的一行包含两个整数，表示上课时间为A(0&lt;=A&lt;24)时B(0&lt;=B&lt;60)分。数据保证至少有一个闹钟可以让牛牛及时到达教室。 1234567891011121314151617181920# 3# 5 0# 6 0# 7 0# 59 # 6 59import sysif __name__ =='__main__': n = int(sys.stdin.readline().strip()) values= [] for i in range(n): line = sys.stdin.readline().strip().split(' ') values.append(line) # [['5', '0'], ['6', '0'], ['7', '0']] dst_time = int(sys.stdin.readline().strip()) class_time = sys.stdin.readline().strip().split(' ') b = list(map(lambda x :int(x[0])*60+int(x[1]), values)) deadline = int(class_time[0]) * 60 + int(class_time[1]) - dst_time c = [n for n in b if n &lt;= deadline ] print((str(max(c)//60)) + ' ' + str(max(c)%60)) # 输出6 0]]></content>
      <categories>
        <category>InterView</category>
      </categories>
      <tags>
        <tag>InterView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python知识点（21-30）]]></title>
    <url>%2F2018%2F04%2F01%2FPython%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%8821-30%EF%BC%89%2F</url>
    <content type="text"><![CDATA[super函数 123456789101112131415class T(object): a = 0class A(T): passclass B(T): a = 2class D(T): a = 3class C(A, D, B): passc = C()print(super(C, c).a) # c继承的哪个值是根据MRO顺序来的，按照广度优先，根据ADB的顺序找到第一个定义a的类# 然后就是它，所以super(C,c).a 是3print(c.a) 在循环中获取索引 1234# 在循环中获取索引(数组下标),用enumerateints = [8, 23, 45 ,12, 78]for idx, val in enumerate(ints): print(idx, val) 如何移除换行符?&#39;test string\n&#39;.rstrip() 合并列表中的列表,一共有三种方法，用列表推导式最快 原因：当有L个子串的时候用+(即sum)的时间复杂度是O(L2)–每次迭代的时候作为中间结果的列表的长度就会越来越长,而且前一个中间结果的所有项都会再拷贝一遍给下一个中间结果.所以当你的列表l含有L个字串:l列表的第一项需要拷贝L-1次,而第二项要拷贝L-2次,以此类推;所以总数为I * (L2)/2.列表推导式(list comprehension)只是生成一个列表,每次运行只拷贝一次(从开始的地方拷贝到最终结果). 123456$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' '[item for sublist in l for item in sublist]'10000 loops, best of 3: 143 usec per loop$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'sum(l, [])'1000 loops, best of 3: 969 usec per loop$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'reduce(lambda x,y: x+y,l)'1000 loops, best of 3: 1.1 msec per loop 反转字符串 &#39;hello world&#39;[::-1] 通常每一个实例x都会有一个dict属性，用来记录实例中所有的属性和方法，也是通过这个字典，可以让实例绑定任意的属性。而slots属性作用就是，当类C有比较少的变量，而且拥有slots属性时，类C的实例 就没有dict属性，而是把变量的值存在一个固定的地方。如果试图访问一个slots中没有的属性，实例就会报错。这样操作有什么好处呢？slots属性虽然令实例失去了绑定任意属性的便利，但是因为每一个实例没有dict属性，却能有效节省每一个实例的内存消耗，有利于生成小而精干的实例。 为什么需要这样的设计呢？在一个实际的企业级应用中，当一个类生成上百万个实例时，即使一个实例节省几十个字节都可以节省一大笔内存，这种情况就值得使用slots属性。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python知识点（11-20）]]></title>
    <url>%2F2018%2F03%2F31%2FPython%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%8811-20%EF%BC%89%2F</url>
    <content type="text"><![CDATA[new和init的区别 new是一个静态方法,而init是一个实例方法. new方法会返回一个创建的实例,而init什么都不返回. 只有在new返回一个cls的实例时后面的init才能被调用. 当创建一个新实例时调用new,初始化一个实例时用init. metaclass是创建类时起作用.所以我们可以分别使用metaclass,new和init来分别在类创建,实例创建和实例初始化的时候做一些小手脚. 单例模式的四种方式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 使用__new__方法class Singleton(object): @staticmethod def __new__(cls, *args, **kwargs): if not hasattr(cls, '_instance'): # 若还没有实例 orig = super(Singleton, cls) cls._instance = orig.__new__(cls, *args, **kwargs) # 创建一个实例 return cls._instance # 返回一个实例class MyClass(Singleton): a = 1# 共享属性 创建实例时把所有实例的__dict_ #_指向同一个字典,这样它们具有相同的属性和方法.class Borg(object): _state = &#123;&#125; def __new__(cls, *args, **kwargs): ob = super(Borg, cls).__new__(cls, *args, **kwargs) ob.__dict__ = cls._state return obclass MyClass2(Borg): a = 1# 装饰器版本def singleton(cls, *args, **kwargs): instance = &#123;&#125; def getinstance(): if cls not in instance: instance[cls] = cls(*args, **kwargs) return instance[cls] return getinstance@singleton()class MyClass: pass# import方法# mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton()# to usefrom mysingleton import my_singletonmy_singleton.foo() Python中的作用域: 当 Python 遇到一个变量的话他会按照这样的顺序进行搜索：本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in） Lambda 表达式:你在某处就真的只需要一个能做一件事情的函数而已，连它叫什么名字都无关紧要。Lambda 表达式就可以用来做这件事。 123456789a=map(lambda x: x*x, [y for y in range(10)])print(list(a))# 这样写不如Lambda，因为有污染环境的函数sqdef sq(x): return x*xa=map(sq, [y for y in range(10)])print(list(a)) 我们习以为常的复制就是深复制，即将被复制对象完全再复制一遍作为独立的新个体单独存在。而浅复制并不会产生一个独立的对象单独存在。 1234567891011121314151617181920212223# 对于普通对象深浅复制一样，而对于下面这样的复杂对象就不同了# 就是列表里嵌套列表import copya = [1, 2, 3, 4, ['a', 'b']]b = a # 赋值，传对象的引用c = copy.copy(a) # 浅拷贝 对于['a','b']只是引用#在浅拷贝中对于子对象，python会把它当作一个公共镜像存储起来，所有对他的复制都被当成一个引用d = copy.deepcopy(a) # 深拷贝print(a is b) # a和b是同一个objectprint(a is c) # 也不是同一个objectprint(a is d) # 可以发现a和d并不是一个objecta.append(5) # 修改对象aa[4].append('c')print(b)print(c)print(d)TrueFalseFalse[1, 2, 3, 4, ['a', 'b', 'c'], 5][1, 2, 3, 4, ['a', 'b', 'c']][1, 2, 3, 4, ['a', 'b']] Python垃圾回收机制Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。1 引用计数PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.引用计数为0时，该对象生命就结束了。优点:简单 实时性缺点:维护引用计数消耗资源 循环引用2 标记-清除机制基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。3 分代技术分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。Python默认定义了三代对象集合，索引数越大，对象存活时间越长。举例：当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去，而新分配的内存都划分到集合B中去。当垃圾收集开始工作时，大多数情况都只对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制需要处理的内存少了，效率自然就提高了。在这个过程中，集合B中的某些内存块由于存活时间长而会被转移到集合A中，当然，集合A中实际上也存在一些垃圾，这些垃圾的回收会因为这种分代的机制而被延迟。 read,readline和readlines read 读取整个文件 readline 读取下一行,使用生成器方法 readlines 读取整个文件到一个迭代器以供我们遍历 生成器 1234567891011121314151617181920212223# 所有你可以用在for...in...语句中的都是可迭代的:比如lists,strings,files...# 因为这些可迭代的对象你可以随意的读取所以非常方便易用,# 但是你必须把它们的值放到内存里,当它们有很多值时就会消耗太多的内存.mylist = [x*x for x in range(3)]for i in mylist: print(i)# 生成器也是迭代器的一种,但是你只能迭代它们一次.原因很简单,因为它们不是# 全部存在内存里,它们只在要调用的时候在内存里生成:# 生成器和迭代器的区别就是用()代替[],还有你不能用for i in mygenerator第二次# 调用生成器:首先计算0,然后会在内存里丢掉0去计算1,直到计算完4.mygenerator = (x*x for x in range(3) )for i in mygenerator: print(i)# 当你的函数要返回一个非常大的集合并且你希望只读一次的话,那么用下面的这个就非常的方便了.def createGenerator(): mlist = range(3) for i in mlist: yield i*i # 函数运行并没有碰到yeild语句就认为生成器已经为空了. # 原因有可能是循环结束或者没有满足if/else之类的.mgenerator = createGenerator()for i in mgenerator: print(i) Python中调用外部命令 12345678910# 这是一个简单的对于给定目录下的目录tar的脚本，有坑！注意输入空格这样的sehll字符！！！！#!/usr/bin/env python# a python script to auto backup a directory file by SJTimport osDirectory=raw_input("Please enter directory you want to backup:")dirs=os.listdir(Directory)for filename in dirs: fulldirfile=os.path.join(Directory,filename) if os.path.isdir(fulldirfile): os.system("tar -czvf "+fulldirfile+".tar.gz "+ fulldirfile) 对字典进行排序是不可能的,只有把字典转换成另一种方式才能排序.字典本身是无序的,但是像列表元组等其他类型是有序的.所以你需要用一个元组列表来表示排序的字典. 12345678import operatorx = &#123;1:2, 3:4, 4:3, 2:1, 0:0&#125;sorted_x_by_value = sorted(x.items(), key=operator.itemgetter(1))print(sorted_x_by_value)# 结果为[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]sorted_x_by_key = sorted(x.items(), key=operator.itemgetter(0))print(sorted_x_by_key)# 结果为[(0, 0), (1, 2), (2, 1), (3, 4), (4, 3)]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python知识点（1-10）]]></title>
    <url>%2F2018%2F03%2F30%2FPython%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%881-10%EF%BC%89%2F</url>
    <content type="text"><![CDATA[python知识点 在python中，strings, tuples, 和numbers是不可更改的对象，而list,dict等则是可以修改的对象。当一个引用传递给函数的时候,函数自动复制一份引用,这个函数里的引用和外边的引用没有半毛关系了.所以第一个例子里函数把引用指向了一个不可变对象,当函数返回的时候,外面的引用没半毛感觉.而第二个例子就不一样了,函数内的引用指向的是可变对象,对它的操作就和定位了指针地址一样,在内存里进行修改. 1234567891011121314151617181920212223a = 1b = []c = [] #If you pass an immutable object to a method, you still can't rebind #the outer reference, and you can't even mutate the object.def fun(a): a = 2 #If you pass a mutable object into a method, #the method gets a reference to that same object #and you can mutate itdef fun2(b): b.append(1) #if you rebind the reference in the method, the outer scope #will know nothing about it, and after you're done, #the outer reference will still point at the original object.def fun3(c): c = [1]fun(a)fun2(b)fun3(c)print(a) #1print(b) #[1]print(c) #[] 元类（metaclass），经常用在ORM这种复杂的结构！参考深刻理解Python中的元类(metaclass) 在类里每次定义方法的时候都需要绑定这个实例,就是foo(self, x),为什么要这么做呢?因为实例方法的调用离不开实例,我们需要把实例自己传给函数,调用的时候是这样的a.foo(x)(其实是foo(a, x)).类方法一样,只不过它传递的是类而不是实例,A.class_foo(x).注意这里的self和cls可以替换别的参数,但是python的约定是这俩,还是不要改的好. 1234567891011121314151617181920212223242526272829303132x = 1def foo(x): print("executing foo(%s)" % (x))class A(object): # self和cls是对类或者实例的绑定 def foo(self, x): print("executing foo(%s,%s)" % (self, x)) @classmethod def class_foo(cls, x): print("executing class_foo(%s,%s)" % (cls, x)) @staticmethod def static_foo(x): print("executing static_foo(%s)" % x)a = A()# 普通方法的调用foo(x)# 实例方法的调用a.foo(x)# 类方法的调用a.class_foo(x)A.class_foo(x)# 静态方法的调用a.static_foo(x) A.static_foo(x) # 程序结果为：executing foo(1)executing foo(&lt;__main__.A object at 0x0000000002A5A518&gt;,1)executing class_foo(&lt;class '__main__.A'&gt;,1)executing class_foo(&lt;class '__main__.A'&gt;,1)executing static_foo(1)executing static_foo(1) 类变量和实例变量:类变量就是供类使用的变量,实例变量就是供实例使用的.这里p1.name=”bbb”是实例调用了类变量,这其实和上面第一个问题一样,就是函数传参的问题,p1.name一开始是指向的类变量name=”aaa”,但是在实例的作用域里把类变量的引用改变了,就变成了一个实例变量,self.name不再引用Person的类变量name了. 12345678910 class Person: name="aaa" p1=Person()p2=Person()p1.name="bbb"print p1.name # bbbprint p2.name # aaaprint Person.name # aaa 类变量就是供类使用的变量,实例变量就是供实例使用的. 这里p1.name=”bbb”是实例调用了类变量,这其实和上面第一个问题一样,就是函数传参的问题,p1.name一开始是指向的类变量name=”aaa”,但是在实例的作用域里把类变量的引用改变了,就变成了一个实例变量,self.name不再引用Person的类变量name了. 可以看看下面的例子: 123456789 class Person: name=[] p1=Person()p2=Person()p1.name.append(1)print p1.name # [1]print p2.name # [1]print Person.name # [1] Python自省自省就是面向对象的语言所写的程序在运行时,所能知道对象的类型.简单一句就是运行时能够获得对象的类型.比如type(),dir(),getattr(),hasattr(),isinstance(). python共有三种推导式，那什么是推导式呢？推导式是可以从一个数据序列构建另一个新的数据序列的结构体。 12345678910111213141516171819202122232425262728293031323334353637383940 # 列表推导式multiples = [i for i in range(30) if i % 3 is 0]print(multiples)# Output: [0, 3, 6, 9, 12, 15, 18, 21, 24, 27]def squared(x): return x*xmultiples = [squared(i) for i in range(30) if i % 3 is 0]print multiples# Output: [0, 9, 36, 81, 144, 225, 324, 441, 576, 729]# 将俩表推导式的[]改成()即可得到生成器。multiples = (i for i in range(30) if i % 3 is 0)print(type(multiples))# Output: &lt;type 'generator'&gt; # 字典推导式 # 字典推导和列表推导的使用方法是类似的，只不中括号该改成大括号。直接举例说明： # 通过把key大小写合并 合并值mcase = &#123;'a': 10, 'b': 34, 'A': 7, 'Z': 3&#125;mcase_frequency = &#123; k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) for k in mcase.keys() if k.lower() in ['a','b']&#125;print(mcase_frequency)# Output: &#123;'a': 17, 'b': 34&#125; # 快速更换key和valuemcase = &#123;'a': 10, 'b': 34, 'c': 30&#125;mcase_frequency = &#123;v: k for k, v in mcase.items()&#125;print(mcase_frequency)# Output: &#123;10: 'a', 34: 'b'&#125; # 集合推导式squared = &#123;x**2 for x in [1, 1, 2]&#125;print(squared)# Output: set([1, 4]) 单下划线和双下划线首先是单下划线开头，这个被常用于模块中，在一个模块中以单下划线开头的变量和函数被默认当作内部函数，如果使用 from a_module import * 导入时，这部分变量和函数不会被导入。不过值得注意的是，如果使用 import a_module 这样导入模块，仍然可以用 a_module._some_var 这样的形式访问到这样的对象。在 Python 的官方推荐的代码样式中，还有一种单下划线结尾的样式，这在解析时并没有特别的含义，但通常用于和 Python 关键词区分开来，比如如果我们需要一个变量叫做 class，但 class 是 Python 的关键词，就可以以单下划线结尾写作 class_。双下划线开头的命名形式在 Python 的类成员中使用表示名字改编 (Name Mangling)，即如果有一 Test 类里有一成员 x，那么 dir(Test) 时会看到 _Testx 而非 x。这是为了避免该成员的名称与子类中的名称冲突。但要注意这要求该名称末尾没有下划线。双下划线开头双下划线结尾的是一些 Python 的“魔术”对象，如类成员的 init__、del、add、getitem 等，以及全局的 file、name 等。 Python 官方推荐永远不要将这样的命名方式应用于自己的变量或函数，而是按照文档说明来使用。另外单下划线开头还有一种一般不会用到的情况在于使用一个 C 编写的扩展库有时会用下划线开头命名，然后使用一个去掉下划线的 Python 模块进行包装。如 struct 这个模块实际上是 C 模块 _struct 的一个 Python 包装。 12345678910111213141516171819class MyClass(): def __init__(self): self.__superprivate = "Hello" self._semiprivate = ",World！"class OtherClass(MyClass): def __init__(self): self.__superprivate = "hhaaa" self.b = "ssss"mc = MyClass()oc = OtherClass()print(mc._semiprivate) # 只有mc能访问该私有变量print(mc.__dict__)print(oc.__dict__)# print(oc.__superprivate) # 访问不了，提示没有该属性print(oc._OtherClass__superprivate) # 这样就可以访问# ,World！#&#123;'_MyClass__superprivate': 'Hello', #'_semiprivate': ',World！'&#125;#&#123;'b': 'ssss', '_OtherClass__superprivate': #'hhaaa'&#125;#hhaaa 当你不确定你的函数里将要传递多少参数时你可以用*args **kwargs允许你使用没有事先定义的参数名 面向切面编程AOP和装饰器装饰器是一个很著名的设计模式，经常被用于有切面需求的场景，较为经典的有插入日志、性能测试、事务处理等。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量函数中与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 12345678910# 字体变粗装饰器def makebold(fn): # 装饰器将返回新的函数 def warpper(): return "&lt;b&gt;"+ fn() + "&lt;/b&gt;" return warpper@makebolddef say(): return "hello"print(say()) # &lt;b&gt;hello&lt;/b&gt; 函数重载主要是为了解决两个问题。可变参数类型。可变参数个数。一个基本的设计原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果两个函数的功能其实不同，那么不应当使用重载，而应当使用一个名字不同的函数。但是因为python可以接受任何类型的参数、和任何数量的参数，所以不需要重载。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的eval函数]]></title>
    <url>%2F2018%2F03%2F29%2Fpython%E4%B8%AD%E7%9A%84eval%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[python中的eval() 这个函数意义在哪？在编译语言里要动态地产生代码，基本上是不可能的，但动态语言是可以，意味着软件已经部署到服务器上了，但只要作很少的更改，只好直接修改这部分的代码，就可立即实现变化，不用整个软件重新加载。 先举个栗子：123a = 1g = &#123;&apos;a&apos;: 20&#125;print(eval(&quot;a+1&quot;, g)) #返回21 再举个栗子1234567891011121314151617# test eval() and locals()x = 1y = 1num1 = eval(&quot;x+y&quot;)print(num1)def g():x = 2y = 2num3 = eval(&quot;x+y&quot;)print(num3)num2 = eval(&quot;x+y&quot;, globals()) # 搜全局num4 = eval(&quot;x+y&quot;,globals(),locals()) # 先搜索局部，搜索到停止print(num2)print(num4)g() # 值依次为2 4 2 4 eval在字符串对象和list、dictinoary、tuple对象之间互相转换123456789def evala(): l = &apos;[1,2,3,4,[5,6,7,8,9]]&apos; d = &quot;&#123;&apos;a&apos;:123,&apos;b&apos;:456,&apos;c&apos;:789&#125;&quot; t = &apos;([1,3,5],[5,6,7,8,9],[123,456,789])&apos; print(type(l), type(eval(l))) print(type(d), type(eval(d))) print(type(t), type(eval(t)))evala() 结果为：123&lt;class &apos;str&apos;&gt; &lt;class &apos;list&apos;&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;dict&apos;&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;tuple&apos;&gt; locals()对象的值不能修改，globals()对象的值可以修改 1234567891011#test globals() and locals()z=0def f(): z = 1 print (locals()) locals()[&quot;z&quot;] = 2 print (locals()) f() globals()[&quot;z&quot;] = 2print (z) # 结果为&#123;&apos;z&apos;: 1&#125; &#123;&apos;z&apos;: 1&#125; 2 eval有安全性问题,比如用户恶意输入就会获得当前目录文件eval(&quot;__import__(&#39;os&#39;).system(&#39;dir&#39;)&quot;) 怎么避免安全问题？ 自行写检查函数； 使用ast.literal_eval tipsif __name__ == &quot;__main__&quot;: 第一开始不是很理解，今天经过学习知道了这句代码的作用。是编写私有化部分 ，这句代码以上的部分，可以被其它的调用，以下的部分只有这个文件自己可以看见，如果文件被调用了，其他人是无法看见私有化部分的。比如进行单元测试的时候会用到！他的原理是每个py文件都有name属性，如果当前属性和main一样，则值为真，否则为假，就不执行！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python多线程]]></title>
    <url>%2F2018%2F03%2F29%2Fpython%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[python多线程（假多线程） 如果你的代码是IO密集型，多线程可以明显提高效率。例如制作爬虫（我就不明白为什么Python总和爬虫联系在一起…不过也只想起来这个例子…），绝大多数时间爬虫是在等待socket返回数据。这个时候C代码里是有release GIL的，最终结果是某个线程等待IO的时候其他线程可以继续执行。如果你的代码是CPU密集型，多个线程的代码很有可能是线性执行的。所以这种情况下多线程是鸡肋，效率可能还不如单线程因为有context switch 一般网络传输类应用都是IO密集型，读写硬盘操作多也算是IO密集型 我们都知道，比方我有一个4核的CPU，那么这样一来，在单位时间内每个核只能跑一个线程，然后时间片轮转切换。但是Python不一样，它不管你有几个核，单位时间多个核只能跑一个线程，然后时间片轮转。看起来很不可思议？但是这就是GIL搞的鬼。任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。（Java中的多线程是可以利用多核的，这是真正的多线程！） 在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192 # 直接调用函数的多线程from threading import Threadimport timedef loop(name, seconds): print('start loop', name, 'at:', time.ctime()) time.sleep(1) print('end loop', name, 'at:', time.ctime())if __name__ == '__main__': loops = [2, 4] nloops = range(len(loops)) threads = [] print('start at:', time.ctime()) for i in nloops: t = Thread(target=loop, args=(i, loops[i],)) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print('all done at:', time.ctime()) # 使用可调用的类对象from threading import Threadimport timedef loop(name, seconds): print('start loop', name, 'at:', time.ctime()) time.sleep(1) print('end loop', name, 'at:', time.ctime())class ThreadFunc(object): def __init__(self, func, args, name=''): self.name = name self.func = func self.args = args def __call__(self): # 需要定义一个特殊的方法__call__ self.func(*self.args)if __name__ == '__main__': loops = [2, 4] nloops = range(len(loops)) threads = [] print('start at:', time.ctime()) for i in nloops: t = Thread(target=ThreadFunc(loop, (i, loops[i]), loop.__name__)) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print('all done at:', time.ctime())# 继承Thread类，也就是子类化from threading import Threadimport timedef loop(name, seconds): print('start loop', name, 'at:', time.ctime()) time.sleep(1) print('end loop', name, 'at:', time.ctime())class ThreadFunc(Thread): def __init__(self, func, args, name=''): super(ThreadFunc, self).__init__() self.name = name self.func = func self.args = args # 将上种方式中可调用的方法改为run方法，其实就是对Thread类中run方法的重写 def run(self): self.func(*self.args)if __name__ == '__main__': loops = [2, 4] nloops = range(len(loops)) threads = [] print('start at:', time.ctime()) for i in nloops: t = ThreadFunc(loop, (i, loops[i]), loop.__name__) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print('all done at:', time.ctime()) # 在一般推荐的方法中，我们用最后一种方式 线程同步如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。使用Thread对象的Lock和Rlock可以实现简单的线程同步，这两个对象都有acquire方法和release方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。如下：多线程的优势在于可以同时运行多个任务（至少感觉起来是这样）。但是当线程需要共享数据时，可能存在数据不同步的问题。考虑这样一种情况：一个列表里所有元素都是0，线程”set”从后向前把所有元素改成1，而线程”print”负责从前往后读取列表并打印。那么，可能线程”set”开始改的时候，线程”print”便来打印列表了，输出就成了一半0一半1，这就是数据的不同步。为了避免这种情况，引入了锁的概念。锁有两种状态——锁定和未锁定。每当一个线程比如”set”要访问共享数据时，必须先获得锁定；如果已经有别的线程比如”print”获得锁定了，那么就让线程”set”暂停，也就是同步阻塞；等到线程”print”访问完毕，释放锁以后，再让线程”set”继续。经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的尴尬场面。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import threadingimport timeclass myThread(threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print("Starting " + self.name) # 获得锁，成功获得锁定后返回True # 可选的timeout参数不填时将一直阻塞直到获得锁定 # 否则超时后将返回False threadLock.acquire() print_time(self.name, self.counter, 3) # 释放锁 threadLock.release()def print_time(threadName, delay, counter): while counter: time.sleep(delay) print("%s: %s" % (threadName, time.ctime(time.time()))) counter -= 1threadLock = threading.Lock()threads = []# 创建新线程thread1 = myThread(1, "Thread-1", 1)thread2 = myThread(2, "Thread-2", 2)# 开启新线程thread1.start()thread2.start()# 添加线程到线程列表threads.append(thread1)threads.append(thread2)# 等待所有线程完成for t in threads: t.join()print("Exiting Main Thread")]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[僵尸进程]]></title>
    <url>%2F2018%2F03%2F28%2F%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[僵尸进程 怎样产生僵尸进程的： 一个进程在调用exit命令结束自己的生命的时候，其实它并没有真正的被销毁，而是留下一个称为僵尸进程（Zombie）的数据结构（系统调用exit，它的作用是使进程退出，但也仅仅限于将一个正常的进程变成一个僵尸进程，并不能将其完全销毁）。在Linux进程的状态中，僵尸进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态等信息供其他进程收集，除此之外，僵尸进程不再占有任何内存空间。它需要它的父进程来为它收尸，如果他的父进程没安装SIGCHLD信号处理函数调用wait或waitpid()等待子进程结束，又没有显式忽略该信号，那么它就一直保持僵尸状态，如果这时父进程结束了，那么init进程自动会接手这个子进程，为它收尸，它还是能被清除的。但是如果如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是为什么系统中有时会有很多的僵尸进程。 网络原因有时也会引起僵尸进程， 僵尸进程有害吗？ 不会。由于僵尸进程并不做任何事情， 不会使用任何资源也不会影响其它进程， 因此存在僵尸进程也没什么坏处。 不过由于进程表中的退出状态以及其它一些进程信息也是存储在内存中的，因此存在太多僵尸进程有时也会是一些问题，比如会影响服务器的性能。signal(SIGCHLD, SIG_IGN); 忽略SIGCHLD信号，这是一个常用于提升并发服务器性能的技巧,因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设置为忽略，可让内核把僵尸进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。 如何防止僵尸进程？ 让僵尸进程成为孤儿进程，由init进程回收；(手动杀死父进程) 调用fork()两次； 捕捉SIGCHLD信号，并在信号处理函数中调用wait函数；代码实例：` #include &lt;signal.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt; void sig_handler(int signo){ printf(&quot;child process deaded, signo: %d\n&quot;, signo); wait(0);// 当捕获到SIGCHLD信号，父进程调用wait回收，避免子进程成为僵尸进程 } void out(int n){ int i; for(i = 0; i &lt; n; ++i) { printf(&quot;%d out %d\n&quot;, getpid(), i); sleep(2); } } int main(void){ // 登记一下SIGCHLD信号 if(signal(SIGCHLD, sig_handler) == SIG_ERR) { perror(&quot;signal sigchld error&quot;); } pid_t pid = fork(); if(pid &lt; 0) { perror(&quot;fork error&quot;); exit(1); } else if(pid &gt; 0) { // parent process out(100); } else { // child process out(10); } return 0; } ` 如何找出僵尸进程呢？ ps aux | grep Zor ps -ef | grep defunct 解决方法： 设置SIGCLD信号为SIG_IGN，系统将不产生僵死进程。 用两次fork()，而且使紧跟的子进程直接退出，是的孙子进程成为孤儿进程，从而init进程将负责清除这个孤儿进程。 重启服务器电脑，这个是最简单，最易用的方法，但是如果你服务器电脑上运行有其他的程序，那么这个方法，代价很大。所以，尽量使用下面一种方法。 找到该defunct僵尸进程的父进程，将该进程的父进程杀掉，则此defunct进程将自动消失。 如何找到defunct僵尸进程的父进程？很简单，一句命令就够了：ps -ef | grep defunct_process_pid 正常情况下我们可以用 SIGKILL 信号来杀死进程，但是僵尸进程已经死了， 你不能杀死已经死掉的东西。 因此你需要输入的命令应该是kill -s SIGCHLD pid 。 将这里的 pid 替换成父进程的进程 id，这样父进程就会删除所有以及完成并死掉的子进程了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表]]></title>
    <url>%2F2018%2F03%2F28%2F%E5%93%88%E5%B8%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希表 哈希表的特点：关键字在表中位置和它之间存在一种确定的关系。hash : 翻译为“散列”，就是把任意长度的输入，通过散列算法，变成固定长度的输出，该输出就是散列值。不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。 实际工作中需视不同的情况采用不同的哈希函数，通常考虑的因素有： 计算哈希函数所需时间 关键字的长度 哈希表的大小 关键字的分布情况 记录的查找频率 由于哈希表高效的特性，查找或者插入的情况在大多数情况下可以达到O(1)，时间主要花在计算hash上，当然也有最坏的情况就是hash值全都映射到同一个地址上，这样哈希表就会退化成链表，查找的时间复杂度变成O(n)，但是这种情况比较少，只要不要把hash计算的公式外漏出去并且有人故意攻击（用兴趣的人可以搜一下基于哈希冲突的拒绝服务攻击），一般也不会出现这种情况。 下面这个程序是用C++实现的一个包含hash算法的小程序，可以让电话或者姓名作为key，从而查找记录。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526 // MyHashTable.cpp : 定义控制台应用程序的入口点。////设计哈希表实现电话号码查询系统//说明：一是从文件old.txt中读取的数据自己在程序运行前建立，// 二是由系统随机生成数据，在程序运行由随机数产生器生成，并且将产生的记录保存到 new.txt文件。//存在的问题：使用随机产生的文件，在显示时出现乱码// #include &lt;stdafx.h&gt; #include&lt;fstream&gt;//文件流#include&lt;iostream&gt;#include &lt;string&gt;#include&lt;stdlib.h&gt;using namespace std;const int D[] = &#123;3,5,8,11,13,14,19,21&#125;;//预定再随机数const int HASH_MAXSIZE = 50;//哈希表长度//记录信息类型class DataInfo&#123;public: DataInfo();//默认构造函数 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, const DataInfo&amp; dataInfo); //重载输出操作符 //friend class HashTable;//private: string name;//姓名 string phone;//电话号码 string address;//地址 char sign;//冲突的标志位，&apos;1&apos;表示冲突，&apos;0&apos;表示无冲突&#125;;DataInfo::DataInfo():name(&quot;&quot;), phone(&quot;&quot;), address(&quot;&quot;), sign(&apos;0&apos;)&#123;&#125;ostream&amp; operator&lt;&lt;(ostream&amp; out, const DataInfo&amp; dataInfo) //重载输出操作符&#123; cout &lt;&lt; &quot;姓名：&quot; &lt;&lt; dataInfo.name &lt;&lt; &quot; 电话：&quot; &lt;&lt; dataInfo.phone &lt;&lt; &quot; 地址：&quot; &lt;&lt; dataInfo.address &lt;&lt; endl; return out;&#125;//存放记录的哈希表类型class HashTable&#123;public: HashTable();//默认构造函数 ~HashTable();//析构函数 int Random(int key, int i);// 伪随机数探测再散列法处理冲突 void Hashname(DataInfo *dataInfo);//以名字为关键字建立哈希表 int Rehash(int key, string str);// 再哈希法处理冲突 注意处理冲突还有链地址法等 void Hashphone(DataInfo *dataInfo);//以电话为关键字建立哈希表 void Hash(char *fname, int n);// 建立哈希表 //fname 是数据储存的文件的名称，用于输入数据，n是用户选择的查找方式 int Findname(string name);// 根据姓名查找哈希表中的记录对应的关键码 int Findphone(string phone);// 根据电话查找哈希表中的记录对应的关键码 void Outhash(int key);// 输出哈希表中关键字码对应的一条记录 void Outfile(string name, int key);// 在没有找到时输出未找到的记录 void Rafile();// 随机生成文件，并将文件保存在 new.txt文档中 void WriteToOldTxt();//在运行前先写入数据 //private: DataInfo *value[HASH_MAXSIZE]; int length;//哈希表长度&#125;;HashTable::HashTable():length(0)//默认构造函数&#123; //memset(value, NULL, HASH_MAXSIZE*sizeof(DataInfo*)); for (int i=0; i&lt;HASH_MAXSIZE; i++) &#123; value[i] = new DataInfo(); &#125;&#125;HashTable::~HashTable()//析构函数&#123; delete[] *value;&#125;void HashTable::WriteToOldTxt()&#123; ofstream openfile(&quot;old.txt&quot;); if (openfile.fail()) &#123; cout &lt;&lt; &quot;文件打开错误！&quot; &lt;&lt; endl; exit(1); &#125; string oldname; string oldphone; string oldaddress; for (int i=0; i&lt;30; i++) &#123; cout &lt;&lt; &quot;请输入第&quot; &lt;&lt; i+1 &lt;&lt; &quot;条记录:&quot; &lt;&lt; endl; cin &gt;&gt; oldname ; cin &gt;&gt; oldphone; cin &gt;&gt; oldaddress; openfile &lt;&lt; oldname &lt;&lt; &quot; &quot; &lt;&lt; oldphone &lt;&lt; &quot; &quot; &lt;&lt; oldaddress &lt;&lt; &quot;,&quot; &lt;&lt; endl; &#125; openfile.close();&#125;int HashTable::Random(int key, int i)// 伪随机数探测再散列法处理冲突&#123;//key是冲突时的哈希表关键码，i是冲突的次数，N是哈希表长度 //成功处理冲突返回新的关键码，未进行冲突处理则返回-1 int h; if(value[key]-&gt;sign == &apos;1&apos;)//有冲突 &#123; h = (key + D[i]) % HASH_MAXSIZE; return h; &#125; return -1;&#125;void HashTable::Hashname(DataInfo *dataInfo)//以名字为关键字建立哈希表&#123;//利用除留取余法建立以名字为关键字建立的哈希函数，在发生冲突时调用Random函数处理冲突 int i = 0; int key = 0; for (int t=0; dataInfo-&gt;name[t]!=&apos;\0&apos;; t++) &#123; key = key + dataInfo-&gt;name[t]; &#125; key = key % 42; while(value[key]-&gt;sign == &apos;1&apos;)//有冲突 &#123; key = Random(key, i++);//处理冲突 &#125; if(key == -1) exit(1);//无冲突 length++;//当前数据个数加 value[key]-&gt;name = dataInfo-&gt;name; value[key]-&gt;address = dataInfo-&gt;address; value[key]-&gt;phone = dataInfo-&gt;phone; value[key]-&gt;sign = &apos;1&apos;;//表示该位置有值 //cout &lt;&lt; value[key]-&gt;name &lt;&lt; &quot; &quot; &lt;&lt; value[key]-&gt;phone &lt;&lt; &quot; &quot; &lt;&lt; value[key]-&gt;address &lt;&lt; endl;&#125;int HashTable::Rehash(int key, string str)// 再哈希法处理冲突&#123;//再哈希时使用的是折叠法建立哈希函数 int h; int num1 = (str[0] - &apos;0&apos;) * 1000 + (str[1] - &apos;0&apos;) * 100 + (str[2] - &apos;0&apos;) * 10 + (str[3] - &apos;0&apos;); int num2 = (str[4] - &apos;0&apos;) * 1000 + (str[5] - &apos;0&apos;) * 100 + (str[6] - &apos;0&apos;) * 10 + (str[7] - &apos;0&apos;); int num3 = (str[8] - &apos;0&apos;) * 100 + (str[9] - &apos;0&apos;) * 10 + (str[10] - &apos;0&apos;); h = num1 + num2 + num3; h = (h + key) % HASH_MAXSIZE; return h;&#125;void HashTable::Hashphone(DataInfo *dataInfo)//以电话为关键字建立哈希表&#123;//利用除留取余法建立以电话为关键字建立的哈希函数，在发生冲突时调用Rehash函数处理冲突 int key = 0; int t; for(t=0; dataInfo-&gt;phone[t] != &apos;\0&apos;; t++) &#123; key = key + dataInfo-&gt;phone[t]; &#125; key = key % 42; while(value[key]-&gt;sign == &apos;1&apos;)//有冲突 &#123; key = Rehash(key, dataInfo-&gt;phone); &#125; length++;//当前数据个数加 value[key]-&gt;name = dataInfo-&gt;name; value[key]-&gt;address = dataInfo-&gt;address; value[key]-&gt;phone = dataInfo-&gt;phone; value[key]-&gt;sign = &apos;1&apos;;//表示该位置有值 &#125;void HashTable::Outfile(string name, int key)//在没有找到时输出未找到的记录&#123; ofstream fout; if((key == -1)||(value[key]-&gt;sign == &apos;0&apos;))//判断哈希表中没有记录 &#123; fout.open(&quot;out.txt&quot;,ios::app);//打开文件 if(fout.fail()) &#123; cout &lt;&lt; &quot;文件打开失败!&quot; &lt;&lt; endl; exit(1); &#125; fout &lt;&lt; name &lt;&lt; endl;//将名字写入文件,有个问题，每次写入的时候总是将原来的内容替换了 fout.close(); &#125;&#125;void HashTable::Outhash(int key)//输出哈希表中关键字码对应的记录&#123; if((key==-1)||(value[key]-&gt;sign==&apos;0&apos;)) cout &lt;&lt; &quot;没有找到这条记录！&quot; &lt;&lt; endl; else &#123; for(unsigned int i=0; value[key]-&gt;name[i]!=&apos;\0&apos;; i++) &#123; cout &lt;&lt; value[key]-&gt;name[i]; &#125; for(unsigned int i=0; i&lt;10; i++) &#123; cout &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; value[key]-&gt;phone; for(int i=0; i&lt;10; i++) &#123; cout &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; value[key]-&gt;address &lt;&lt; endl; &#125;&#125;void HashTable::Rafile()//随机生成文件，并将文件保存在new.txt文档中&#123; ofstream fout; fout.open(&quot;new.txt&quot;);//打开文件，等待写入 if(fout.fail()) &#123; cout &lt;&lt; &quot;文件打开失败！&quot; &lt;&lt; endl; exit(1); &#125; for(int j=0; j&lt;30; j++) &#123; string name = &quot;&quot;; for(int i=0; i&lt;20; i++)//随机生成长个字的名字 &#123; name += rand() % 26 + &apos;a&apos;;//名字是由个字母组成 &#125; fout &lt;&lt; name &lt;&lt; &quot; &quot;;//将名字写入文件 string phone = &quot;&quot;; for(int i=0; i&lt;11; i++)//随机生成长位的电话号码 &#123; phone += rand() % 10 + &apos;0&apos;;//电话号码是纯数字 &#125; fout &lt;&lt; phone &lt;&lt; &quot; &quot;;//将电话号码写入文件 string address = &quot;&quot;; for(int i=0; i&lt;29; i++)//随机生成长个字的名字 &#123; address += rand() % 26 + &apos;a&apos;;//地址是由个字母组成 &#125; address += &apos;,&apos;; fout &lt;&lt; address &lt;&lt; endl;//将地址写入文件 &#125; fout.close();&#125;void HashTable::Hash(char *fname, int n)//建立哈希表//fname是数据储存的文件的名称，用于输入数据，n是用户选择的查找方式//函数输入数据，并根据选择调用Hashname或Hashphone函数进行哈希表的建立&#123; ifstream fin; int i; fin.open(fname);//读文件流对象 if(fin.fail()) &#123; cout &lt;&lt; &quot;文件打开失败！&quot; &lt;&lt; endl; exit(1); &#125; while(!fin.eof())//按行读入数据 &#123; DataInfo *dataInfo = new DataInfo(); char* str = new char[100]; fin.getline(str, 100, &apos;\n&apos;);//读取一行数据 if(str[0] == &apos;*&apos;)//判断数据结束 &#123; break; &#125; i = 0;//记录字符串数组的下标 //a-z:97-122 A-Z:65-90 //本程序的姓名和地址都使用小写字母 while((str[i] &lt; 97) || (str[i] &gt; 122))//读入名字 &#123; i++; &#125; for(; str[i]!=&apos; &apos;; i++) &#123; dataInfo-&gt;name += str[i]; &#125; while(str[i] == &apos; &apos;) &#123; i++; &#125; for(int j=0; str[i]!=&apos; &apos;; j++,i++)//读入电话号码 &#123; dataInfo-&gt;phone += str[i]; &#125; while(str[i] == &apos; &apos;) &#123; i++; &#125; for(int j=0; str[i]!=&apos;,&apos;; j++,i++)//读入地址 &#123; dataInfo-&gt;address += str[i]; &#125; if(n == 1) &#123; Hashname(dataInfo); &#125; else &#123; Hashphone(dataInfo);//以电话为关键字 &#125; delete []str; delete dataInfo; &#125; fin.close();&#125;int HashTable::Findname(string name)//根据姓名查找哈希表中的记录对应的关键码&#123; int i = 0; int j = 1; int t; int key = 0; for(key=0, t=0; name[t] != &apos;\0&apos;; t++) &#123; key = key + name[t]; &#125; key = key % 42; while((value[key]-&gt;sign == &apos;1&apos;) &amp;&amp; (value[key]-&gt;name != name)) &#123; key = Random(key, i++); j++; if(j &gt;= length) return -1; &#125; return key;&#125;int HashTable::Findphone(string phone)//根据电话查找哈希表中的记录对应的关键码&#123; int key = 0; int t; for(t=0; phone[t] != &apos;\0&apos; ; t++) &#123; key = key + phone[t]; &#125; key = key % 42; int j = 1; while((value[key]-&gt;sign == &apos;1&apos;) &amp;&amp; (value[key]-&gt;phone != phone)) &#123; key = Rehash(key, phone); j++; if(j &gt;= length) &#123; return -1; &#125; &#125; return key;&#125;int main()&#123; //WriteToOldTxt(); int k; int ch; char *Fname; HashTable *ht = new HashTable; while(1) &#123; system(&quot;cls&quot;);//cls命令清除屏幕上所有的文字 cout &lt;&lt; &quot;欢迎使用本系统！&quot; &lt;&lt; endl &lt;&lt; endl; cout &lt;&lt; &quot;请选择数据&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.使用已有数据文件&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.随机生成数据文件&quot; &lt;&lt; endl; cout &lt;&lt; &quot;0.结束&quot; &lt;&lt; endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; k; switch(k) &#123; case 0: return 0; case 1: Fname = &quot;old.txt&quot;;//从数据文件old.txt(自己现行建好)中读入各项记录 break; case 2: ht-&gt;Rafile(); Fname = &quot;new.txt&quot;;//由系统随机产生各记录，并且把记录保存到new.txt文件中 break; default: cout &lt;&lt; &quot;输入序号有误，退出程序。&quot; &lt;&lt; endl; return 0; &#125; do &#123; system(&quot;cls&quot;); cout &lt;&lt; &quot; 请选择查找方式&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.通过姓名查找&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.通过电话查找&quot; &lt;&lt; endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; ch; if((ch != 1) &amp;&amp; (ch != 2)) cout &lt;&lt; &quot;输入序号有误！&quot; &lt;&lt; endl; &#125;while((ch != 1) &amp;&amp; (ch != 2)); ht-&gt;Hash(Fname, ch); while(ch == 1) &#123; int choice; cout &lt;&lt; endl &lt;&lt; &quot;请选择功能&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.输入姓名查找数据&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.显示哈希表&quot; &lt;&lt; endl; cout &lt;&lt; &quot;0.退出&quot;&lt;&lt;endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; choice; switch(choice) &#123; case 1: &#123;//注意此处应该加上大括号 int key1; string name; cout &lt;&lt; &quot;请输入姓名：&quot;; cin &gt;&gt; name; key1 = ht-&gt;Findname(name); ht-&gt;Outfile(name, key1); ht-&gt;Outhash(key1); &#125; break; case 2: &#123; for(int i=0; i&lt;HASH_MAXSIZE; i++) &#123; if(ht-&gt;value[i]-&gt;sign!=&apos;0&apos;) &#123; ht-&gt;Outhash(i); &#125; &#125; &#125; break; default: cout &lt;&lt; endl &lt;&lt; &quot;您的输入有误！&quot; &lt;&lt; endl; &#125; if(choice == 0) &#123; return 0; &#125; &#125; while(ch == 2) &#123; int choice; cout &lt;&lt; endl &lt;&lt; &quot;请选择功能&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.输入电话查找数据&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.显示哈希表&quot;&lt;&lt;endl; cout &lt;&lt; &quot;0.退出&quot;&lt;&lt;endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; choice; switch(choice) &#123; case 1: &#123; int key2; string phone; cout &lt;&lt; &quot;请输入11位的电话号码：&quot;; do &#123; cin &gt;&gt; phone; if(phone.length() != 11) &#123; cout &lt;&lt; &quot;电话号码应为11位！\n请重新输入：&quot;; &#125; &#125;while(phone.length() != 11); key2 = ht-&gt;Findphone(phone); ht-&gt;Outfile(phone, key2); ht-&gt;Outhash(key2); &#125; break; case 2: &#123; for(int i=0; i&lt;HASH_MAXSIZE; i++) &#123; if(ht-&gt;value[i]-&gt;sign != &apos;0&apos;) &#123; ht-&gt;Outhash(i); &#125; &#125; &#125; break; default: cout &lt;&lt; endl &lt;&lt; &quot;您的输入有误！&quot; &lt;&lt; endl; &#125; if(choice == 0) &#123; return 0; &#125; &#125; while((ch != 1) &amp;&amp; (ch != 2)) &#123; cout &lt;&lt; &quot;您的输入有误！请输入相应需要选择功能：&quot;; &#125; &#125; system(&quot;pause&quot;); return 0;&#125;]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种树]]></title>
    <url>%2F2018%2F03%2F27%2F%E5%90%84%E7%A7%8D%E6%A0%91%2F</url>
    <content type="text"><![CDATA[红黑树，AVL树简单来说都是用来搜索的呗。 AVL树：平衡二叉树，一般是用平衡因子差值决定并通过旋转来实现，左右子树树高差不超过1，那么和红黑树比较它是严格的平衡二叉树，平衡条件非常严格（树高差只有1），只要插入或删除不满足上面的条件就要通过旋转来保持平衡。由于旋转是非常耗费时间的。我们可以推出AVL树适合用于插入删除次数比较少，但查找多的情况。 红黑树：平衡二叉树，通过对任何一条从根到叶子的简单路径上各个节点的颜色进行约束，确保没有一条路径会比其他路径长2倍，因而是近似平衡的。所以相对于严格要求平衡的AVL树来说，它的旋转保持平衡次数较少。用于搜索时，插入删除次数多的情况下我们就用红黑树来取代AVL。（现在部分场景使用跳表来替换红黑树，可搜索“为啥 redis 使用跳表(skiplist)而不是使用 red-black？”） B树，B+树：它们特点是一样的，是多路查找树，一般用于数据库系统中，为什么，因为它们分支多层数少呗，都知道磁盘IO是非常耗时的，而像大量数据存储在磁盘中所以我们要有效的减少磁盘IO次数避免磁盘频繁的查找。B+树是B树的变种树，有n棵子树的节点中含有n个关键字，每个关键字不保存数据，只用来索引，数据都保存在叶子节点。是为文件系统而生的。b+树是b树的一个变种，只在leaf node存储数据，可以方便地遍历所有数据。b树相较于b+树可以把热点数据放在internal node中以便更快地查找。 B+树本来就是为 SQL 实现的，它比 B 树的优势在于范围查询更快，因为数据都在叶子节点上，所有的叶子节点又在同一底层上。 磁盘中的B+树以文件的形式将整体都存放磁盘当中，使用时只在内存中缓存部份结构。 先了解下相关的硬件知识，才能很好的了解为什么需要B~tree这种外存数据结构。 B-tree就是指的B树。 B+-tree的查询效率更加稳定 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 数据库索引采用B+树的主要原因是 B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。正是为了解决这个问题，B+树应运而生。B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）。 Trie树：又名单词查找树，一种树形结构，常用来操作字符串,比如在百度搜索时，会给出提示。它是不同字符串的相同前缀只保存一份。相对直接保存字符串肯定是节省空间的，但是它保存大量字符串时会很耗费内存（是内存）。类似的有前缀树(prefix tree)，后缀树(suffix tree)，radix tree(patricia tree, compact prefix tree)，crit-bit tree（解决耗费内存问题），以及前面说的double array trie。简单的补充下我了解应用前缀树：字符串快速检索，字符串排序，最长公共前缀，自动匹配前缀显示后缀。后缀树：查找字符串s1在s2中，字符串s1在s2中出现的次数，字符串s1,s2最长公共部分，最长回文串。radix tree：linux内核，nginx。]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机通过桥接模式上网（补充）]]></title>
    <url>%2F2018%2F03%2F24%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%80%9A%E8%BF%87%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E4%B8%8A%E7%BD%91%EF%BC%88%E8%A1%A5%E5%85%85%EF%BC%89%2F</url>
    <content type="text"><![CDATA[虚拟机通过桥接模式上网（补充）（上次设置的桥接模式并不具备上外网的能力，这次重新梳理了一下过程） 通过brctl show命令可以看到原来已经有网桥br1，我想通过brctl delbr br1试着删除该网桥，但是提示不能删除，经过分析，原因可能有二，其一还有网卡挂在其上，其二，该网桥没有关闭，执行ifconfig br1 down命令关闭网桥,然后再进行删除。 重新建立一个网桥，brctl addbr br-ex（让linux知道网桥，首先告诉它，我们想要一个虚拟的以太网桥接口） 把物理网卡enp11s0挂载到网桥上，brctl addif br-ex enp11s0（以太网物理接口变成了网桥上的逻辑端口。那物理接口过去存在，未来也不会消失。） 此时，ifconfig发现网卡和网桥均有ip（不正常，上不去网） 执行删去网卡ip的命令id addr del dev enp11s0 192.168.1.50/24（为什么可以删去，因为物理网卡成了逻辑网桥设备的一部分了，所以不再需要IP地址。虽然不把原有的网卡地址释放掉，网桥也能工作！但是，为了更规范，或者说为了避免有什幺莫名其妙的问题，最好还是按要求做） 更改/etc/network/interface文件，添加配置，static模式 此时再ifconfig发现物理网卡已没有ip，只有br-ex有，此时可以上网。 登录到学校网关（如果登不上，可能DNS解析出现问题，去/etc/resolv.conf更改配置，加上nameserver 172.21.0.21 ，此为学校的DNS服务器） 此时一切完好，服务器设置已经完毕！这时虚拟机即可以通过桥接模式连接外网，但请注意，如果重启服务器的话，这些配置会消失，因为这些事通过命令行设置的，如果想永久生效的话，可能需要通过配置文件进行修改（我并没有尝试）注：ping 172.21.4.254可以检查是否可以访问外网。 下图显示的是一些配置网桥常用的命令 注意的问题： brctl show中有STP选项，这个其实是生成树协议！因为实验室目前只有一个路由器，是绝对不可能形成一个环的。可以关闭这个功能，这样也可以减少网络环境的数据包污染。 服务器可以上网但是ping百度不通，可能是由于很多网站在服务器都设置了阻止ping数据包，一是安全考虑，二是如果每天都有大量的ping数据包向服务器请求，那会给服务器带来很大负担，如果人家恶意向你的服务器发送大量这种数据包，你的服务器将会无暇顾及其他数据包，那你的网站别人将无法访问，或者打开非常慢，经过测试，确实是这样的！]]></content>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机通过代理上外网]]></title>
    <url>%2F2018%2F03%2F24%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%80%9A%E8%BF%87%E4%BB%A3%E7%90%86%E4%B8%8A%E5%A4%96%E7%BD%91%2F</url>
    <content type="text"><![CDATA[虚拟机通过代理连接外网 因为实验室的服务器没有连接外网，而如果又需要连网的需求，那么可以通过代理的方式，有一款软件CCProxy，需要有校园IP ，服务器的ip网段172.21.4.x，校园网的ip网段为172.21.6.x， 所以虚拟机可以通过有校园网IP的电脑作为Proxy。 下载CCproxy，主界面如下，点击账号管理。 新建一个用户 注意：输入用户名，勾选密码，自定义一个密码，取消勾选IP地址/IP地址段 回到主界面，点击设置，按如下方式设置，注意“请选择本机局域网IP地址默认为自动检测，如果虚拟机不能联网，可尝试手动修改其为本机当前IP地址” 在虚拟机中输入如下命令：export http_proxy=http://username:passwd@ip:port 之后就可以使用apt-get 等功能安装软件包，升级系统。注意：代理设置只在当前ssh连接有效，如果你断开过ssh连接，重新连接后，需要重新在ubuntu中通过命令设置代理。]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell知识点]]></title>
    <url>%2F2018%2F03%2F18%2FShell%E7%9F%A5%E8%AF%86%E7%82%B9-1%2F</url>
    <content type="text"><![CDATA[使用read读取行 read可以一次读取所有的值到多个变量里，使用$IFS分割，比如应用于/etc/passwd文件。 12345#!/bin/bashwhile IFS=: read user pass uid gid fullname homedir Shelldo echo $userdone &lt; /etc/passwd 当到文件末尾时，read会以非0退出，终止while循环。可能会觉得把/etc/passwd的重定向放到末尾有些奇怪，不过这是必须的。如果这样写，就不会终止！因为每次循环，Shell都会打开/etc/passwd一次，且read只读取文件的第一行。 12345#!/bin/bashwhile IFS=: read user pass uid gid &lt; /etc/passwd fullname homedir Shelldo echo $userdone make 1&gt; results 2&gt; ERRS 该命令将标准错误输出到ERRS，将标准输出传给results。 命令替换：就是指Shell执行命令并将命令替换为执行该命令后的结果。可以用两个反引号，不过这种方式容易混淆，所以还有一种方式就是使用$(...) ,现在多用此。 1234567$# 传递到脚本的参数个数$* 以一个单字符串显示所有向脚本传递的参数$$ 脚本运行的当前进程ID号$! 后台运行的最后一个进程的ID号$@ 与$#相同，但是使用时加引号，并在引号中返回每个参数。$- 显示Shell使用的当前选项，与set命令功能相同。$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误]]></content>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机IP]]></title>
    <url>%2F2018%2F03%2F15%2F%E8%99%9A%E6%8B%9F%E6%9C%BAIP%2F</url>
    <content type="text"><![CDATA[如何不进去虚拟机看到其IP 在linux上玩过kvm的朋友基本都晓得，在宿主机上运行了虚拟主机以后，我们无法直接看到某一个虚拟主机IP地址。比如 如果我们想知道test这个虚拟机的IP地址，那么是无法直接看到的。但是我们可以通过一个小技巧间接得到其IP，也就是利用ARP。 编辑虚拟主机配置文件。查看虚拟机的配置文件test.xml，（或者通过virsh dumpxml test）找到MAC标签，可以得到该虚拟机的MAC地址，记录下mac后退出，然后通过arp -a判定虚拟机IP地址，由此可以发现此虚拟机IP为192.168.122.118，由此实现了不登陆虚拟机即可得到其IP。 (注意这里一定要加上-i 忽略大小写。不然因为大小写问题有可能查不到)说明：这里只根据通信缓存记录的mac 、IP地址手段做排查。也有可能找不到。最好的办法是自己写一个脚本跟网段内的所有服务器都ping一次，记录下mac、ip地址以后再查找就没问题,因为这个方法就根据ARP缓存得到的。 虚拟机指定固定IP (方法1) 由于bridge模式默认创建虚拟机的时候用的DHCP方式，分配给虚拟机的IP可能会发生改变，有时候很麻烦。那么如何指定其IP呢？进去虚拟机，编辑/etc/network/interface文件，由变成然后输入 systemctl restart networking或者实在不行重启，即可更改为192.168.1.111的地址。 虚拟机指定固定IP (方法2) 把MAC与IP之间进行绑定,配置DHCP的配置文件 12345678910111213141516171819202122232425262728293031323334353637# dhcpd.conf## Sample configuration file for ISC dhcpd# # Use this to enble / disable dynamic dns updates globally.ddns-update-style none; ignore client-updates; # If this DHCP server is the official DHCP server for the local# network, the authoritative directive should be uncommented.#authoritative; # Use this to send dhcp log messages to a different log file (you also# have to hack syslog.conf to complete the redirection).#log-facility local7; # No service will be given on this subnet, but declaring it helps the# DHCP server to understand the network topology.# This is a very basic subnet declaration. # A slightly different configuration for an internal subnet.subnet 192.168.0.0 netmask 255.255.255.0 &#123; range 192.168.0.30 192.168.0.39; option domain-name-servers 192.168.0.31; option domain-name &quot;wan.hust.china&quot;; option routers 192.168.0.1; option broadcast-address 192.168.0.255; default-lease-time 21600; max-lease-time 43200; host pc001 &#123; hardware ethernet 66:66:66:66:66:0b; fixed-address 192.168.0.88; &#125;&#125; 如今就能够通过在创建虚拟机时指定MAC地址来间接指定IP地址了： 1/usr/local/qemu-kemari-v0.2.14/bin/qemu-system-x86_64 -m 1024 /images/test2.img -net nic,mac=66:66:66:66:66:0b -net tap,ifname=tap1,script=/etc/qemu-ifup,downscript=no -vnc :6 -enable-kvm 注意的问题这里要注意：当两台虚拟机都指定同一个与特定IP绑定的MAC地址时。DHCP并不报错。而是给两台虚拟机都分配这个特定的IP。以下是我在网上找到的一些帖子。来解释同一个网段内能够有两台电脑拥有同样的IP和MAC地址： 事实上是能够的，你全然能够把两台电脑的IP 和MAC改成一样。不但能够上网并且还没IP冲突。这样的方法不但能够突破路由封锁用在ADSL共享上网。并且还能够用在IEEE802.1X认证上网的环境中。可是前提必需要用同样的帐号来拨号上网（前提认证server没设验证帐号的反复性）。我的机子是通过学校校园网接入internet的，client採用802.1x认证client软件“STAR Supplicant拨号软件”来拨号上网，在我们学校里能够将两台机子的IP和MAC改成一样然后用同样的一个帐号来达到共享上网的目的，只是在我们学校仅仅能够在同一个宿舍的两台机子才干够共享上网，由于我们学校的server不单止验证帐号,ip,MAC并且还验证接入serverIP（NASIP），和接入serverport（NAS port)，不同的宿舍接在学校交换机不同的port，所以仅仅限于同一个宿舍用这样的法共享上网。 至于为什么不会引起IP冲突并且还能上网,这是由于ARP工作的缺陷，系统之所以会发现网上有相的IP的而提示“IP冲突”，是由于系统在启动时,TCP/IP中的ARP会广播一个免费ARP(free arp)请求包到网段上，这个ARP(free arp)包包括自己的IP和MAC。假设网段上有机子回应了这个包，这台发广播的机子就会觉得局域网有别的机子使用和自己同样的IP。 比如：PC A和PC B的IP和MAC全然一样，PC A的系统启动时会广播一个包括自己IP和MAC的免费ARP(free arp)请求包到网段上，假设PC B回应了这个请求。PC A会觉得自己的IP和网络上的IP有冲突并发出提示（这就是为什么IP冲突一般发生系统刚启动完毕时），问题是PC B根本不会回应这个请求包。这是由于这个请求包的IP和MAC和PC B自己的全然一样，而PC B会觉得是自己发的包。所以不会回应，既然不会回应自然不会发生IP冲突了。 好了。让我来解释下一个问题。就是两台机子的IP和MAC一样究竟会不会导致不能上网： 既然能够。那么网络上的硬件设备是如何区份这些数据究竟是哪台机的呢？？大家都知道局域网内是用硬件地址来通迅的，局域网的二层设备(如交换机）维护着一张地址表，地址表记录着本设备每一个port所相应的MAC（注：不是port的MAC，而是port所连设备的MAC）。设备要经过地址学习状态才干知道这些port所相应的MAC，当一个帧经过设备的某介port时，设备会检查该帧源地址和目的地址,然后再对比自己的地址表，看地址表中是否存在该源地址的相应项。若不存在则port会变为“地址学习状态”，将该地址保存在地址表中组成一个新的表项。假设PCA和PCB都连在同一个交换机上。则交换机经过“地址学习状态”后，地址表中存在两个同样的地址项，只是它们所相应的port是不同的。当交换机在外部接收到一个目的地址为该地址（PCA和PCB同样的MAC地址）的帧时，则会检查地址表。检查地址表后会发现存在两个同样地址的表项。于是交换机会将该帧转发到这两个表项所相应的port，(至于交换机是用组播的方式还是说用一个帧发两遍的方式转发给这两个port我就不太清楚了)。 路由器也一样。不同是的路由器的地址表是路由表。存放的是IP而不是硬件地址。 连接这两个port的PCA和PCB都会收到相同的帧，既然会收到相同的帧，那么计算机如何才知道哪些帧才是自己想要的呢？这取决于工作在TCP/ip上层协议。尽管网卡是接收了这个帧，可是上层的协议进行进一步的分用，也能够说成是过滤，当TCP/IP的网络接口层(也叫链路层)收到一个帧，会检查帧头中的帧类型，假设是ARP类型的就交给ARP协议去处理，假设是RARP类型就会交给RARP协议处理。假设是IP类型会去掉帧头并把这个帧传给上一层（即网络层来处理）。网络层会依据包头（去掉帧头就叫IP包了）中的协议类型来分用。如是TCMP类型就交给ICMP协议处理。假设是IGMP类型就交给IGMP协议处理。假设是TCP或UDP就把包头去掉并交给上一层（即传输层）来片理，去掉IP包头后就叫做报文分段了（传输层的单位），相同传输层也会对报文分段的头部进行检查从而进行进一步的分用，假设是TCP类型的交给TCP协议处理，假设是UDP类型就交给UDP协议处理，TCP或UDP会依据报文分段的头部中的“目的port号”来交给应用层（交给应用层前会把报文分段的头部去掉），然后应用层的用户进程会依据该“port号”来决是否接收这个数据，比如QQ某个进程打开了UDP 1324这个port，传输层的UDP协议会把全部接收到的且“目的port号”为1324的报文分段交给QQ的这个进程。 这样就完毕接收数据的整个过程。尽管两台电脑都会接收到不是属于自己的数据帧。可是在把帧交给上层协议片理时有可能会被丢充。就如应用层的QQ进程不会接到除“目的port号”为1324以外的其他数据包，由于这些数据在应用层前已经被丢弃。 在同一个局域网内理论上是同意同样MAC地址存在的。为什么使用同样的MAC地址的PC都能在同一网段内执行呢？首先。我们要明白的是，局域网内的通信是以帧为基础的，也就是我们通常说的MAC地址。而不是IP地址。其次，路由器（特指平时我们家庭用的那种路由，如tplink等）或交换机（如cisco）在局域网内是依据mac-table进行数据的交换。并且这些表都有特定的生存期。不是静态的。 如今如果，有两台PC（PC1和PC2）的MAC地址同样。分别接在路由器（或交换机）的两个端口（port1，port2）上，pc1首先发起连接魔兽游戏的server的请求，那么在路由器（或交换机）上就会在mac-table加入PC1的mac地址到port1上。当魔兽游戏的server反应请求后，路由器也会把信息转发到port1上给PC1.同理。当PC2也要登陆魔兽游戏server时。过程也一样。 可是。路由器的mac-table是动态的，当pc1请求连接并且被路由器记录这个mac地址相应的端口为port1时，pc2突然发起连接魔兽server的请求，那么路由器的mac-table就会更改次MAC地址的相应端口，把这个mac地址的端口改为port2。那么pc1的响应消息就会直接发给PC2,造成pc1不能上网。 当然。发生这样的情况比較少。由于，请求响应都是在几秒甚至几十毫秒内完毕的。 所以这也解释了，为什么当中一台PC接收大量数据时，还有一台会断网的原因啦。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM配置虚拟机桥接（bridge）模式]]></title>
    <url>%2F2018%2F03%2F14%2FKVM%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A1%A5%E6%8E%A5%EF%BC%88bridge%EF%BC%89%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[主机：Ubuntu14.04 64bit虚拟机：Ubuntu14.04 64bitVMM:KVM 基础知识：默认创建的网桥virbr0用于NAT模式，如果想用brigde模式，需要自己创建一个br0。Bridge方式即虚拟网桥的网络连接方式，是客户机和子网里面的机器能够互相通信。可以使虚拟机成为网络中具有独立IP的主机。 桥接网络（也叫物理设备共享）被用作把一个物理设备复制到一台虚拟机。网桥多用作高级设置，特别是主机多个网络接口的情况。 修改网络配置文件 /etc/network/interfaces ，此处是DHCP方式，也可以static方式。（Ubuntu系统，centos在etc/sysconfig里）输入 brctl addbr br0 建立一个网桥br0，此时在Linux内核里创建虚拟网卡br0，enp11s0 是host主机的网卡。 重新启动网络服务便可重启计算机或者sudo systemctl restart networking / sudo systemctl restart network-manager，此时输入ifconfig，显示如图。（据说br0与enp11s0只能有一个有ip地址，此处不是很明白，但是目前并不影响使用。） 输入该命令，可以看到此时已有br0的网桥。 创建虚拟机时，指定—bridge=br0。（–bridge与—network只能二选一，不能同时指定） 1virt-install --virt-type kvm --name test2 --ram 1024 --vcpus 1 --bridge=br0 \ --cdrom=/home/lib206/vmimage/ubuntu-16.04.1-server-amd64.iso \--disk path=/home/lib206/vmimage/Test.img,size=20,format=raw --graphics vnc,port=5901 --os-type=linux --boot cdrom 创建成功后，如果启动虚拟机时出现不能引导Booting from No bootable device，按下图所示设置，可能是引导顺序的原因。 此时虚拟机即处于桥接模式，ip由路由器DHCP随即分配。通过以上步骤的设置KVM的桥接问题解决了，此时可以查看一下虚拟机网络IP地址，应该跟主机的IP地址处于同一个网段；但是还是有问题的， 无线网卡桥接是不成功的，默认的是有线网卡！ 如果想指定该虚拟机的ip地址，按另一篇文章设置。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell知识点]]></title>
    <url>%2F2018%2F03%2F11%2FShell%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[/dev/null 位桶（bit bucket）传送到此文件的数据会被丢掉,可以用来测试一个文件是否包含某个pattern。 1234if grep pattern myfile &gt; /dev/nullthen ... 找到模式else ...没找到模式fi Shell脚本的命令行参数超多9时，用数字框起来${10} ^$ 用来匹配空字符串或行列，cc -E foo.c | grep -v &#39;^$&#39;&gt; foo.out 用来排除空行 实时查看当前进程中使用的shell种类ps | grep $$ | awk &#39;{print $4}&#39; 正则表达式对于程序执行时的locale环境相当敏感；方括号表达式里的范围应避免使用，该用字符集，例如[[:alnum:]]比较好。 -k选项指定排序字段，-t选择字段界定符 12345678910sort -t_ -k1,1 -k2,2 &lt;&lt; EOF&gt; one_two&gt; one_two_three&gt; ont_two_four&gt; ont_two_five&gt; EOFone_twoone_two_threeont_two_fiveont_two_four 可以看出sort并不稳定，因为输入与输出不一致，但我们可以通过–stable选项补救该问题。 为什么看不到/etc/passwd,因为默认是隐藏的。 awk与cut是提取字段的好工具。 awk -F: &apos;{print $5}&apos; or cut -d: -f5 2&gt; /dev/null 是丢弃标准错误信息的输出 myvar=赋值并不会将myvar删除，只不过是将其设为null字符串，unset myvar则会完全删除它。 rm -fr /$MYPROGRAM 若MYPROGRAM未定义，就会有灾难发生！！！ POSIX标准化字符串长度运算符：返回字符长度。 12x=supercalifraglistcexpialidoucius 著名的特殊单词echo There are $&#123;#x&#125; characters in $x set命令 如果未給任何选项，会设置位置参数的值，并将之前存在的任何值丢弃。 12345678910111213141516171819202122232425262728293031323334[root@localhost ~]# set -- hello &quot;hi there&quot; greetings[root@localhost ~]# echo there are $# total arguments 计数there are 3 total arguments[root@localhost ~]# for i in $*&gt; do echo i is $i&gt; donei is hello 注意内嵌的空白已经消失i is hii is therei is greetings[root@localhost ~]# for i in $@ 没有双引号 $*和$@一样&gt; do echo i is $i&gt; donei is helloi is hii is therei is greetings[root@localhost ~]# for i in &quot;$*&quot;&gt; do echo i is $i&gt; donei is hello hi there greetings[root@localhost ~]# for i in &quot;$@&quot;; do echo i is $i; donei is helloi is hi therei is greetings[root@localhost ~]# shift 截去第一个参数[root@localhost ~]# echo there are now $# total argumentsthere are now 2 total arguments 证明消失[root@localhost ~]# for i in &quot;$@&quot;; do echo i is $i; donei is hi therei is greetings[root@localhost ~]# shift[root@localhost ~]# echo there are now $# total argumentsthere are now 1 total arguments 特殊变量$$ 可在编写脚本时用来建立具有唯一性的文件名，多半是临时的，根据Shell的进程编号建立文件名，不过，mktemp也能做。 set -e当命令以非零状态退出时，则退出shell。主要作用是，当脚本执行出现意料之外的情况时，立即退出，避免错误被忽略，导致最终结果不正确。说明set -e 选项对set.sh起作用。脚本作为一个进程去描述set -e选项的范围应该是：set -e选项只作用于当前进行，不作用于其创建的子进程。set -e 命令用法总结如下：1.当命令的返回值为非零状态时，则立即退出脚本的执行。2.作用范围只限于脚本执行的当前进行，不作用于其创建的子进程。3.另外，当想根据命令执行的返回值，输出对应的log时，最好不要采用set -e选项，而是通过配合exit 命令来达到输出log并退出执行的目的。 shell 脚本中set-x 与set+x的区别linux shell 脚本编写好要经过漫长的调试阶段，可以使用sh -x 执行。但是这种情况在远程调用脚本的时候，就有诸多不便。又想知道脚本内部执行的变量的值或执行结果，这个时候可以使用在脚本内部用 set -x 。set去追踪一段代码的显示情况，执行后在整个脚本有效，set -x 开启，set +x关闭，set -o 查看 shell if条件判断中的-z到-d的意思 123456789101112131415161718192021222324252627282930313233[ -a FILE ] 如果 FILE 存在则为真。[ -b FILE ] 如果 FILE 存在且是一个块特殊文件则为真。[ -c FILE ] 如果 FILE 存在且是一个字特殊文件则为真。[ -d FILE ] 如果 FILE 存在且是一个目录则为真。[ -e FILE ] 如果 FILE 存在则为真。[ -f FILE ] 如果 FILE 存在且是一个普通文件则为真。[ -g FILE ] 如果 FILE 存在且已经设置了SGID则为真。[ -h FILE ] 如果 FILE 存在且是一个符号连接则为真。[ -k FILE ] 如果 FILE 存在且已经设置了粘制位则为真。[ -p FILE ] 如果 FILE 存在且是一个名字管道(F如果O)则为真。[ -r FILE ] 如果 FILE 存在且是可读的则为真。[ -s FILE ] 如果 FILE 存在且大小不为0则为真。[ -t FD ] 如果文件描述符 FD 打开且指向一个终端则为真。[ -u FILE ] 如果 FILE 存在且设置了SUID (set user ID)则为真。[ -w FILE ] 如果 FILE 如果 FILE 存在且是可写的则为真。[ -x FILE ] 如果 FILE 存在且是可执行的则为真。[ -O FILE ] 如果 FILE 存在且属有效用户ID则为真。[ -G FILE ] 如果 FILE 存在且属有效用户组则为真。[ -L FILE ] 如果 FILE 存在且是一个符号连接则为真。[ -N FILE ] 如果 FILE 存在 and has been mod如果ied since it was last read则为真。[ -S FILE ] 如果 FILE 存在且是一个套接字则为真。[ FILE1 -nt FILE2 ] 如果 FILE1 has been changed more recently than FILE2, or 如果 FILE1 exists and FILE2 does not则为真。[ FILE1 -ot FILE2 ] 如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真。[ FILE1 -ef FILE2 ] 如果 FILE1 和 FILE2 指向相同的设备和节点号则为真。[ -o OPTIONNAME ] 如果 shell选项 “OPTIONNAME” 开启则为真。[ -z STRING ] “STRING” 的长度为零则为真。[ -n STRING ] or [ STRING ] “STRING” 的长度为非零 non-zero则为真。[ STRING1 == STRING2 ] 如果2个字符串相同。 “=” may be used instead of “==” for strict POSIX compliance则为真。[ STRING1 != STRING2 ] 如果字符串不相等则为真。[ STRING1 &lt; STRING2 ] 如果 “STRING1” sorts before “STRING2” lexicographically in the current locale则为真。[ STRING1 &gt; STRING2 ] 如果 “STRING1” sorts after “STRING2” lexicographically in the current locale则为真。[ ARG1 OP ARG2 ] “OP” is one of -eq, -ne, -lt, -le, -gt or -ge. These arithmetic binary operators return true if “ARG1” is equal to, not equal to, less than, less than or equal to, greater than, or greater than or equal to “ARG2”, respectively. “ARG1” and “ARG2” are integers. Shell变量表达式 举个栗子：12345678910111213#!/bin/bashstr=&quot;a b c d e f g h i j&quot;echo &quot;the source string is &quot;$&#123;str&#125; #源字符串echo &quot;the string length is &quot;$&#123;#str&#125; #字符串长度echo &quot;the 6th to last string is &quot;$&#123;str:5&#125; #截取从第五个后面开始到最后的字符echo &quot;the 6th to 8th string is &quot;$&#123;str:5:2&#125; #截取从第五个后面开始的2个字符echo &quot;after delete shortest string of start is &quot;$&#123;str#a*f&#125; #从开头删除a到f的字符echo &quot;after delete widest string of start is &quot;$&#123;str##a*&#125; #从开头删除a以后的字符echo &quot;after delete shortest string of end is &quot;$&#123;str%f*j&#125; #从结尾删除f到j的字符echo &quot;after delete widest string of end is &quot;$&#123;str%%*j&#125; #从结尾删除j前面的所有字]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qemu-kvm-io线程]]></title>
    <url>%2F2018%2F03%2F11%2Fqemu-kvm-io%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[qemu-kvm一般会有4个线程，主线程是io thread，还有一个vcpu thread，一个signal thread。对于io thread，可以从kvm_main_loop(qemu-kvm.c)开始看：两个pipe是比较重要的一点： 它调用qemu_eventfd创建一个event pipe，pipe read fd用qemu_set_fd _hadnler2注册一个read fd handler，也就是说如果fd read ready，io thread将通过某种机制调用这个handler，即io_thread_wakeup。换句话说，这个event pipe读的操作应该是在io_thread_wakeup()函数中，那么是由谁执行写操作的呢？这个还不是很清楚，只知道write fd记录到了全局变量io_thread_fd中，也就是说在qemu-kvm任何地方都可以引用io_thread_fd向pipe写东西。 它还调用qemu_signalfd创建一个signal thread，不过现在还不清楚为什么要单独创建一个这样的线程。qemu_signalfd中还会创建一个signal pipe，read fd同样用qemu_set_fd _hadnler2注册一个read fd handler——sigfd_handler，而write fd作为参数传递给signal thread执行函数，也就是说写操作应该是由signal thread负责的。为什么要创建一个signal thread和signal pipe呢？ 上面提到用qemu_set_fd_handler2注册的handler在fd ready时，io thread会通过某种机制调用相应地handler。这个机制是main_loop_wait函数实现的。main_loop_wait函数中将所有注册的r/w fd都加入到对应地r/w fd_set中，然后调用select系统调用，这个系统调用将检查相应fd_set中的fd是否有已ready的，如果没有一个ready，将使得调用线程阻塞直到超时，否则将返回，并将原来fd_set修改，将没有ready的fd从原fd_set中删除。返回后，通过遍历handler队列，检测其fd是否在fd_set中，并调用相应的handler。 我记得中说过，发送给这个qemu process的信号可以由process内任意的thread来处理， 但是每个线程都可以设置mask来选择是否处理某信号。那么为什么要单独设置一个signal thread来接受信号呢？实际上，用signal thread这种机制是将原本对指定信号的处理由异步方式改成同步方式。 默认异步方式时，信号发送给本qemu process后，内核将检测是否有pending signal，如果有内核将调用相应的handler，而这个执行实体可以是process中任意的thread。这样，thread有可能因为信号的到来，而被临时打断，去执行handler。 同步方式是这样的，首先sigprocmask系统调用屏蔽掉指定的signal，这样process将不再接受这个signal(当然，每个thread都有屏蔽码的，但是应该是调用pthread_sigmask，调用sigprocmask将使整个process不接受)。然后，创建一个signal thread，其执行代码调用sigwaitinfo函数，等待指定的信号，如果无信号则signal thread阻塞在这个系统调用中，否则返回，将siginfo_t写入signal pipe中。最后，io thread通过select系统调用检测到signal pipe read_fd ready，然后调用相应的read_fd handler，fd handler再调用相应的signal handler。 可以看到，同步方式虽然代价比异步方式大得多，需要多创建一个signal pipe和signal thread，但是它不会突然打断thread执行，对于程序响应性有利。这个跟interrupt和polling之间的比较类似，当外部事情来时，执行内核的中断服务例程，interrupt handler有可能发送一个信号给要处理事件的process。 之前发现一个很奇怪的现象：在我的电脑上跑的qemu-kvm有4个线程，而其他同学电脑上跑只有2个线程。我原本觉得奇怪，按照前面的论述，qemu-kvm至少得有3个线程才是，只有2个线程的话，那么signal thread去哪里了呢？带着这个问题，对两种情况的代码做了一下trace，结果发现是在qemu_signalfd (compatfd.c)函数中出现了差异—如果系统有定义CONFIG_SIGNALFD宏，那么就不会创建signal thread，否则就创建。不太理解的是，我的装的是32位CentOS，结果没有SIGNALFD，而其他装的是64位CentOS，是有SIGNALFD的。那么signalfd是什么呢？简单的说，就是一个线程可以创建一个signalfd，指定哪些signal可以由它来接受，当信号来时，就不是像原来那样去调用signal handler，而是将siginfo_t写入signalfd，线程通过read或select或poll就可以知道signalfd是否接受到了新的signal。这样，在由signalfd情况下，就没有必要创建signal thread了。这样，就减少了一点开销。原来是signal thread通过sigwaitinfo检测到signal，然后将siginfo_t写入signal pipe，io thread通过select检测到signal pipe read fd ready，然后读出siginfo_t，再调用handler；现在是，内核直接将siginfo_t写入signalfd，io thread通过select检测到signalfd ready，然后读出读出siginfo_t，再调用handler。很显然，省去了额外signal thread的开销。总之，只要先用sigprocmask将可能接受的signal block掉，再用select+signalfd或者是sigwaitinfo都可以讲异步signal转变为同步signal。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
</search>
