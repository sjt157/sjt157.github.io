<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[谷歌之Percolator模型]]></title>
    <url>%2F2018%2F12%2F15%2F%E8%B0%B7%E6%AD%8C%E4%B9%8BPercolator%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[论文今天读了一篇论文https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf 思考 在谷歌的索引系统中。通过MapReduce将爬取下来的页面弄到Percolator中，该模型提供用户随机访问一个超大的数据库，避免了MapReduce的全局scan。该模型中因为有很多线程并发，所以提供了ACID。 Percolator由一系列observers组成。每个observer可以完成一个任务而且可以为下游的observers指派更多的任务。 Percolator使用于增量处理。 该模型如下图，A Percolator system由这三部分组成。还需要依赖两个服务the timestamp oracle and the lightweight lock service。该模型的事务：Percolator provides cross-row, cross-table transactions with ACID snapshot-isolation semantics. 提出了snapshot isolation。意思如图 这里边还讲了个很有意思的比喻。扫描线程一多可能会导致parallelism的减少，拿公交车来作比喻，公交车一慢，会导致等的乘客过多，从而导致车更慢。该模型中为了解决这个问题，采取了如下做法：当一个线程发现别的线程慢的时候，它选择一个随机的位置进行扫描。 TiDB通过查询知道TiKV 的事务采用的就是是 Percolator 模型，并且做了大量的优化。事务的细节这里不详述，大家可以参考论文。这里只提一点，TiKV 的事务采用乐观锁，事务的执行过程中，不会检测写写冲突，只有在提交过程中，才会做冲突检测，冲突的双方中比较早完成提交的会写入成功，另一方会尝试重新执行整个事务。当业务的写入冲突不严重的情况下，这种模型性能会很好，比如随机更新表中某一行的数据，并且表很大。但是如果业务的写入冲突严重，性能就会很差，举一个极端的例子，就是计数器，多个客户端同时修改少量行，导致冲突严重的，造成大量的无效重试。 初体验TiDB 通过docker-compose来部署，目前为止，所以组件已经准备完毕，如图 123访问集群: mysql -h 127.0.0.1 -P 4000 -u root访问集群 Grafana 监控页面: http://localhost:3000 默认用户名和密码均为 admin。集群数据可视化： http://localhost:8010 效果如图：]]></content>
      <categories>
        <category>TiDB</category>
      </categories>
      <tags>
        <tag>TiDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VM与HOST之间传输文件]]></title>
    <url>%2F2018%2F12%2F12%2FVM%E4%B8%8EHOST%E4%B9%8B%E9%97%B4%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[今天老师有一个需求，是从host向qemu创建的虚拟机中传输文件，调研了几个方法，起初是通过网络传输，但是在新的这个平台上没有搭建网桥等设备，而且想还没有别的其他的方式。经过查询，主要有以下方式： 共享文件夹的方式Docker中也有此方法https://blog.csdn.net/zhongbeida_xue/article/details/80747212?utm_source=blogxgwz9 把数据存到usb设备（可真可假）中https://blog.csdn.net/kingtj/article/details/82952783 总结：qemu-kvm虚拟机与宿主机之间实现文件传输，大概两类方法： 虚拟机与宿主机之间，使用网络来进行文件传输。这个需要先在宿主机上配置网络桥架，在qemu-kvm启动配置网卡就可以实现文件传输。 使用9psetup协议实现虚拟机与宿主机之间文件传输。该方法先要宿主机需要在内核中配置了9p选项，即：12345CONFIG_NET_9P=yCONFIG_net_9P_VIRTIO=yCONFIG_NET_9P_DEBUG=y (可选项)CONFIG_9P_FS=yCONFIG_9P_FS_POSIX_ACL=y 另外，qemu在编译时需要支持ATTR/XATTR。 综上，两类方法配置起来都比较麻烦。其实有一个比较简单的方法123456789101. 使用dd创建一个文件，作为虚拟机和宿主机之间传输桥梁 dd if=/dev/zero of=/opt/share.img bs=1M count=2002. 格式化share.img文件 mkfs.ext4 /opt/share.img3. 在宿主机上创建一个文件夹， mkdir /tmp/share mount -o loop /opt/share.img /tmp/share这样，在宿主机上把需要传输给虚拟机的文件放到/tmp/share 下即可。4. 启动qemu-kvm虚拟机，添加上/opt/share.img文件。5. 在虚拟机中 mount上添加的一块硬盘。即可以获得宿主机上放在/tmp/share文件夹下的文件 但是该方法有个缺点：宿主机和虚拟机文件传输不能实时传输。如果需要传输新文件，需要重启虚拟机。 有没有其他的方式呢还？待补充。。。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国密算法之SM4]]></title>
    <url>%2F2018%2F12%2F12%2F%E5%9B%BD%E5%AF%86%E7%AE%97%E6%B3%95%E4%B9%8BSM4%2F</url>
    <content type="text"><![CDATA[为什么用SM4加密后文件会略长于明文文件？ 首先了解什么是SM4算法 参考： https://blog.csdn.net/Soul_Programmer_Swh/article/details/80263822 https://www.cnblogs.com/TaiYangXiManYouZhe/p/4317519.html https://blog.csdn.net/cg129054036/article/details/83016958 原因就在于sm4 算法加解密时，采用的是 TCM_ES_SM4_CBC 模式，该模式会填 充加密数据以保证其长度为 16 的整数倍，因此加密后文件会略长于明文文件，解 密后文件长度将恢复。 那么什么是又CBC？在密码学中，分组加密（英语：Block cipher），又称分块加密或块密码，是一种对称密钥算法。它将明文分成多个等长的模块（block），使用确定的算法和对称密钥对每组分别加密解密。分组加密是极其重要的加密协议组成，其中典型的如DES和AES作为美国政府核定的标准加密算法，应用领域从电子邮件加密到银行交易转帐，非常广泛。现代分组加密创建在迭代的思想上产生密文。其思想由克劳德·香农在他1949年的重要论文《保密系统的通信理论》（Communication Theory of Secrecy Systems）中提出，作为一种通过简单操作如替代和排列等以有效改善保密性的方法。[1] 迭代产生的密文在每一轮加密中使用不同的子密钥，而子密钥生成自原始密钥。DES加密在1977年由前美国国家标准局（今“美国国家标准与技术研究所”）颁布，是现代分组加密设计的基础思想。它同样也影响了密码分析的学术进展。 https://zh.wikipedia.org/wiki/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F#%E5%AF%86%E7%A0%81%E5%9D%97%E9%93%BE%E6%8E%A5%EF%BC%88CBC%EF%BC%89 SM9算法 SM9标识密码算法是由国密局发布的一种IBE(Identity-Based Encryption)算法。IBE算法以用户的身份标识作为公钥，不依赖于数字证书。 IBC(基于标示的密码技术) 基于证书的公钥体制在应用中面临诸多问题，特别是证书使用过程的复杂性使得不具备相关知识的普通用户难以驾驭。为了降低公钥系统中密钥管理和使用的复杂性，Shamir在1984[S84]年提出了基于标识的密码技术(Identity-Based Cryptography - IBC)：即用户的标识就可以用做用户的公钥（更加准确地说是用户的公钥可以从用户的标识和系统指定的一个方法计算得出）。 在这种情况下，用户不需要申请和交换证书，从而极大地简化了密码系统管理的复杂性。用户的私钥由系统中的一受信任的第三方（密钥生成中心）使用标识私钥生成算法计算生成。这样的系统具有天然的密码委托功能，适合于有监管的应用环境。 NTLS(下一代安全传输协议)]]></content>
      <categories>
        <category>TrustComputing</category>
      </categories>
      <tags>
        <tag>TrustComputing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker化我的秒杀项目]]></title>
    <url>%2F2018%2F12%2F09%2FDocker%E5%8C%96%E6%88%91%E7%9A%84%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[Docker化秒杀项目 首先构建jar包，因为该秒杀基于maven的，第一开始想把配置文件啥的都放一起，可以用一些eclipse插件啥的，但是后来一想这样不好，因为如果我想改配置的话需要重新构建，所以在网上找了个方法，构建好maven install 之后是这样子的，参考的这篇文章http://https://blog.csdn.net/qq_22857293/article/details/79416165，最后构建之后的结果如图，可以看出第三方依赖，配置文件，资源分离开来： （当把jar包通过Xshell上传文件的时候出现了不能上传的问题，这是因为目标目录没有相应写权限造成的，通过chmod o+w 赋予相应权限即可。） * 启动jar包的命令是java -jar -Dloader.path=.,config,resources,3rd-lib miaosha.jar然后我写了Dockerfile，内容如下：构建镜像 docker build -t sjt157/miaoshaapp:v2 .（注意后边有个.）运行docker容器：docker run -d -p 65534:65510 sjt157/miaoshaapp:v2 Docker化Rabbit1234首先pull官方镜像，Docker pull rabbitmq:3启动docker run -d --name miaosharabbit -p 5672:5672 -p 15672:15672 rabbitmq:3当时启动rabbit容器的时候出现了异常 An unexpected connection driver error occurred的话，执行这个 Docker化Mysql 首先拉取镜像，docker pull mysql:5.7 使用镜像创建容器 docker run -p 3306:3306 --name miaoshaMysql -e MYSQL_ROOT_PASSWORD=123 -d mysql:5.7 进入容器 docker exec -it miaoshaMysql bash 进入mysql -uroot -p 输入 GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123' WITH GRANT OPTION; FLUSH PRIVILEGES; 复制sql文件到容器 docker inspect -f '{{.ID}}' miaoshaMysql docker cp 本地路径 容器长ID:容器路径 我把文件考到了根目录下 docker cp /home/ubuntu16/docker/miaoshaMysql/seckill.sql 561e41a0347d:/ 首先进入mysql 创建数据库 create database miaosha; 在执行mysql -uroot -p miaosha &lt; miaosha.sql命令导入文件 我要把原镜像 重新弄一个我的数据库镜像 docker commit -m "added miaosha.sql" -a "sjt157" 561e41a0347d sjt157/miaoshamysql:v2 运行我自己的镜像 docker run -p 3306:3306 --name miaoshamysql -e MYSQL_ROOT_PASSWORD=123 -d sjt157/miaoshamysql:v2 此处有个疑问？？？为什么在官方mysql镜像上 我做了相应操作，存了文件，执行了命令，只有文件被保存了，但是 我做的其他命令 却没有保存上？？？比如创建数据库表等命令 这是为什么？那如果是用Dockerfile创建的自己的镜像会不会也是这样呢，相关命令不保存？？？还有一个，为什么容器已经是退出状态了，却也不能重名呢？？必须要rm掉吗。因为已经是退出状态了，所以不能kill。 Docker化Redis不用 redis.password=123456这个加密码的配置了，因为默认的官方镜像是没有的。docker pull redis:4（有个疑问。不能制定详细的版本信息吗？？应该可以把）启动redis容器docker run -p 6379:6379 –name miaosharedis -d redis最后可以看到4个容器均运行成功。 下一步工作这样太麻烦了，每次都要手动执行，能不能自动编排呢？利用compose来操作。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack-vm-cannot-ssh]]></title>
    <url>%2F2018%2F12%2F09%2Fopenstack-vm-cannot-ssh%2F</url>
    <content type="text"><![CDATA[云之迷雾 今天发现了一件奇事，过程是这样的，我想SSH一个虚拟机，但是怎么也出不来，排除了防火墙等等一系列原因都无果，结果想到了在VNC界面上查看一下，不看还好，一看吓了自己一跳，为什么在3月份创建虚拟机的时候明明指定的IP是172.21.4.68，但是不知道怎么自己偷摸摸的变成了172.21.4.197。我也不能在现在再改该虚拟机IP，因为按openstack的规定：虚拟机的IP默认都是DHCP分配的，如果要设置固定IP，需要在创建虚拟机时就指定，直接在虚拟机上更改IP是会被过滤的，所以此法无效。 现在的情况就是除了通过在VNC界面查看ip是172.21.4.197 以外 ， 在电科华云界面上 和 通过openstack的命令查看的ip 都是 172.21.4.68 ，也就是说虚拟机的IP是真的改了，但是openstack还未知道。到底是哪的原因呢？按照重启大法重启了两次，发现自己又变成了172.21.4.68的网址，后来左思右想都不对，再仔细一看，原来Bcast的地方变成了172.21.6.255，按道理来讲正常应该为172.21.4.255，为什么会变成172.21.6.255呢？ 首先，我查了一下什么是Bcast：broadcast address 即广播地址。Broadcast Address(广播地址)是专门用于同时向网络中所有工作站进行发送的一个地址。在使用TCP/IP 协议的网络中，主机标识段host ID 为全1 的IP 地址为广播地址，广播的分组传送给host ID段所涉及的所有计算机。例如，对于172.21.4.0（255.255.255.0 ）网段，其广播地址为172.21.4.255 （255 即为2 进制的11111111 ），当发出一个目的地址为172.21.4.255 的分组（封包）时，它将被分发给该网段上的所有计算机。按正常来讲，这些信息都是由DHCP服务器来分配的，那么是不是也就是说可能存在别的DHCP服务器（比如172.21.6.X）扰乱了这个虚拟机的网络，而且按正常来讲，B类私有网址（172.21.4.X）的网络掩码应该是255.255.0.0，现在是255.255.255.0，这样做是为了能多一些子网。多8位掩码，就是多了2的8次方个子网（256个），毕竟学校没有那么多网络资源。在虚拟机正常的情况下我查看了一下该虚拟机上的syslog情况，发现了如下： 可知该虚拟机正常情况下与172.21.4.3这个dhcp服务器进行了 交互，DHCP租约过程就是DHCP客户机动态获取IP地址的过程。DHCP租约过程分为4步：①客户机请求IP（客户机发DHCPDISCOVER广播包）；②服务器响应（服务器发DHCPOFFER广播包）；③客户机选择IP（客户机发DHCPREQUEST广播包）；④服务器确定租约（服务器发DHCPACK/DHCPNAK广播包）。我又查看了一下出问题的这个虚拟机的日志（出问题的时候）发现了问题 可以发现这个出问题的虚拟机早先通过了172.21.4.254进行了DHCP交互，获得了有问题的IP地址，因为这个iP地址是它分配的，所以也ping不通就很正常了，因为172.21.4.254也ping不通，这个是我们学校的网关，还有一个网关是172.21.6.254，可得出结论：172.21.4.254不仅是一个网关还是一个dhcp服务器，还有一张图，如下 172.21.201.1 是一个DHCP服务器也。而且不单单是4网段的会与之交互，连6网段的也会与之交互，难道说172.21.201.1是一个学校总的DHCp服务器？经过查看别的服务器可确定172.21.201.1确实是一个DHCP服务器。是不是可能172.21.4.254是一个中继DHCP服务呢？DHCP服务器是可以分配不同网段的IP地址的，可以通过两个网卡，比如一个网卡可以提供4网段的，一个可以提供6网段的，这样也和日志上的证据对上了。 最后，经过查看一批虚拟机发现所有的都会与172.21.4.3（既有DNS也有DHCP）交互，难道是那个有问题的虚拟机与172.21.4.254，然后再与172.21.201.1 进行DHCP交互，扰乱了正常的应该与172.21.4.3的交互？最后经与云提供商询问，可能就是这个原因 结论 最后的猜想：是不是因为172.21.201.1扰乱了我们的虚拟机，毕竟广播地址是172.21.6.255，现在我有个问题就是Bcast由谁来决定？？？？？]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BloomFilter]]></title>
    <url>%2F2018%2F09%2F14%2FBloomFilter%2F</url>
    <content type="text"><![CDATA[简介BloomFilter（布隆过滤器）是一种可以高效地判断元素是否在某个集合中的算法。 在很多日常场景中，都大量存在着布隆过滤器的应用。例如：检查单词是否拼写正确、网络爬虫的URL去重、黑名单检验，微博中昵称不能重复的检测。在工业界中，Google著名的分布式数据库BigTable也用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的IO次数；Google Chrome浏览器使用BloomFilter来判断一个网站是否为恶意网站。 对于以上场景，可能很多人会说，用HashSet甚至简单的链表、数组做存储，然后判断是否存在不就可以了吗？ 当然，对于少量数据来说，HashSet是很好的选择。但是对于海量数据来说，BloomFilter相比于其他数据结构在空间效率和时间效率方面都有着明显的优势。 但是，布隆过滤器具有一定的误判率，有可能会将本不存在的元素判定为存在。因此，对于那些需要“零错误”的应用场景，布隆过滤器将不太适用。具体的原因将会在第二部分中介绍。 在本文的第二部分，本文将会介绍BloomFilter的基本算法思想；第三部分将会基于Google开源库Guava来讲解BloomFilter的具体实现；在第四部分中，将会介绍一些开源的BloomFilter的扩展，以解决目前BloomFilter的不足。 算法讲述布隆过滤器是基于Hash来实现的，在学习BloomFilter之前，也需要对Hash的原理有基本的了解。个人认为，BloomFilter的总体思想实际上和bitmap很像，但是比bitmap更节省空间，误判率也更低。 BloomFilter的整体思想并不复杂，主要是使用k个Hash函数将元素映射到位向量的k个位置上面，并将这k个位置全部置为1。当查找某元素是否存在时，查找该元素所对应的k位是否全部为1即可说明该元素是否存在。 缺点BloomFilter 由于并不存储元素，而是用位的01来表示元素是否存在，并且很有可能一个位时被多个元素同时使用。所以无法通过将某元素对应的位置为0来删除元素。 幸运的是，目前学术界和工业界都有很多方法扩展已解决以上问题。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#include "bloomfilter.h"#include "hashs.h"//#include "md5.h" #include "crc32.h"//#include "sha1.h"#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#define HASH_FUNC_NUM 8#define BLOOM_SIZE 1000000#define BITSIZE_PER_BLOOM 32#define LIMIT (BLOOM_SIZE * BITSIZE_PER_BLOOM)/* * m=10n, k=8 when e=0.01 (m is bitsize, n is inputnum, k is hash_func num, e is error rate) * here m = BLOOM_SIZE*BITSIZE_PER_BLOOM = 32,000,000 (bits) * so n = m/10 = 3,200,000 (urls) * enough for crawling a website */static int bloom_table[BLOOM_SIZE] = &#123;0&#125;;pthread_mutex_t bt_lock = PTHREAD_MUTEX_INITIALIZER;//static MD5_CTX md5;//static SHA1_CONTEXT sha; static unsigned int encrypt(char *key, unsigned int id)&#123; unsigned int val = 0; switch(id)&#123; case 0: val = times33(key); break; case 1: val = timesnum(key,31); break; case 2: val = aphash(key); break; case 3: val = hash16777619(key); break; case 4: val = mysqlhash(key); break; case 5: //basically multithreads supported val = crc32((unsigned char *)key, strlen(key)); break; case 6: val = timesnum(key,131); break; /* int i; unsigned char decrypt[16]; MD5Init(&amp;md5); MD5Update(&amp;md5, (unsigned char *)key, strlen(key)); MD5Final(&amp;md5, decrypt); for(i = 0; i &lt; 16; i++) val = (val &lt;&lt; 5) + val + decrypt[i]; break; */ case 7: val = timesnum(key,1313); break; /* sha1_init(&amp;sha); sha1_write(&amp;sha, (unsigned char *)key, strlen(key)); sha1_final(&amp;sha); for (i=0; i &lt; 20; i++) val = (val &lt;&lt; 5) + val + sha.buf[i]; break; */ default: // should not be here abort(); &#125; return val;&#125;int search(char *url)&#123; unsigned int h, i, index, pos; int res = 0; pthread_mutex_lock(&amp;bt_lock); for (i = 0; i &lt; HASH_FUNC_NUM; i++) &#123; h = encrypt(url, i); h %= LIMIT; index = h / BITSIZE_PER_BLOOM; pos = h % BITSIZE_PER_BLOOM; if (bloom_table[index] &amp; (0x80000000 &gt;&gt; pos)) res++; else bloom_table[index] |= (0x80000000 &gt;&gt; pos); &#125; pthread_mutex_unlock(&amp;bt_lock); return (res == HASH_FUNC_NUM);&#125;]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux可以Ping通但不能traceroute]]></title>
    <url>%2F2018%2F07%2F10%2FLinux%E5%8F%AF%E4%BB%A5Ping%E9%80%9A%E4%BD%86%E4%B8%8D%E8%83%BDtraceroute%2F</url>
    <content type="text"><![CDATA[今天闲来无事，想弄清楚学校至百度服务器的网络问题，结果不试不知道，一试吓一跳。完全出乎我的意料。我们学校的网关是172.21.6.254,172.21.4.254和172.21.7.254。发现可以ping通学校网关，却不能traceroute。如下图： 这是为什么？查了一下资料： windows的tracert预设是走ICMP协议，而linux的traceroute则预设走UDP协议，若两端点之间的UDP connection被任何firewall挡掉, 那 traceroute 就不行了. 原因好像大概知道了，就是有firewall把udp给挡掉了。解决方法：traceroute -I 加I参数改用ICMP协议。即下图，果然成功了。可以发现，从我的服务器到达百度服务器经过了21跳。 12345678910111213141516171819202122traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets 1 192.168.1.1 (192.168.1.1) 实验室路由器 2 172.21.6.254 (172.21.6.254) 学校网关内接口 3 172.21.200.5 (172.21.200.5) 学校网关外接口 4 172.30.201.6 (172.30.201.6) 本地局域网 5 211.71.94.251 (211.71.94.251) 北京市朝阳区 教育网 6 124.207.38.253 (124.207.38.253) 北京市 鹏博士宽带 7 * * * (有的就是这么设置，便于隐藏) 8 10.10.1.1 (10.10.1.1) 4.997 ms 本地局域网 9 218.241.251.105 (218.241.251.105) 北京市 鹏博士宽带10 218.241.253.241 (218.241.253.241) 北京市 鹏博士宽带11 218.241.245.181 (218.241.245.181) 北京市 鹏博士宽带12 202.99.1.173 (202.99.1.173) 北京市 鹏博士宽带13 * * *14 * * *15 202.106.42.97 (202.106.42.97) 北京市北京市 联通16 61.148.154.97 (61.148.154.97) 北京市 联通17 * * *18 61.148.146.194 (61.148.146.194) 北京市 联通19 61.49.168.98 (61.49.168.98) 北京市 联通20 * * *21 123.125.115.110 (123.125.115.110) 北京市 联通 (百度服务器) 那么我们就来了解一下traceroute的工作原理：Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。前面说到，尽管ping工具也可以进行侦测，但是，因为ip头的限制，ping不能完全的记录下所经过的路由器。所以Traceroute正好就填补了这个缺憾。Traceroute的原理是非常非常的有意思，它受到目的主机的IP后，首先给目的主机发送一个TTL=1（还记得TTL是什么吗？）的UDP(后面就 知道UDP是什么了)数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器ip。从而避开了ip头只能记录有限路由IP的问题。有人要问，我怎么知道UDP到没到达目的主机呢？这就涉及一个技巧的问题，TCP和UDP协议有一个端口号定义，而普通的网络程序只监控少数的几个号码较 小的端口，比如说80,比如说23,等等。而traceroute发送的是端口号&gt;30000(真变态)的UDP报，所以到达目的主机的时候，目的 主机只能发送一个端口不可达的ICMP数据报给主机。主机接到这个报告以后就知道，主机到了，所以，说Traceroute是一个骗子一点也不为过Traceroute程序里面提供了一些很有用的选项，甚至包含了IP选路的选项。 当我以为终于弄懂得时候，我发现还是太年轻了，在windows我又手贱的试了一下，又发现了问题。为什么windows下也能ping通，但不能traceroute呢？ 欲知结果如何，还是待我知道以后。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器不能上网之谜]]></title>
    <url>%2F2018%2F05%2F11%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8D%E8%83%BD%E4%B8%8A%E7%BD%91%E4%B9%8B%E8%B0%9C%2F</url>
    <content type="text"><![CDATA[因为服务器一重启很多配置就要重新配，很麻烦，那么有没有一种方式可以实现开机自启动。当然有了，那就是配置rc.local文件了！ 那什么是rc.local脚本嗯？rc.local脚本是一个Ubuntu开机后会自动执行的脚本，我们可以在该脚本内添加命令行指令。该脚本位于/etc/路径下，需要root权限才能修改。该脚本具体格式如下： 1234567891011121314#!/bin/sh -e## rc.local## This script is executed at the end of each multiuser runlevel.# Make sure that the script will "exit 0" on success or any other# value on error.## In order to enable or disable this script just change the execution# bits.## By default this script does nothing.exit 0 注意: 一定要将命令添加在exit 0之前。里面可以直接写命令或者执行Shell脚本文件sh。 下面这个是用来开机自启动网络的命令 12345678# add by SongJianTao 2018-5-8# use to config network autoip addr del dev enp11s0 192.168.1.50/24tunctl -t tap0brctl addif be-ex tap0ifconfig tap0 0.0.0.0 promisc up#end by SongJianTao 注意如果不生效的话，可以尝试rc.local文件头部/bin/sh修改为/bin/bash，还可以增加日志输出功能，来查看最终为什么这个脚本不启动的原因，代码如下所示： 12345#logexec 2&gt; /tmp/rc.local.log # send stderr from rc.local to a log file exec 1&gt;&amp;2 # send stdout to the same log file set -x # tell sh to display commands before execution 今天正在奋笔疾书、焦头烂额的写报告，老胡说他要上网，但是服务器怎么也上不去网，查了很多原因也不知道（mmp，原来没出现过这种情况啊），经过层层排查，最后可能是因为交换机长期没有关的的问题，导致不能用（交换机的质量这么差的吗）， 所以直接把网线接在了路由器上，那就要更改配置了，不要直接在/etc/resolve.conf那设置，因为重启会消失，要在/etc/resolvconf/resolv.conf.d/base 这个文件下改，加上nameserver 192.168.1.1 这样就可以了，然后果然可以了，所以这个不能赖我了，要赖交换机！这个锅我不背！]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速排序]]></title>
    <url>%2F2018%2F04%2F27%2F%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[快速排序的基本思想快速排序（Quicksort）是对冒泡排序的一种改进。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 快速排序的三个步骤1.选择基准：在待排序列中，按照某种方式挑出一个元素，作为 “基准”（pivot）；2.分割操作：以该基准在序列中的实际位置，把序列分成两个子序列。此时，在基准左边的元素都比该基准小，在基准右边的元素都比基准大；3.递归地对两个序列进行快速排序，直到序列为空或者只有一个元素； 选择基准元的方式对于分治算法，当每次划分时，算法若都能分成两个等长的子序列时，那么分治算法效率会达到最大。也就是说，基准的选择是很重要的。选择基准的方式决定了两个分割后两个子序列的长度，进而对整个算法的效率产生决定性影响。最理想的方法是，选择的基准恰好能把待排序序列分成两个等长的子序列。1.固定基准元：如果输入序列是随机的，处理时间是可以接受的。如果数组已经有序时，此时的分割就是一个非常不好的分割。因为每次划分只能使待排序序列减一，此时为最坏情况，快速排序沦为冒泡排序，时间复杂度为Θ(n^2)。而且，输入的数据是有序或部分有序的情况是相当常见的。因此，使用第一个元素作为基准元是非常糟糕的，应该立即放弃这种想法。2.随机基准元：这是一种相对安全的策略。由于基准元的位置是随机的，那么产生的分割也不会总是会出现劣质的分割。在整个数组数字全相等时，仍然是最坏情况，时间复杂度是O(n^2）。实际上，随机化快速排序得到理论最坏情况的可能性仅为1/(2^n）。所以随机化快速排序可以对于绝大多数输入数据达到O(nlogn）的期望时间复杂度。3.三数取中:引入的原因：虽然随机选取基准时，减少出现不好分割的几率，但是还是最坏情况下还是O(n^2），要缓解这种情况，就引入了三数取中选取基准。分析：最佳的划分是将待排序的序列分成等长的子序列，最佳的状态我们可以使用序列的中间的值，也就是第N/2个数。可是，这很难算出来，并且会明显减慢快速排序的速度。这样的中值的估计可以通过随机选取三个元素并用它们的中值作为基准元而得到。事实上，随机性并没有多大的帮助，因此一般的做法是使用左端、右端和中心位置上的三个元素的中值作为基准元。显然使用三数中值分割法消除了预排序输入的不好情形，并且减少快排大约5%的比较次数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576 #include&lt;stdio.h&gt; //交换子表的记录，使枢轴记录到位，并返回枢轴所在的位置 int Partition(int array[], int low, int high)&#123; /*三数中值分割法*/ int m = low + (high - low) / 2;//数组中间元素的下标 if (array[low]&gt;array[high]) //保证左端较小 swap(array, low, high); if (array[m] &gt; array[high]) //保证中间较小 swap(array, high, m); if (array[m] &gt; array[low]) swap(array, m, low); //保证左端最小 //此时array[low]已经为整个序列左中右三个关键字的中间值 int pivotkey = array[low]; /*固定基准元 int pivotkey = array[low]; */ /*随机基准元 int randomIndex = rand() % (high - low) + low;//取数组中随机下标 swap(array, randomIndex, low); //与第一个数交换 int pivotkey = array[low]; */ int i = low, j = high; while(i&lt;j) //从表的两端交替向中间扫描,当没有相遇 &#123; while (array[j] &gt;= pivotkey&amp;&amp;i&lt;j)&#123; j--; &#125; while (array[i] &lt;= pivotkey&amp;&amp;i&lt;j)&#123; i++; &#125; if (i&lt;j) &#123; swap(array, i, j); &#125; &#125; //最终将基准数归位 swap(array, low, i); return i; //返回枢轴所在的位置 &#125; void QSort(int array[], int low, int high)&#123; int pivot; if (low&lt;high) &#123; pivot = Partition(array, low, high);//算出枢轴值 QSort(array, low, pivot - 1); //对低子表递归排序 QSort(array, pivot + 1, high); //对高子表递归排序 &#125; &#125; void swap(int array[], int i, int j)&#123; //0∧0=0,0∧1=1,1∧1=0 //i,j为需要交换数值的数组下标 if(i == j) return;//下标相同直接返回 array[i] = array[i]^array[j]; array[j] = array[i]^array[j]; array[i] = array[i]^array[j];&#125;//对array做快速排序 int main()&#123; int array[] = &#123;9, 2, 4, 3, 5, 1, 0, 7, 8, 6&#125;; int i; int n = sizeof(array)/sizeof(int); QSort(array, 0, n - 1); for( i = 0; i &lt; n; i++) printf("%d", array[i]); return 0;&#125; 快速排序的优化对于很小的数组（N&lt;=20）,快速排序不如插入排序好。不仅如此，因为快速排序是递归的，所以这样的情况经常发生。通常的解决办法是对于小的数组不递归的使用快速排序，而代之以诸如插入排序这样的对小数组有效的排序算法。使用这种策略实际上可以节省大约15%的（相对于自始至终使用快速排序时）的运行时间。一种好的截止范围是N=10，虽然在5到20之间任一截止范围都有可能产生类似的结果。下面是代码： 123456789101112 void QSort(int array[], int low, int high)&#123; int pivot; if (high-low+1&gt;=10) &#123; pivot = Partition(array, low, high);//算出枢轴值 QSort(array, low, pivot - 1); //对低子表递归排序 QSort(array, pivot + 1, high); //对高子表递归排序 &#125; else&#123; InsertSort(array+low, high-low+1); //插入排序 &#125; &#125; 插入排序代码： 123456789101112void InsertSort(int array[], int n)&#123;int j;for (int i = 1; i &lt; n;++i)&#123; int key = array[i]; for (j = i; j&gt;0 &amp;&amp; array[j - 1] &gt; key;j--) &#123; array[j] = array[j - 1]; &#125; array[j] = key;&#125;&#125;]]></content>
      <categories>
        <category>Interview</category>
      </categories>
      <tags>
        <tag>InterView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[守护进程]]></title>
    <url>%2F2018%2F04%2F21%2F%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[什么是守护进程 守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是一种很有用的进 程。 Linux的大多数服务器就是用守护进程实现的。比如，Internet服务器inetd，Web服务器httpd等。同时，守护进程完成许多系统任务。 比如，作业规划进程crond，打印进程lpd等。 守护进程最重要的特性是后台运行。在这一点上DOS下的常驻内存程序TSR与之相似。其次，守护进程必须与其运行前的环境隔离开来。这些环 境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩模等。这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下 来的。最后，守护进程的启动方式有其特殊之处。它可以在Linux系统启动时从启动脚本/etc/rc.d中启动，可以由作业规划进程crond启动，还 可以由用户终端（通常是 shell）执行。 一个守护进程的父进程是init进程，因为它真正的父进程在fork出子进程后就先于子进程exit退出了，所以它是一个由init继承的孤儿进程。守护进程是非交互式程序，没有控制终端，所以任何输出，无论是向标准输出设备stdout还是标准出错设备stderr的输出都需要特殊处理。实现守护进程要注意的地方 在后台运行为避免挂起控制终端将Daemon放入后台执行。方法是在进程中调用fork使父进程终止，让Daemon在子进程中后台执行。if(pid=fork())exit(0); //是父进程，结束父进程，子进程继续 脱离控制终端，登录会话和进程组 有必要先介绍一下Linux中的进程与控制终端，登录会话和进程组之间的关系：进程属于一个进程组，进程组号（GID）就是进程组长的进程号（PID）。登录会话可以包含多个进程组。这些进程组共享一个控制终端。这个控制终端通常是创建进程的登录终端。 控制终端，登录会话和进程组通常是从父进程继承下来的。我们的目的就是要摆脱它们，使之不受它们的影响。方法是在第1点的基础上，调用setsid()使进程成为会话组长： setsid(); 说明：当进程是会话组长时setsid()调用失败。但第一点已经保证进程不是会话组长。setsid()调用成功后，进程成为新的会话组长和新的进程组长，并与原来的登录会话和进程组脱离。由于会话过程对控制终端的独占性，进程同时与控制终端脱离。 禁止进程重新打开控制终端现在，进程已经成为无终端的会话组长。但它可以重新申请打开一个控制终端。可以通过使进程不再成为会话组长来禁止进程重新打开控制终端： if(pid=fork()) exit(0); //结束第一子进程，第二子进程继续（第二子进程不再是会话组长） 关闭打开的文件描述符 进程从创建它的父进程那里继承了打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。按如下方法关闭它们： for(i=0;i 关闭打开的文件描述符close(i); 改变当前工作目录进程活动时，其工作目录所在的文件系统不能卸下。一般需要将工作目录改变到根目录。对于需要转储核心，写运行日志的进程将工作目录改变到特定目录如 /tmpchdir(“/“) 重设文件创建掩模进程从创建它的父进程那里继承了文件创建掩模。它可能修改守护进程所创建的文件的存取位。为防止这一点，将文件创建掩模清除：umask(0); 处理SIGCHLD信号处理SIGCHLD信号并不是必须的。但对于某些进程，特别是服务器进程往往在请求到来时生成子进程处理请求。如果父进程不等待子进程结 束，子进程将成为僵尸进程（zombie）从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下 可以简单地将 SIGCHLD信号的操作设为SIG_IGN。 signal(SIGCHLD,SIG_IGN); 这样，内核在子进程结束时不会产生僵尸进程。这一点与BSD4不同，BSD4下必须显式等待子进程结束才能释放僵尸进程。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之闭包]]></title>
    <url>%2F2018%2F04%2F17%2Fpython%E4%B9%8B%E9%97%AD%E5%8C%85%2F</url>
    <content type="text"><![CDATA[无意间，看到这么一道Python面试题：以下代码将输出什么？12345def Fun(): temp = [lambda x:i*x for i in range(4)] return tempfor everyLambda in Fun(): print(everyLambda(2)) 不是0,2,4,6，而是6,6,6,6 Python 的闭包的后期绑定导致的 late binding，这意味着在闭包中的变量是在内部函数被调用的时候被查找。因为在 for 里面 i 的值是不断改写的，但是 lambda 里面只是储存了 i 的符号，调用的时候再查找。所以结果是，当任何 testFun() 返回的函数被调用，在那时，i 的值是在它被调用时的周围作用域中查找，到那时，无论哪个返回的函数被调用，for 循环都已经完成了，i 最后的值是 3，因此，每个返回的函数 testFun 的值都是 3。因此一个等于 2 的值被传递进以上代码，它们将返回一个值 6 （比如： 3 x 2）。 那如何才能是0,2,4,6呢？ 创建一个闭包，通过使用默认参数立即绑定它的参数。为什么你加了默认参数就成功了呢？因为在创建函数的时候就要获取默认参数的值，放到 lambda 的环境中，所以这里相当于存在一个赋值，从而 lambda 函数环境中有了一个独立的 i。 12345 def Fun(): temp = [lambda x,i=i:i*x for i in range(4)] return tempfor everyLambda in Fun(): print(everyLambda(2)) 使用functools.partial 函数，把函数的某些参数（不管有没有默认值）给固定住（也就是相当于设置默认值） 123456 from functools import partialfrom operator import muldef Fun(): return [partial(mul,i) for i in range(4)]for everyLambda in Fun(): print(everyLambda(2)) 用生成器 1234 def Fun(): return (lambda x,i=i:i*x for i in range(4))for everyLambda in Fun(): print(everyLambda(2)) 利用yield的惰性求值的思想 12345 def Fun(): for i in range(4): yield lambda x: i*xfor everyLambda in Fun(): print(everyLambda(2))]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[协议的简单C/S程序]]></title>
    <url>%2F2018%2F04%2F15%2F%E5%8D%8F%E8%AE%AE%E7%9A%84%E7%AE%80%E5%8D%95C-S%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[C/S 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/socket.h&gt;#include &lt;string.h&gt; #define MAX_LINE 100 int main(int argc,char **argv)&#123; struct sockaddr_in sin; char buf[MAX_LINE]; int s_fd; int port = 8000; char *str = "test string"; char *serverIP = "127.0.0.1"; int n; if(argc &gt; 1) &#123; str = argv[1]; &#125; //服务器端填充 sockaddr结构 bzero(&amp;sin , sizeof(sin)); sin.sin_family = AF_INET; inet_pton(AF_INET,serverIP,(void *)&amp;sin.sin_addr); sin.sin_port = htons(port); int bReuseaddr=1; struct timeval nNetTimeout=&#123;0,1000&#125;;//1绉? if((s_fd = socket(AF_INET,SOCK_STREAM,0)) == -1) &#123; perror("fail to create socket"); exit(1); &#125; /*if(setsockopt(s_fd,SOL_SOCKET ,SO_REUSEADDR,&amp;bReuseaddr,sizeof(int)) == -1) &#123; perror("fail to set opt reuseaddr"); exit(1); &#125; */ if(setsockopt(s_fd,SOL_SOCKET ,SO_RCVTIMEO,&amp;nNetTimeout,sizeof(nNetTimeout)) == -1) &#123; perror("fail to set opt rcvtimeout"); exit(1); &#125; if(connect(s_fd,(struct sockaddr *)&amp;sin,sizeof(sin)) == -1) &#123; perror("fail to connect server"); exit(1); &#125; n = send(s_fd, str , strlen(str) + 1, 0); if(n == -1) &#123; perror("fail to send"); exit(1); &#125; n = recv(s_fd ,buf , MAX_LINE, 0); if(n == -1) &#123; perror("fail to recv"); exit(1); &#125; printf("the length of str = %s\n" , buf); if(close(s_fd) == -1) &#123; perror("fail to close"); exit(1); &#125; return 0;&#125; server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;ctype.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt; #define INET_ADDR_STR_LEN 1024#define MAX_LINE 100 int main(int argc,char **argv)&#123; struct sockaddr_in sin; struct sockaddr_in cin; int l_fd; int c_fd; socklen_t len; char buf[MAX_LINE]; char addr_p[INET_ADDR_STR_LEN]; int port = 8000; int n; bzero(&amp;sin , sizeof(sin)); sin.sin_family = AF_INET; sin.sin_addr.s_addr = INADDR_ANY; sin.sin_port = htons(port); //参数设置 int bReuseaddr=1; struct timeval nNetTimeout=&#123;0,10000&#125;;//10秒 if((l_fd = socket(AF_INET,SOCK_STREAM,0)) == -1) &#123; perror("fail to create socket"); exit(1); &#125; if(setsockopt(l_fd,SOL_SOCKET ,SO_REUSEADDR,&amp;bReuseaddr,sizeof(int)) == -1) &#123; perror("fail to set opt reuseaddr"); exit(1); &#125; if(setsockopt(l_fd,SOL_SOCKET ,SO_RCVTIMEO,&amp;nNetTimeout,sizeof(nNetTimeout)) == -1) &#123; perror("fail to set opt rcvtimeout"); exit(1); &#125; if(bind(l_fd,(struct sockaddr *)&amp;sin ,sizeof(sin) ) == -1) &#123; perror("fail to bind"); exit(1); &#125; if(listen(l_fd,10) == -1) &#123; perror("fail to listen"); exit(1); &#125; printf("waiting.....\n"); while(1) &#123; //if((c_fd = accept(l_fd,(struct sockaddr *)&amp;cin, &amp;len)) == -1) if((c_fd = accept(l_fd,NULL, 0)) == -1) &#123; // perror("fail to accept"); // exit(1); continue; &#125; n = recv(c_fd , buf, MAX_LINE, 0); if(n == -1) &#123; perror("fail to recv"); exit(1); &#125; else if(n == 0) &#123; printf("the connect has been closed\n"); close(c_fd); continue; &#125; //inet_ntop(AF_INET,&amp;cin.sin_addr,addr_p,sizeof(addr_p)); printf("content is : %s\n",buf); n = strlen(buf); sprintf(buf,"%d",n); n = send(c_fd , buf, sizeof(buf) + 1 , 0); if( n == -1) &#123; perror("fail to send"); exit(1); &#125; if(close(c_fd) == -1) &#123; perror("fail to close"); exit(1); &#125; &#125; if(close(l_fd) == -1) &#123; perror("fail to close"); exit(1); &#125; return 0;&#125; linux下基于简单socket编程实现C/S12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;netinet/in.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt; #define MAX_LINE 1024#define INET_ADDR_STR 16 void my_fun(char *p)&#123; if(p == NULL) &#123; return; &#125; for( ; *p != '\0' ; p++) &#123; if((*p &gt;= 'a') &amp;&amp; (*p &lt;= 'z')) &#123; *p = *p - 32; &#125; &#125; return;&#125;int main(int argc,char **argv)&#123; struct sockaddr_in sin; //服务器通信地址结构 struct sockaddr_in cin; //保存客户端通信地址结构 int l_fd; int c_fd; socklen_t len; char buf[MAX_LINE]; //存储传送内容的缓冲区 char addr_p[INET_ADDR_STR]; //存储客户端地址的缓冲区 int port = 8000; int n; bzero((void *)&amp;sin,sizeof(sin)); sin.sin_family = AF_INET; //使用IPV4通信域 sin.sin_addr.s_addr = INADDR_ANY; //服务器可以接受任意地址 sin.sin_port = htons(port); //端口转换为网络字节序 l_fd = socket(AF_INET,SOCK_STREAM,0); //创建套接子,使用TCP协议 bind(l_fd,(struct sockaddr *)&amp;sin,sizeof(sin)); listen(l_fd,10); //开始监听连接 printf("waiting ....\n"); while(1) &#123; c_fd = accept(l_fd,(struct sockaddr *)&amp;cin,&amp;len); n = read(c_fd,buf,MAX_LINE); //读取客户端发送来的信息 inet_ntop(AF_INET,&amp;cin.sin_addr,addr_p,INET_ADDR_STR); //将客户端传来地址转化为字符串 printf("client IP is %s,port is %d\n",addr_p,ntohs(cin.sin_port)); printf("content is : %s\n", buf); //打印客户端发送过来的数据 my_fun(buf); write(c_fd,buf,n); //转换后发给客户端 close(c_fd); &#125; printf("buf = %s\n",buf); if((close(l_fd)) == -1) &#123; perror("fail to close\n"); exit(1); &#125; return 0;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;string.h&gt;#include &lt;netinet/in.h&gt; #define MAX_LINE 1024 int main(int argc,char **argv)&#123; struct sockaddr_in sin; //服务器的地址 char buf[MAX_LINE]; int sfd; int port = 8000; char *str = "test string"; char *serverIP = "127.0.0.1"; if(argc &gt; 1) &#123; str = argv[1]; //读取用户输入的字符串 &#125; bzero((void *)&amp;sin,sizeof(sin)); sin.sin_family = AF_INET; //使用IPV4地址族 inet_pton(AF_INET,serverIP,(void *)&amp;(sin.sin_addr)); sin.sin_port = htons(port); /*理论上建立socket时是指定协议，应该用PF_xxxx，设置地址时应该用AF_xxxx。当然AF_INET和PF_INET的值是相同的，混用也不会有太大的问题。也就是说你socket时候用PF_xxxx，设置的时候用AF_xxxx也是没关系的，这点随便找个TCPIP例子就可以验证出来了。如下，不论是AF_INET还是PF_INET都是可行的，只不过这样子的话，有点不符合规范。*/ sfd = socket(AF_INET,SOCK_STREAM,0); connect(sfd,(struct sockaddr *)&amp;(sin),sizeof(sin)); printf("str = %s\n" , str); write(sfd , str , strlen(str) + 1); read(sfd , buf , MAX_LINE); printf("recive from server: %s\n" , buf); close(sfd); return 0;&#125;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openstack中的RPC请求分析]]></title>
    <url>%2F2018%2F04%2F08%2Fopenstack%E4%B8%AD%E7%9A%84RPC%E8%AF%B7%E6%B1%82%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[openstack中的RPC请求分析 首先，什么是RPC请求？我们都知道，rpc就是远程过程调用，是Openstack中一种用来实现跨进程(或者跨机器)的通信机制。Openstack中同项目内(如nova, neutron, cinder…)各服务(service)及通过RPC实现彼此间通信。Openstack中还有另外两种跨进程的通信方式：数据库和Rest API。一般情况下，openstack各个项目之间通过RestAPI接口进行相互访问，而项目内部服务之间则通过RPC请求的方式进行通信。 其他参考官网详细介绍了Openstack RPC中的基本概念及API设计http://https://wiki.openstack.org/wiki/Oslo/Messaging，其实它的rpc的设计参考了Sun RPC的设计，Sun RPC的介绍可以参看http://http://en.wikipedia.org/wiki/Open_Network_Computing_Remote_Procedure_Call这篇文章。 RPC的使用场景 随机调用某server上的一个方法：Invoke Method on One of Multiple Servers这个应该是Openstack中最常用的一种RPC调用，每个方法都会有多个server来提供，client调用时由底层机制选择一个server来处理这个调用请求。像nova-scheduler, nova-conductor都可以以这种多部署方式提供服务。这种场景通过AMQP的topic exchange实现。所有server在binding中为binding key指定一个相同的topic， client在调用时使用这个topic既可实现。 调用某特定server上的一个方法：Invoke Method on a Specific Server 一般Openstack中的各种scheduler会以这种方式调用。通常scheduler都会先选定一个节点，然后调用该节点上的服务。这种场景通过AMQP的topic exchange实现。每个server在binding中为其binding key指定一个自己都有的topic， client在调用时使用这个topic既可实现。 调用所有server上的一个方法：Invoke Method on all of Multiple Servers 这种其实就是一个广播系统。就像开会议，台上的人讲话，台下的人都能听到。Openstack中有些rpcapi.py的某些方法带有fanout=True参数，这些都是让所有server处理某个请求的情况。例子： neutron中所有plugin都会有一个AgentNotifierApi，这个rpc是用来调用安装在compute上的L2 agent。因为存在多个L2 agent(每个compute上都会有)，所以要用广播模式。这种场景通过AMQP的fanout exchange实现。每个server在binding中将其队列绑定到一个fanout exchange， client在调用时指定exchange类型为fanout即可。server和client使用同一个exchange。 rpc.call和rpc.cast的区别： RPC.call：发送请求到消息队列，等待返回最终结果。 RPC.cast：发送请求到消息队列，不需要等待最终返回的结果。其实还有一种rpc调用，也就是RPC.Notifier:发送各类操作消息到队列，不需要等待最终的返回结果。RPC.call、RPC.cast一般用于同一个项目下的服务之间进行的“内部“请求；RPC.Notifier发送的操作消息，目前被ceilometer notification服务所接收。 举个栗子：比如虚拟机创建过程，创建虚拟机等TaskAPI任务，已经由nova-conductor承担，因此nova-api监听到创建虚拟机的HTTP请求后，会通过RPC调用（是cast）nova.conductor.manager.ComputeTaskManager中的build_instance()方法。nova-conductor会在build_instances()中生成request_spec字典，其中包括了详细的虚拟机信息，nova-conductor通过rpc.call方法向nova-scheduler发出请求，nova-scheduler依据这些信息为虚拟机选择一个最佳的主机，然后返回给nova-conductor。（为什么有返回，因为是call）然后nova-conductor再通过nova-compute创建虚拟机。nova-compute首先会使用Resource Tracker的Claim机制检测一下主机的可用资源是否能够满足新建虚拟机的需要，然后通过具体的virt Driver创建虚拟机。]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之intern机制]]></title>
    <url>%2F2018%2F04%2F08%2Fpython%E4%B9%8Bintern%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[python之intern机制(字符串驻留机制) 在主流面向对象的编程语言中intern 机制对于处理字符串已经成为一种标配，通过 intern 机制可以提高字符串的处理效率，当然，解释器内部很对 intern 机制的使用策略是有考究的，有些场景会自动使用 intern ，有些地方需要通过手动方式才能启动。python中如果创建的对象一样，那么就会自动启动intern机制，所有对象会指向同一个地址。先看个栗子：123456a = "helloworld"b = "helloworld"c = "helloworld"print(id(a))print(id(b))print(id(c)) # 三个对象的内存地址一样 其实这就是python的intern机制，这样可以节省内存。看一下源码12345678910111213141516171819202122232425262728293031323334353637static PyObject *interned;void PyString_InternInPlace(PyObject **p)&#123; register PyStringObject *s = (PyStringObject *)(*p); PyObject *t; if (s == NULL || !PyString_Check(s)) Py_FatalError("PyString_InternInPlace: strings only please!"); /* If it's a string subclass, we don't really know what putting it in the interned dict might do. */ if (!PyString_CheckExact(s)) return; if (PyString_CHECK_INTERNED(s)) return; if (interned == NULL) &#123; interned = PyDict_New(); if (interned == NULL) &#123; PyErr_Clear(); /* Don't leave an exception */ return; &#125; &#125; t = PyDict_GetItem(interned, (PyObject *)s); if (t) &#123; Py_INCREF(t); Py_DECREF(*p); *p = t; return; &#125; if (PyDict_SetItem(interned, (PyObject *)s, (PyObject *)s) &lt; 0) &#123; PyErr_Clear(); return; &#125; /* The two references in interned are not counted by refcnt. The string deallocator will take care of this */ Py_REFCNT(s) -= 2; PyString_CHECK_INTERNED(s) = SSTATE_INTERNED_MORTAL;&#125; 可以看到interned的定义是一个PyObject,但从下面的代码可以看出，在interned=nul的时候，interned = PyDict_New();所以它实际上是一个PyDictObject，我们可以暂时理解为c++里面的map对象。对一个PyStringObject对象进行intern机制处理的时候，会通过PyDict_GetItem去从Interned对象中查找有没有一样的已经创建的对象，有的话就直接拿来用，没有的话就说明这种对象是第一次创建，用PyDict_SetItem函数把相应的信息存到interned里面，下次再创建一样的就能从中找到了。 Python解释器会缓冲256个字符串, 第257个字符串多次赋值不同的变量名, id()查看的结果就不同了。 intern机制的优点是。须要值同样的字符串的时候（比方标识符）。直接从池里拿来用。避免频繁的创建和销毁。提升效率，节约内存。缺点是，拼接字符串、对字符串改动之类的影响性能。 由于是不可变的。所以对字符串改动不是inplace操作。要新建对象。 这也是为什么拼接多字符串的时候不建议用+而用join()。join()是先计算出全部字符串的长度，然后一一拷贝，仅仅new一次对象。 须要小心的坑。并非全部的字符串都会採用intern机制。仅仅包括下划线、数字、字母的字符串才会被intern。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python之协程]]></title>
    <url>%2F2018%2F04%2F07%2Fpython%E4%B9%8B%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Generator 其中一个特性就是不是一次性生成数据，而是生成一个可迭代的对象，在迭代时，根据我们所写的逻辑来控制其启动时机。 Generator 另一个很大作用可以说就是当做协程使用。协程就是你可以暂停执行的函数。简而言之，协程是比线程更为轻量的一种模型，我们可以自行控制启动与停止的时机。知乎上说的，最易懂的解释：你行你就上，不行旁边等着让别人上，啥时候行了你再上。在 Python 中其实没有专门针对协程的这个概念，社区一般而言直接将 Generator 作为一种特殊的协程看待，想想，我们可以用 next 或 next() 方法或者是 send() 方法唤醒我们的 Generator ，在运行完我们所规定的代码后， Generator 返回并将其所有状态冻结。这是不是很让我们 Excited 呢！！ 总而言之，协程比线程更节省资源，效率更高，并且更安全。如果使用线程做过重要的编程，你就知道写出程序有多么困难，因为调度程序任何时候都能中断线程。必须记住保留锁，去保护程序中的重要部分，防止多步操作在执行的过程中中断，防止数据处于无效状态。而协程默认会做好全方位保护，以防止中断。我们必须显式产出才能让程序的余下部分运行。对协程来说，无需保留锁，在多个线程之间同步操作，协程自身就会同步，因为在任意时刻只有一个协程运行。想交出控制权时，可以使用 yield 或 yield from 把控制权交还调度程序。这就是能够安全地取消协程的原因：按照定义，协程只能在暂停的 yield处取消，因此可以处理 CancelledError 异常，执行清理操作。 这是一个异步编程的例子，将代码与事件循环及其相关的函数一一对应起来。这个例子里包含的几个协程，代表着火箭发射的倒计时，并且看起来是同时开始的。这是通过并发实现的异步编程；3个不同的协程将分别独立运行，并且都在同一个线程内完成。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128import datetimeimport heapqimport typesimport timeclass Task: """Represent how long a coroutine should before starting again. Comparison operators are implemented for use by heapq. Two-item tuples unfortunately don't work because when the datetime.datetime instances are equal, comparison falls to the coroutine and they don't implement comparison methods, triggering an exception. Think of this as being like asyncio.Task/curio.Task. """ def __init__(self, wait_until, coro): self.coro = coro self.waiting_until = wait_until def __eq__(self, other): return self.waiting_until == other.waiting_until def __lt__(self, other): return self.waiting_until &lt; other.waiting_untilclass SleepingLoop: """An event loop focused on delaying execution of coroutines. Think of this as being like asyncio.BaseEventLoop/curio.Kernel. """ def __init__(self, *coros): self._new = coros self._waiting = [] def run_until_complete(self): # Start all the coroutines. for coro in self._new: wait_for = coro.send(None) heapq.heappush(self._waiting, Task(wait_for, coro)) # Keep running until there is no more work to do. while self._waiting: now = datetime.datetime.now() # Get the coroutine with the soonest resumption time. task = heapq.heappop(self._waiting) if now &lt; task.waiting_until: # We're ahead of schedule; wait until it's time to resume. delta = task.waiting_until - now time.sleep(delta.total_seconds()) now = datetime.datetime.now() try: # It's time to resume the coroutine. wait_until = task.coro.send(now) heapq.heappush(self._waiting, Task(wait_until, task.coro)) except StopIteration: # The coroutine is done. pass@types.coroutinedef sleep(seconds): """Pause a coroutine for the specified number of seconds. Think of this as being like asyncio.sleep()/curio.sleep(). """ now = datetime.datetime.now() wait_until = now + datetime.timedelta(seconds=seconds) # Make all coroutines on the call stack pause; the need to use `yield` # necessitates this be generator-based and not an async-based coroutine. actual = yield wait_until # Resume the execution stack, sending back how long we actually waited. return actual - nowasync def countdown(label, length, *, delay=0): """Countdown a launch for `length` seconds, waiting `delay` seconds. This is what a user would typically write. """ print(label, 'waiting', delay, 'seconds before starting countdown') delta = await sleep(delay) print(label, 'starting after waiting', delta) while length: print(label, 'T-minus', length) waited = await sleep(1) length -= 1 print(label, 'lift-off!')def main(): """Start the event loop, counting down 3 separate launches. This is what a user would typically write. """ loop = SleepingLoop(countdown('A', 5), countdown('B', 3, delay=2), countdown('C', 4, delay=1)) start = datetime.datetime.now() loop.run_until_complete() print('Total elapsed time is', datetime.datetime.now() - start)if __name__ == '__main__': main()# A waiting 0 seconds before starting countdown#B waiting 2 seconds before starting countdown#C waiting 1 seconds before starting countdown#A starting after waiting 0:00:00.001000#A T-minus 5#C starting after waiting 0:00:01.000058#C T-minus 4#A T-minus 4#B starting after waiting 0:00:02.000115#B T-minus 3#C T-minus 3#A T-minus 3#B T-minus 2#C T-minus 2#A T-minus 2#B T-minus 1#C T-minus 1#A T-minus 1#B lift-off!#C lift-off!#A lift-off!#Total elapsed time is 0:00:05.001286 但是基于async的协程和基于生成器的协程会在对应的暂停表达式上面有所不同？主要原因是出于最优化Python性能的考虑，确保你不会将刚好有同样API的不同对象混为一谈。由于生成器默认实现协程的API，因此很有可能在你希望用协程的时候错用了一个生成器。而由于并不是所有的生成器都可以用在基于协程的控制流中，你需要避免错误地使用生成器。但是由于 Python 并不是静态编译的，它最好也只能在用基于生成器定义的协程时提供运行时检查。这意味着当用types.coroutine时，Python 的编译器将无法判断这个生成器是用作协程还是仅仅是普通的生成器（记住，仅仅因为types.coroutine这一语法的字面意思，并不意味着在此之前没有人做过types = spam的操作），因此编译器只能基于当前的情况生成有着不同限制的操作码。关于基于生成器的协程和async定义的协程之间的差异，我想说明的关键点是只有基于生成器的协程可以真正的暂停执行并强制性返回给事件循环。你可能不了解这些重要的细节，因为通常你调用的像是asyncio.sleep() function 这种事件循环相关的函数，由于事件循环实现他们自己的API，而这些函数会处理这些小的细节。对于我们绝大多数人来说，我们只会跟事件循环打交道，而不需要处理这些细节，因此可以只用async定义的协程。但是如果你和我一样好奇为什么不能在async定义的协程中使用asyncio.sleep()，那么这里的解释应该可以让你顿悟。 Generator迭代的就是通过内建的next（）或next()方法调用内建的send（）方法。 与其它特性一起，PEP 342 为生成器引入了 send() 方法。这让我们不仅可以暂停生成器，而且能够传递值到生成器暂停的地方。还是以我们的 range() 为例，你可以让序列向前或向后跳过几个值。 123456789101112131415161718192021def jumping_range(up_to): """Generator for the sequence of integers from 0 to up_to, exclusive. Sending a value into the generator will shift the sequence by that amount. """ index = 0 while index &lt; up_to: jump = yield index if jump is None: jump = 1 index += jumpif __name__ == '__main__': iterator = jumping_range(5) print(next(iterator)) # 0 print(iterator.send(2)) # 2 print(next(iterator)) # 3 print(iterator.send(-1)) # 2 for x in iterator: print(x) # 3, 4 openstack中就是用了协程模型，利用Python库Eventlet可以产生很多协程，这些协程之间只有在调用到了某些特殊的Eventlet库函数的时候（比如睡眠sleep、IO调用等）才会发生切换。协程的实现主要是在协程休息时把当前的寄存器保存起来，然后重新工作时将其恢复，可以简单的理解为，在单个线程内部有多个栈去保存切换时的线程上下文，因此，协程可以理解为一个线程内的伪并发方式。但是由于Eventlet本身的一些局限性，目前openstack考虑用AsynclIO来代替他。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C之内存对齐]]></title>
    <url>%2F2018%2F04%2F06%2FC%E4%B9%8B%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%2F</url>
    <content type="text"><![CDATA[内存对齐123456789101112131415161718192021222324252627282930313233#include&lt;stdio.h&gt;typedef struct bb&#123; int id; //[0]-[3] 第一个数据成员放在offset为0的地方 double weight;//从该成员的大小的整数倍位置开始存，也就是[8]-[15] float height; //[16]-[19],结构体的总大小必须是内部最大成员的整数倍，不足的补齐，所以补上[20]-[23] &#125;BB;typedef struct aa&#123; char name[2]; //[0]-[1] int id; //[4]-[7] double score; //[8]-[15] short grade; // [16]-[17] 从该成员的大小的整数倍开始存，也就是24 BB b; //[24]-[47] &#125;AA;int main()&#123; AA a; BB b; printf("%d\n",sizeof(a)); printf("%d",sizeof(b)); return 0;&#125;// #pragma pack(1) 不内存对齐 32 16 // #pragma pack(2) 32 16// #pragma pack(4) 36 16// #pragma pack(8) 48 24 如果#pragma pack (n)中指定的n大于结构体中最大成员的size，则其不起作用，结构体仍然按照size最大的成员进行对界。 为什么要进行内存对齐？ 一种提高内存访问速度的策略，cpu在访问未对其的内存需要经过两次内存访问，而经过内存对齐一次就可以了。 平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据，某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常 其实数据在内存中存放时，是否对齐并不重要，重要的是你怎样去访问它。memcpy的实现本身并不简单(你在源码里看到的通过while每次拷贝一个char的只是一个例子，并不是真实的memcpy)，它考虑了是否对齐。当检测到内存是对齐时，memcpy调用合适的指令(比较这里拷贝一个int，就调用LDR)，一次拷贝多个字节，以提高效率。当检测到不对齐时，先调用LDRB遂个字节拷贝，直到对齐部分后再调用合适的指令拷贝。因此，在上面的例子中，它是先调用LDRB的，因为LDRB是按1byte对齐(所有的内存都按这个对齐)，所以不会触发报错。但效率就要慢一点了，毕竟要拷贝几次。内存对齐本身对程序员来说是透明的，即程序员该取变量就取变量，该存就存，编译程序时编译器会把变量按本身的平台进行对齐。况且现在的CPU都很高级，别说服务器，台式机的CPU，ARM 7以上应该也支持内存不对齐访问了。但如果你要写一个内存池(boost的ordered_pool有对齐的例子)，或者使用了reinterpret_cast这种对内存直接进行操作的函数，这方面还是要注意一下，即使CPU支持，效率也会受到影响。 #pragma pack(push,1) #pragma pack(pop)强制把结构体按照1byte对齐。]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网易18实习算法题]]></title>
    <url>%2F2018%2F04%2F02%2F%E7%BD%91%E6%98%9318%E5%AE%9E%E4%B9%A0%E7%AE%97%E6%B3%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.小Q正在给一条长度为n的道路设计路灯安置方案。 为了让问题更简单,小Q把道路视为n个方格,需要照亮的地方用’.’表示, 不需要照亮的障碍物格子用’X’表示。 小Q现在要在道路上设置一些路灯, 对于安置在pos位置的路灯, 这盏路灯可以照亮pos - 1, pos, pos + 1这三个位置。 小Q希望能安置尽量少的路灯照亮所有’.’区域, 希望你能帮他计算一下最少需要多少盏路灯。123456789101112131415161718192021222324252627 # 算法思路 # x的位置也是可以放置路灯的 其实是贪心 #遍历路灯字符串，遇见“.”，就给计数器+1，然后往后挪 三个位置。如果遇到“X”，就直接往后挪一个位置。 #编程思路 #路灯个数放入数组n中，路灯对应的字符串放入数组#lantern中，要放路灯的个数放入lantern_count中。这三#个数组是一一对应的。双重循环来遍历lantern中的字符#串，如果遇到“.”，对应的lantern_count+=1，j+=3(挪三#个位置)。如果遇到“X”，j+=1(挪一个位置)。if __name__ =='__main__': count = int(input()) # 测试用例个数 n = [] lantern = [] for i in range(count): n_tmp = int(input()) # 路灯个数 n.append(n_tmp) lantern_tmp = input() # 路灯分布字符串 lantern.append(lantern_tmp) # ['.x.', '...xxx...xx'] lantern_count = [0 for i in range(count)] # [0, 0] for i in range(len(lantern)): j = 0 while (j &lt; len(lantern[i])): if lantern[i][j] == '.': j += 3 lantern_count[i] +=1 else: j += 1 print(lantern_count[0]) for i in range(len(lantern_count)-1): print(lantern_count[i+1]) 牛牛去犇犇老师家补课，出门的时候面向北方，但是现在他迷路了。虽然他手里有一张地图，但是他需要知道自己面向哪个方向，请你帮帮他。输入描述:每个输入包含一个测试用例。每个测试用例的第一行包含一个正整数，表示转方向的次数N(N&lt;=1000)。接下来的一行包含一个长度为N的字符串，由L和R组成，L表示向左转，R表示向右转。 1234567891011 # 比如输入3 LRL 输出Wn = input()m = input()dict1 = &#123;'1':'E','2':'S','3':'W','0':'N'&#125;init = 0for i in range(int(n)): if m[i]=='L': init-=1 else: init+=1print(dict1[str(init%4)]) # -1%4是3 牛牛总是睡过头，所以他定了很多闹钟，只有在闹钟响的时候他才会醒过来并且决定起不起床。从他起床算起他需要X分钟到达教室，上课时间为当天的A时B分，请问他最晚可以什么时间起床输入描述:每个输入包含一个测试用例。每个测试用例的第一行包含一个正整数，表示闹钟的数量N(N&lt;=100)。接下来的N行每行包含两个整数，表示这个闹钟响起的时间为Hi(0&lt;=A&lt;24)时Mi(0&lt;=B&lt;60)分。接下来的一行包含一个整数，表示从起床算起他需要X(0&lt;=X&lt;=100)分钟到达教室。接下来的一行包含两个整数，表示上课时间为A(0&lt;=A&lt;24)时B(0&lt;=B&lt;60)分。数据保证至少有一个闹钟可以让牛牛及时到达教室。 1234567891011121314151617181920# 3# 5 0# 6 0# 7 0# 59 # 6 59import sysif __name__ =='__main__': n = int(sys.stdin.readline().strip()) values= [] for i in range(n): line = sys.stdin.readline().strip().split(' ') values.append(line) # [['5', '0'], ['6', '0'], ['7', '0']] dst_time = int(sys.stdin.readline().strip()) class_time = sys.stdin.readline().strip().split(' ') b = list(map(lambda x :int(x[0])*60+int(x[1]), values)) deadline = int(class_time[0]) * 60 + int(class_time[1]) - dst_time c = [n for n in b if n &lt;= deadline ] print((str(max(c)//60)) + ' ' + str(max(c)%60)) # 输出6 0]]></content>
      <categories>
        <category>InterView</category>
      </categories>
      <tags>
        <tag>InterView</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python知识点（21-30）]]></title>
    <url>%2F2018%2F04%2F01%2FPython%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%8821-30%EF%BC%89%2F</url>
    <content type="text"><![CDATA[super函数 123456789101112131415class T(object): a = 0class A(T): passclass B(T): a = 2class D(T): a = 3class C(A, D, B): passc = C()print(super(C, c).a) # c继承的哪个值是根据MRO顺序来的，按照广度优先，根据ADB的顺序找到第一个定义a的类# 然后就是它，所以super(C,c).a 是3print(c.a) 在循环中获取索引 1234# 在循环中获取索引(数组下标),用enumerateints = [8, 23, 45 ,12, 78]for idx, val in enumerate(ints): print(idx, val) 如何移除换行符?&#39;test string\n&#39;.rstrip() 合并列表中的列表,一共有三种方法，用列表推导式最快 原因：当有L个子串的时候用+(即sum)的时间复杂度是O(L2)–每次迭代的时候作为中间结果的列表的长度就会越来越长,而且前一个中间结果的所有项都会再拷贝一遍给下一个中间结果.所以当你的列表l含有L个字串:l列表的第一项需要拷贝L-1次,而第二项要拷贝L-2次,以此类推;所以总数为I * (L2)/2.列表推导式(list comprehension)只是生成一个列表,每次运行只拷贝一次(从开始的地方拷贝到最终结果). 123456$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' '[item for sublist in l for item in sublist]'10000 loops, best of 3: 143 usec per loop$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'sum(l, [])'1000 loops, best of 3: 969 usec per loop$ python -mtimeit -s'l=[[1,2,3],[4,5,6], [7], [8,9]]*99' 'reduce(lambda x,y: x+y,l)'1000 loops, best of 3: 1.1 msec per loop 反转字符串 &#39;hello world&#39;[::-1] 通常每一个实例x都会有一个dict属性，用来记录实例中所有的属性和方法，也是通过这个字典，可以让实例绑定任意的属性。而slots属性作用就是，当类C有比较少的变量，而且拥有slots属性时，类C的实例 就没有dict属性，而是把变量的值存在一个固定的地方。如果试图访问一个slots中没有的属性，实例就会报错。这样操作有什么好处呢？slots属性虽然令实例失去了绑定任意属性的便利，但是因为每一个实例没有dict属性，却能有效节省每一个实例的内存消耗，有利于生成小而精干的实例。 为什么需要这样的设计呢？在一个实际的企业级应用中，当一个类生成上百万个实例时，即使一个实例节省几十个字节都可以节省一大笔内存，这种情况就值得使用slots属性。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python知识点（11-20）]]></title>
    <url>%2F2018%2F03%2F31%2FPython%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%8811-20%EF%BC%89%2F</url>
    <content type="text"><![CDATA[new和init的区别 new是一个静态方法,而init是一个实例方法. new方法会返回一个创建的实例,而init什么都不返回. 只有在new返回一个cls的实例时后面的init才能被调用. 当创建一个新实例时调用new,初始化一个实例时用init. metaclass是创建类时起作用.所以我们可以分别使用metaclass,new和init来分别在类创建,实例创建和实例初始化的时候做一些小手脚. 单例模式的四种方式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 使用__new__方法class Singleton(object): @staticmethod def __new__(cls, *args, **kwargs): if not hasattr(cls, '_instance'): # 若还没有实例 orig = super(Singleton, cls) cls._instance = orig.__new__(cls, *args, **kwargs) # 创建一个实例 return cls._instance # 返回一个实例class MyClass(Singleton): a = 1# 共享属性 创建实例时把所有实例的__dict_ #_指向同一个字典,这样它们具有相同的属性和方法.class Borg(object): _state = &#123;&#125; def __new__(cls, *args, **kwargs): ob = super(Borg, cls).__new__(cls, *args, **kwargs) ob.__dict__ = cls._state return obclass MyClass2(Borg): a = 1# 装饰器版本def singleton(cls, *args, **kwargs): instance = &#123;&#125; def getinstance(): if cls not in instance: instance[cls] = cls(*args, **kwargs) return instance[cls] return getinstance@singleton()class MyClass: pass# import方法# mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton()# to usefrom mysingleton import my_singletonmy_singleton.foo() Python中的作用域: 当 Python 遇到一个变量的话他会按照这样的顺序进行搜索：本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in） Lambda 表达式:你在某处就真的只需要一个能做一件事情的函数而已，连它叫什么名字都无关紧要。Lambda 表达式就可以用来做这件事。 123456789a=map(lambda x: x*x, [y for y in range(10)])print(list(a))# 这样写不如Lambda，因为有污染环境的函数sqdef sq(x): return x*xa=map(sq, [y for y in range(10)])print(list(a)) 我们习以为常的复制就是深复制，即将被复制对象完全再复制一遍作为独立的新个体单独存在。而浅复制并不会产生一个独立的对象单独存在。 1234567891011121314151617181920212223# 对于普通对象深浅复制一样，而对于下面这样的复杂对象就不同了# 就是列表里嵌套列表import copya = [1, 2, 3, 4, ['a', 'b']]b = a # 赋值，传对象的引用c = copy.copy(a) # 浅拷贝 对于['a','b']只是引用#在浅拷贝中对于子对象，python会把它当作一个公共镜像存储起来，所有对他的复制都被当成一个引用d = copy.deepcopy(a) # 深拷贝print(a is b) # a和b是同一个objectprint(a is c) # 也不是同一个objectprint(a is d) # 可以发现a和d并不是一个objecta.append(5) # 修改对象aa[4].append('c')print(b)print(c)print(d)TrueFalseFalse[1, 2, 3, 4, ['a', 'b', 'c'], 5][1, 2, 3, 4, ['a', 'b', 'c']][1, 2, 3, 4, ['a', 'b']] Python垃圾回收机制Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。1 引用计数PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.引用计数为0时，该对象生命就结束了。优点:简单 实时性缺点:维护引用计数消耗资源 循环引用2 标记-清除机制基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。3 分代技术分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。Python默认定义了三代对象集合，索引数越大，对象存活时间越长。举例：当某些内存块M经过了3次垃圾收集的清洗之后还存活时，我们就将内存块M划到一个集合A中去，而新分配的内存都划分到集合B中去。当垃圾收集开始工作时，大多数情况都只对集合B进行垃圾回收，而对集合A进行垃圾回收要隔相当长一段时间后才进行，这就使得垃圾收集机制需要处理的内存少了，效率自然就提高了。在这个过程中，集合B中的某些内存块由于存活时间长而会被转移到集合A中，当然，集合A中实际上也存在一些垃圾，这些垃圾的回收会因为这种分代的机制而被延迟。 read,readline和readlines read 读取整个文件 readline 读取下一行,使用生成器方法 readlines 读取整个文件到一个迭代器以供我们遍历 生成器 1234567891011121314151617181920212223# 所有你可以用在for...in...语句中的都是可迭代的:比如lists,strings,files...# 因为这些可迭代的对象你可以随意的读取所以非常方便易用,# 但是你必须把它们的值放到内存里,当它们有很多值时就会消耗太多的内存.mylist = [x*x for x in range(3)]for i in mylist: print(i)# 生成器也是迭代器的一种,但是你只能迭代它们一次.原因很简单,因为它们不是# 全部存在内存里,它们只在要调用的时候在内存里生成:# 生成器和迭代器的区别就是用()代替[],还有你不能用for i in mygenerator第二次# 调用生成器:首先计算0,然后会在内存里丢掉0去计算1,直到计算完4.mygenerator = (x*x for x in range(3) )for i in mygenerator: print(i)# 当你的函数要返回一个非常大的集合并且你希望只读一次的话,那么用下面的这个就非常的方便了.def createGenerator(): mlist = range(3) for i in mlist: yield i*i # 函数运行并没有碰到yeild语句就认为生成器已经为空了. # 原因有可能是循环结束或者没有满足if/else之类的.mgenerator = createGenerator()for i in mgenerator: print(i) Python中调用外部命令 12345678910# 这是一个简单的对于给定目录下的目录tar的脚本，有坑！注意输入空格这样的sehll字符！！！！#!/usr/bin/env python# a python script to auto backup a directory file by SJTimport osDirectory=raw_input("Please enter directory you want to backup:")dirs=os.listdir(Directory)for filename in dirs: fulldirfile=os.path.join(Directory,filename) if os.path.isdir(fulldirfile): os.system("tar -czvf "+fulldirfile+".tar.gz "+ fulldirfile) 对字典进行排序是不可能的,只有把字典转换成另一种方式才能排序.字典本身是无序的,但是像列表元组等其他类型是有序的.所以你需要用一个元组列表来表示排序的字典. 12345678import operatorx = &#123;1:2, 3:4, 4:3, 2:1, 0:0&#125;sorted_x_by_value = sorted(x.items(), key=operator.itemgetter(1))print(sorted_x_by_value)# 结果为[(0, 0), (2, 1), (1, 2), (4, 3), (3, 4)]sorted_x_by_key = sorted(x.items(), key=operator.itemgetter(0))print(sorted_x_by_key)# 结果为[(0, 0), (1, 2), (2, 1), (3, 4), (4, 3)]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python知识点（1-10）]]></title>
    <url>%2F2018%2F03%2F30%2FPython%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%881-10%EF%BC%89%2F</url>
    <content type="text"><![CDATA[python知识点 在python中，strings, tuples, 和numbers是不可更改的对象，而list,dict等则是可以修改的对象。当一个引用传递给函数的时候,函数自动复制一份引用,这个函数里的引用和外边的引用没有半毛关系了.所以第一个例子里函数把引用指向了一个不可变对象,当函数返回的时候,外面的引用没半毛感觉.而第二个例子就不一样了,函数内的引用指向的是可变对象,对它的操作就和定位了指针地址一样,在内存里进行修改. 1234567891011121314151617181920212223a = 1b = []c = [] #If you pass an immutable object to a method, you still can't rebind #the outer reference, and you can't even mutate the object.def fun(a): a = 2 #If you pass a mutable object into a method, #the method gets a reference to that same object #and you can mutate itdef fun2(b): b.append(1) #if you rebind the reference in the method, the outer scope #will know nothing about it, and after you're done, #the outer reference will still point at the original object.def fun3(c): c = [1]fun(a)fun2(b)fun3(c)print(a) #1print(b) #[1]print(c) #[] 元类（metaclass），经常用在ORM这种复杂的结构！参考深刻理解Python中的元类(metaclass) 在类里每次定义方法的时候都需要绑定这个实例,就是foo(self, x),为什么要这么做呢?因为实例方法的调用离不开实例,我们需要把实例自己传给函数,调用的时候是这样的a.foo(x)(其实是foo(a, x)).类方法一样,只不过它传递的是类而不是实例,A.class_foo(x).注意这里的self和cls可以替换别的参数,但是python的约定是这俩,还是不要改的好. 1234567891011121314151617181920212223242526272829303132x = 1def foo(x): print("executing foo(%s)" % (x))class A(object): # self和cls是对类或者实例的绑定 def foo(self, x): print("executing foo(%s,%s)" % (self, x)) @classmethod def class_foo(cls, x): print("executing class_foo(%s,%s)" % (cls, x)) @staticmethod def static_foo(x): print("executing static_foo(%s)" % x)a = A()# 普通方法的调用foo(x)# 实例方法的调用a.foo(x)# 类方法的调用a.class_foo(x)A.class_foo(x)# 静态方法的调用a.static_foo(x) A.static_foo(x) # 程序结果为：executing foo(1)executing foo(&lt;__main__.A object at 0x0000000002A5A518&gt;,1)executing class_foo(&lt;class '__main__.A'&gt;,1)executing class_foo(&lt;class '__main__.A'&gt;,1)executing static_foo(1)executing static_foo(1) 类变量和实例变量:类变量就是供类使用的变量,实例变量就是供实例使用的.这里p1.name=”bbb”是实例调用了类变量,这其实和上面第一个问题一样,就是函数传参的问题,p1.name一开始是指向的类变量name=”aaa”,但是在实例的作用域里把类变量的引用改变了,就变成了一个实例变量,self.name不再引用Person的类变量name了. 12345678910 class Person: name="aaa" p1=Person()p2=Person()p1.name="bbb"print p1.name # bbbprint p2.name # aaaprint Person.name # aaa 类变量就是供类使用的变量,实例变量就是供实例使用的. 这里p1.name=”bbb”是实例调用了类变量,这其实和上面第一个问题一样,就是函数传参的问题,p1.name一开始是指向的类变量name=”aaa”,但是在实例的作用域里把类变量的引用改变了,就变成了一个实例变量,self.name不再引用Person的类变量name了. 可以看看下面的例子: 123456789 class Person: name=[] p1=Person()p2=Person()p1.name.append(1)print p1.name # [1]print p2.name # [1]print Person.name # [1] Python自省自省就是面向对象的语言所写的程序在运行时,所能知道对象的类型.简单一句就是运行时能够获得对象的类型.比如type(),dir(),getattr(),hasattr(),isinstance(). python共有三种推导式，那什么是推导式呢？推导式是可以从一个数据序列构建另一个新的数据序列的结构体。 12345678910111213141516171819202122232425262728293031323334353637383940 # 列表推导式multiples = [i for i in range(30) if i % 3 is 0]print(multiples)# Output: [0, 3, 6, 9, 12, 15, 18, 21, 24, 27]def squared(x): return x*xmultiples = [squared(i) for i in range(30) if i % 3 is 0]print multiples# Output: [0, 9, 36, 81, 144, 225, 324, 441, 576, 729]# 将俩表推导式的[]改成()即可得到生成器。multiples = (i for i in range(30) if i % 3 is 0)print(type(multiples))# Output: &lt;type 'generator'&gt; # 字典推导式 # 字典推导和列表推导的使用方法是类似的，只不中括号该改成大括号。直接举例说明： # 通过把key大小写合并 合并值mcase = &#123;'a': 10, 'b': 34, 'A': 7, 'Z': 3&#125;mcase_frequency = &#123; k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) for k in mcase.keys() if k.lower() in ['a','b']&#125;print(mcase_frequency)# Output: &#123;'a': 17, 'b': 34&#125; # 快速更换key和valuemcase = &#123;'a': 10, 'b': 34, 'c': 30&#125;mcase_frequency = &#123;v: k for k, v in mcase.items()&#125;print(mcase_frequency)# Output: &#123;10: 'a', 34: 'b'&#125; # 集合推导式squared = &#123;x**2 for x in [1, 1, 2]&#125;print(squared)# Output: set([1, 4]) 单下划线和双下划线首先是单下划线开头，这个被常用于模块中，在一个模块中以单下划线开头的变量和函数被默认当作内部函数，如果使用 from a_module import * 导入时，这部分变量和函数不会被导入。不过值得注意的是，如果使用 import a_module 这样导入模块，仍然可以用 a_module._some_var 这样的形式访问到这样的对象。在 Python 的官方推荐的代码样式中，还有一种单下划线结尾的样式，这在解析时并没有特别的含义，但通常用于和 Python 关键词区分开来，比如如果我们需要一个变量叫做 class，但 class 是 Python 的关键词，就可以以单下划线结尾写作 class_。双下划线开头的命名形式在 Python 的类成员中使用表示名字改编 (Name Mangling)，即如果有一 Test 类里有一成员 x，那么 dir(Test) 时会看到 _Testx 而非 x。这是为了避免该成员的名称与子类中的名称冲突。但要注意这要求该名称末尾没有下划线。双下划线开头双下划线结尾的是一些 Python 的“魔术”对象，如类成员的 init__、del、add、getitem 等，以及全局的 file、name 等。 Python 官方推荐永远不要将这样的命名方式应用于自己的变量或函数，而是按照文档说明来使用。另外单下划线开头还有一种一般不会用到的情况在于使用一个 C 编写的扩展库有时会用下划线开头命名，然后使用一个去掉下划线的 Python 模块进行包装。如 struct 这个模块实际上是 C 模块 _struct 的一个 Python 包装。 12345678910111213141516171819class MyClass(): def __init__(self): self.__superprivate = "Hello" self._semiprivate = ",World！"class OtherClass(MyClass): def __init__(self): self.__superprivate = "hhaaa" self.b = "ssss"mc = MyClass()oc = OtherClass()print(mc._semiprivate) # 只有mc能访问该私有变量print(mc.__dict__)print(oc.__dict__)# print(oc.__superprivate) # 访问不了，提示没有该属性print(oc._OtherClass__superprivate) # 这样就可以访问# ,World！#&#123;'_MyClass__superprivate': 'Hello', #'_semiprivate': ',World！'&#125;#&#123;'b': 'ssss', '_OtherClass__superprivate': #'hhaaa'&#125;#hhaaa 当你不确定你的函数里将要传递多少参数时你可以用*args **kwargs允许你使用没有事先定义的参数名 面向切面编程AOP和装饰器装饰器是一个很著名的设计模式，经常被用于有切面需求的场景，较为经典的有插入日志、性能测试、事务处理等。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量函数中与函数功能本身无关的雷同代码并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 12345678910# 字体变粗装饰器def makebold(fn): # 装饰器将返回新的函数 def warpper(): return "&lt;b&gt;"+ fn() + "&lt;/b&gt;" return warpper@makebolddef say(): return "hello"print(say()) # &lt;b&gt;hello&lt;/b&gt; 函数重载主要是为了解决两个问题。可变参数类型。可变参数个数。一个基本的设计原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果两个函数的功能其实不同，那么不应当使用重载，而应当使用一个名字不同的函数。但是因为python可以接受任何类型的参数、和任何数量的参数，所以不需要重载。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中的eval函数]]></title>
    <url>%2F2018%2F03%2F29%2Fpython%E4%B8%AD%E7%9A%84eval%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[python中的eval() 这个函数意义在哪？在编译语言里要动态地产生代码，基本上是不可能的，但动态语言是可以，意味着软件已经部署到服务器上了，但只要作很少的更改，只好直接修改这部分的代码，就可立即实现变化，不用整个软件重新加载。 先举个栗子：123a = 1g = &#123;&apos;a&apos;: 20&#125;print(eval(&quot;a+1&quot;, g)) #返回21 再举个栗子1234567891011121314151617# test eval() and locals()x = 1y = 1num1 = eval(&quot;x+y&quot;)print(num1)def g():x = 2y = 2num3 = eval(&quot;x+y&quot;)print(num3)num2 = eval(&quot;x+y&quot;, globals()) # 搜全局num4 = eval(&quot;x+y&quot;,globals(),locals()) # 先搜索局部，搜索到停止print(num2)print(num4)g() # 值依次为2 4 2 4 eval在字符串对象和list、dictinoary、tuple对象之间互相转换123456789def evala(): l = &apos;[1,2,3,4,[5,6,7,8,9]]&apos; d = &quot;&#123;&apos;a&apos;:123,&apos;b&apos;:456,&apos;c&apos;:789&#125;&quot; t = &apos;([1,3,5],[5,6,7,8,9],[123,456,789])&apos; print(type(l), type(eval(l))) print(type(d), type(eval(d))) print(type(t), type(eval(t)))evala() 结果为：123&lt;class &apos;str&apos;&gt; &lt;class &apos;list&apos;&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;dict&apos;&gt; &lt;class &apos;str&apos;&gt; &lt;class &apos;tuple&apos;&gt; locals()对象的值不能修改，globals()对象的值可以修改 1234567891011#test globals() and locals()z=0def f(): z = 1 print (locals()) locals()[&quot;z&quot;] = 2 print (locals()) f() globals()[&quot;z&quot;] = 2print (z) # 结果为&#123;&apos;z&apos;: 1&#125; &#123;&apos;z&apos;: 1&#125; 2 eval有安全性问题,比如用户恶意输入就会获得当前目录文件eval(&quot;__import__(&#39;os&#39;).system(&#39;dir&#39;)&quot;) 怎么避免安全问题？ 自行写检查函数； 使用ast.literal_eval tipsif __name__ == &quot;__main__&quot;: 第一开始不是很理解，今天经过学习知道了这句代码的作用。是编写私有化部分 ，这句代码以上的部分，可以被其它的调用，以下的部分只有这个文件自己可以看见，如果文件被调用了，其他人是无法看见私有化部分的。比如进行单元测试的时候会用到！他的原理是每个py文件都有name属性，如果当前属性和main一样，则值为真，否则为假，就不执行！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python多线程]]></title>
    <url>%2F2018%2F03%2F29%2Fpython%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[python多线程（假多线程） 如果你的代码是IO密集型，多线程可以明显提高效率。例如制作爬虫（我就不明白为什么Python总和爬虫联系在一起…不过也只想起来这个例子…），绝大多数时间爬虫是在等待socket返回数据。这个时候C代码里是有release GIL的，最终结果是某个线程等待IO的时候其他线程可以继续执行。如果你的代码是CPU密集型，多个线程的代码很有可能是线性执行的。所以这种情况下多线程是鸡肋，效率可能还不如单线程因为有context switch 一般网络传输类应用都是IO密集型，读写硬盘操作多也算是IO密集型 我们都知道，比方我有一个4核的CPU，那么这样一来，在单位时间内每个核只能跑一个线程，然后时间片轮转切换。但是Python不一样，它不管你有几个核，单位时间多个核只能跑一个线程，然后时间片轮转。看起来很不可思议？但是这就是GIL搞的鬼。任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。（Java中的多线程是可以利用多核的，这是真正的多线程！） 在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192 # 直接调用函数的多线程from threading import Threadimport timedef loop(name, seconds): print('start loop', name, 'at:', time.ctime()) time.sleep(1) print('end loop', name, 'at:', time.ctime())if __name__ == '__main__': loops = [2, 4] nloops = range(len(loops)) threads = [] print('start at:', time.ctime()) for i in nloops: t = Thread(target=loop, args=(i, loops[i],)) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print('all done at:', time.ctime()) # 使用可调用的类对象from threading import Threadimport timedef loop(name, seconds): print('start loop', name, 'at:', time.ctime()) time.sleep(1) print('end loop', name, 'at:', time.ctime())class ThreadFunc(object): def __init__(self, func, args, name=''): self.name = name self.func = func self.args = args def __call__(self): # 需要定义一个特殊的方法__call__ self.func(*self.args)if __name__ == '__main__': loops = [2, 4] nloops = range(len(loops)) threads = [] print('start at:', time.ctime()) for i in nloops: t = Thread(target=ThreadFunc(loop, (i, loops[i]), loop.__name__)) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print('all done at:', time.ctime())# 继承Thread类，也就是子类化from threading import Threadimport timedef loop(name, seconds): print('start loop', name, 'at:', time.ctime()) time.sleep(1) print('end loop', name, 'at:', time.ctime())class ThreadFunc(Thread): def __init__(self, func, args, name=''): super(ThreadFunc, self).__init__() self.name = name self.func = func self.args = args # 将上种方式中可调用的方法改为run方法，其实就是对Thread类中run方法的重写 def run(self): self.func(*self.args)if __name__ == '__main__': loops = [2, 4] nloops = range(len(loops)) threads = [] print('start at:', time.ctime()) for i in nloops: t = ThreadFunc(loop, (i, loops[i]), loop.__name__) threads.append(t) for i in nloops: threads[i].start() for i in nloops: threads[i].join() print('all done at:', time.ctime()) # 在一般推荐的方法中，我们用最后一种方式 线程同步如果多个线程共同对某个数据修改，则可能出现不可预料的结果，为了保证数据的正确性，需要对多个线程进行同步。使用Thread对象的Lock和Rlock可以实现简单的线程同步，这两个对象都有acquire方法和release方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到acquire和release方法之间。如下：多线程的优势在于可以同时运行多个任务（至少感觉起来是这样）。但是当线程需要共享数据时，可能存在数据不同步的问题。考虑这样一种情况：一个列表里所有元素都是0，线程”set”从后向前把所有元素改成1，而线程”print”负责从前往后读取列表并打印。那么，可能线程”set”开始改的时候，线程”print”便来打印列表了，输出就成了一半0一半1，这就是数据的不同步。为了避免这种情况，引入了锁的概念。锁有两种状态——锁定和未锁定。每当一个线程比如”set”要访问共享数据时，必须先获得锁定；如果已经有别的线程比如”print”获得锁定了，那么就让线程”set”暂停，也就是同步阻塞；等到线程”print”访问完毕，释放锁以后，再让线程”set”继续。经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的尴尬场面。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import threadingimport timeclass myThread(threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print("Starting " + self.name) # 获得锁，成功获得锁定后返回True # 可选的timeout参数不填时将一直阻塞直到获得锁定 # 否则超时后将返回False threadLock.acquire() print_time(self.name, self.counter, 3) # 释放锁 threadLock.release()def print_time(threadName, delay, counter): while counter: time.sleep(delay) print("%s: %s" % (threadName, time.ctime(time.time()))) counter -= 1threadLock = threading.Lock()threads = []# 创建新线程thread1 = myThread(1, "Thread-1", 1)thread2 = myThread(2, "Thread-2", 2)# 开启新线程thread1.start()thread2.start()# 添加线程到线程列表threads.append(thread1)threads.append(thread2)# 等待所有线程完成for t in threads: t.join()print("Exiting Main Thread")]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[僵尸进程]]></title>
    <url>%2F2018%2F03%2F28%2F%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[僵尸进程 怎样产生僵尸进程的： 一个进程在调用exit命令结束自己的生命的时候，其实它并没有真正的被销毁，而是留下一个称为僵尸进程（Zombie）的数据结构（系统调用exit，它的作用是使进程退出，但也仅仅限于将一个正常的进程变成一个僵尸进程，并不能将其完全销毁）。在Linux进程的状态中，僵尸进程是非常特殊的一种，它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程列表中保留一个位置，记载该进程的退出状态等信息供其他进程收集，除此之外，僵尸进程不再占有任何内存空间。它需要它的父进程来为它收尸，如果他的父进程没安装SIGCHLD信号处理函数调用wait或waitpid()等待子进程结束，又没有显式忽略该信号，那么它就一直保持僵尸状态，如果这时父进程结束了，那么init进程自动会接手这个子进程，为它收尸，它还是能被清除的。但是如果如果父进程是一个循环，不会结束，那么子进程就会一直保持僵尸状态，这就是为什么系统中有时会有很多的僵尸进程。 网络原因有时也会引起僵尸进程， 僵尸进程有害吗？ 不会。由于僵尸进程并不做任何事情， 不会使用任何资源也不会影响其它进程， 因此存在僵尸进程也没什么坏处。 不过由于进程表中的退出状态以及其它一些进程信息也是存储在内存中的，因此存在太多僵尸进程有时也会是一些问题，比如会影响服务器的性能。signal(SIGCHLD, SIG_IGN); 忽略SIGCHLD信号，这是一个常用于提升并发服务器性能的技巧,因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设置为忽略，可让内核把僵尸进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。 如何防止僵尸进程？ 让僵尸进程成为孤儿进程，由init进程回收；(手动杀死父进程) 调用fork()两次； 捕捉SIGCHLD信号，并在信号处理函数中调用wait函数；代码实例：` #include &lt;signal.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;#include &lt;unistd.h&gt; void sig_handler(int signo){ printf(&quot;child process deaded, signo: %d\n&quot;, signo); wait(0);// 当捕获到SIGCHLD信号，父进程调用wait回收，避免子进程成为僵尸进程 } void out(int n){ int i; for(i = 0; i &lt; n; ++i) { printf(&quot;%d out %d\n&quot;, getpid(), i); sleep(2); } } int main(void){ // 登记一下SIGCHLD信号 if(signal(SIGCHLD, sig_handler) == SIG_ERR) { perror(&quot;signal sigchld error&quot;); } pid_t pid = fork(); if(pid &lt; 0) { perror(&quot;fork error&quot;); exit(1); } else if(pid &gt; 0) { // parent process out(100); } else { // child process out(10); } return 0; } ` 如何找出僵尸进程呢？ ps aux | grep Zor ps -ef | grep defunct 解决方法： 设置SIGCLD信号为SIG_IGN，系统将不产生僵死进程。 用两次fork()，而且使紧跟的子进程直接退出，是的孙子进程成为孤儿进程，从而init进程将负责清除这个孤儿进程。 重启服务器电脑，这个是最简单，最易用的方法，但是如果你服务器电脑上运行有其他的程序，那么这个方法，代价很大。所以，尽量使用下面一种方法。 找到该defunct僵尸进程的父进程，将该进程的父进程杀掉，则此defunct进程将自动消失。 如何找到defunct僵尸进程的父进程？很简单，一句命令就够了：ps -ef | grep defunct_process_pid 正常情况下我们可以用 SIGKILL 信号来杀死进程，但是僵尸进程已经死了， 你不能杀死已经死掉的东西。 因此你需要输入的命令应该是kill -s SIGCHLD pid 。 将这里的 pid 替换成父进程的进程 id，这样父进程就会删除所有以及完成并死掉的子进程了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表]]></title>
    <url>%2F2018%2F03%2F28%2F%E5%93%88%E5%B8%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希表 哈希表的特点：关键字在表中位置和它之间存在一种确定的关系。hash : 翻译为“散列”，就是把任意长度的输入，通过散列算法，变成固定长度的输出，该输出就是散列值。不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。 实际工作中需视不同的情况采用不同的哈希函数，通常考虑的因素有： 计算哈希函数所需时间 关键字的长度 哈希表的大小 关键字的分布情况 记录的查找频率 由于哈希表高效的特性，查找或者插入的情况在大多数情况下可以达到O(1)，时间主要花在计算hash上，当然也有最坏的情况就是hash值全都映射到同一个地址上，这样哈希表就会退化成链表，查找的时间复杂度变成O(n)，但是这种情况比较少，只要不要把hash计算的公式外漏出去并且有人故意攻击（用兴趣的人可以搜一下基于哈希冲突的拒绝服务攻击），一般也不会出现这种情况。 下面这个程序是用C++实现的一个包含hash算法的小程序，可以让电话或者姓名作为key，从而查找记录。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526 // MyHashTable.cpp : 定义控制台应用程序的入口点。////设计哈希表实现电话号码查询系统//说明：一是从文件old.txt中读取的数据自己在程序运行前建立，// 二是由系统随机生成数据，在程序运行由随机数产生器生成，并且将产生的记录保存到 new.txt文件。//存在的问题：使用随机产生的文件，在显示时出现乱码// #include &lt;stdafx.h&gt; #include&lt;fstream&gt;//文件流#include&lt;iostream&gt;#include &lt;string&gt;#include&lt;stdlib.h&gt;using namespace std;const int D[] = &#123;3,5,8,11,13,14,19,21&#125;;//预定再随机数const int HASH_MAXSIZE = 50;//哈希表长度//记录信息类型class DataInfo&#123;public: DataInfo();//默认构造函数 friend ostream&amp; operator&lt;&lt;(ostream&amp; out, const DataInfo&amp; dataInfo); //重载输出操作符 //friend class HashTable;//private: string name;//姓名 string phone;//电话号码 string address;//地址 char sign;//冲突的标志位，&apos;1&apos;表示冲突，&apos;0&apos;表示无冲突&#125;;DataInfo::DataInfo():name(&quot;&quot;), phone(&quot;&quot;), address(&quot;&quot;), sign(&apos;0&apos;)&#123;&#125;ostream&amp; operator&lt;&lt;(ostream&amp; out, const DataInfo&amp; dataInfo) //重载输出操作符&#123; cout &lt;&lt; &quot;姓名：&quot; &lt;&lt; dataInfo.name &lt;&lt; &quot; 电话：&quot; &lt;&lt; dataInfo.phone &lt;&lt; &quot; 地址：&quot; &lt;&lt; dataInfo.address &lt;&lt; endl; return out;&#125;//存放记录的哈希表类型class HashTable&#123;public: HashTable();//默认构造函数 ~HashTable();//析构函数 int Random(int key, int i);// 伪随机数探测再散列法处理冲突 void Hashname(DataInfo *dataInfo);//以名字为关键字建立哈希表 int Rehash(int key, string str);// 再哈希法处理冲突 注意处理冲突还有链地址法等 void Hashphone(DataInfo *dataInfo);//以电话为关键字建立哈希表 void Hash(char *fname, int n);// 建立哈希表 //fname 是数据储存的文件的名称，用于输入数据，n是用户选择的查找方式 int Findname(string name);// 根据姓名查找哈希表中的记录对应的关键码 int Findphone(string phone);// 根据电话查找哈希表中的记录对应的关键码 void Outhash(int key);// 输出哈希表中关键字码对应的一条记录 void Outfile(string name, int key);// 在没有找到时输出未找到的记录 void Rafile();// 随机生成文件，并将文件保存在 new.txt文档中 void WriteToOldTxt();//在运行前先写入数据 //private: DataInfo *value[HASH_MAXSIZE]; int length;//哈希表长度&#125;;HashTable::HashTable():length(0)//默认构造函数&#123; //memset(value, NULL, HASH_MAXSIZE*sizeof(DataInfo*)); for (int i=0; i&lt;HASH_MAXSIZE; i++) &#123; value[i] = new DataInfo(); &#125;&#125;HashTable::~HashTable()//析构函数&#123; delete[] *value;&#125;void HashTable::WriteToOldTxt()&#123; ofstream openfile(&quot;old.txt&quot;); if (openfile.fail()) &#123; cout &lt;&lt; &quot;文件打开错误！&quot; &lt;&lt; endl; exit(1); &#125; string oldname; string oldphone; string oldaddress; for (int i=0; i&lt;30; i++) &#123; cout &lt;&lt; &quot;请输入第&quot; &lt;&lt; i+1 &lt;&lt; &quot;条记录:&quot; &lt;&lt; endl; cin &gt;&gt; oldname ; cin &gt;&gt; oldphone; cin &gt;&gt; oldaddress; openfile &lt;&lt; oldname &lt;&lt; &quot; &quot; &lt;&lt; oldphone &lt;&lt; &quot; &quot; &lt;&lt; oldaddress &lt;&lt; &quot;,&quot; &lt;&lt; endl; &#125; openfile.close();&#125;int HashTable::Random(int key, int i)// 伪随机数探测再散列法处理冲突&#123;//key是冲突时的哈希表关键码，i是冲突的次数，N是哈希表长度 //成功处理冲突返回新的关键码，未进行冲突处理则返回-1 int h; if(value[key]-&gt;sign == &apos;1&apos;)//有冲突 &#123; h = (key + D[i]) % HASH_MAXSIZE; return h; &#125; return -1;&#125;void HashTable::Hashname(DataInfo *dataInfo)//以名字为关键字建立哈希表&#123;//利用除留取余法建立以名字为关键字建立的哈希函数，在发生冲突时调用Random函数处理冲突 int i = 0; int key = 0; for (int t=0; dataInfo-&gt;name[t]!=&apos;\0&apos;; t++) &#123; key = key + dataInfo-&gt;name[t]; &#125; key = key % 42; while(value[key]-&gt;sign == &apos;1&apos;)//有冲突 &#123; key = Random(key, i++);//处理冲突 &#125; if(key == -1) exit(1);//无冲突 length++;//当前数据个数加 value[key]-&gt;name = dataInfo-&gt;name; value[key]-&gt;address = dataInfo-&gt;address; value[key]-&gt;phone = dataInfo-&gt;phone; value[key]-&gt;sign = &apos;1&apos;;//表示该位置有值 //cout &lt;&lt; value[key]-&gt;name &lt;&lt; &quot; &quot; &lt;&lt; value[key]-&gt;phone &lt;&lt; &quot; &quot; &lt;&lt; value[key]-&gt;address &lt;&lt; endl;&#125;int HashTable::Rehash(int key, string str)// 再哈希法处理冲突&#123;//再哈希时使用的是折叠法建立哈希函数 int h; int num1 = (str[0] - &apos;0&apos;) * 1000 + (str[1] - &apos;0&apos;) * 100 + (str[2] - &apos;0&apos;) * 10 + (str[3] - &apos;0&apos;); int num2 = (str[4] - &apos;0&apos;) * 1000 + (str[5] - &apos;0&apos;) * 100 + (str[6] - &apos;0&apos;) * 10 + (str[7] - &apos;0&apos;); int num3 = (str[8] - &apos;0&apos;) * 100 + (str[9] - &apos;0&apos;) * 10 + (str[10] - &apos;0&apos;); h = num1 + num2 + num3; h = (h + key) % HASH_MAXSIZE; return h;&#125;void HashTable::Hashphone(DataInfo *dataInfo)//以电话为关键字建立哈希表&#123;//利用除留取余法建立以电话为关键字建立的哈希函数，在发生冲突时调用Rehash函数处理冲突 int key = 0; int t; for(t=0; dataInfo-&gt;phone[t] != &apos;\0&apos;; t++) &#123; key = key + dataInfo-&gt;phone[t]; &#125; key = key % 42; while(value[key]-&gt;sign == &apos;1&apos;)//有冲突 &#123; key = Rehash(key, dataInfo-&gt;phone); &#125; length++;//当前数据个数加 value[key]-&gt;name = dataInfo-&gt;name; value[key]-&gt;address = dataInfo-&gt;address; value[key]-&gt;phone = dataInfo-&gt;phone; value[key]-&gt;sign = &apos;1&apos;;//表示该位置有值 &#125;void HashTable::Outfile(string name, int key)//在没有找到时输出未找到的记录&#123; ofstream fout; if((key == -1)||(value[key]-&gt;sign == &apos;0&apos;))//判断哈希表中没有记录 &#123; fout.open(&quot;out.txt&quot;,ios::app);//打开文件 if(fout.fail()) &#123; cout &lt;&lt; &quot;文件打开失败!&quot; &lt;&lt; endl; exit(1); &#125; fout &lt;&lt; name &lt;&lt; endl;//将名字写入文件,有个问题，每次写入的时候总是将原来的内容替换了 fout.close(); &#125;&#125;void HashTable::Outhash(int key)//输出哈希表中关键字码对应的记录&#123; if((key==-1)||(value[key]-&gt;sign==&apos;0&apos;)) cout &lt;&lt; &quot;没有找到这条记录！&quot; &lt;&lt; endl; else &#123; for(unsigned int i=0; value[key]-&gt;name[i]!=&apos;\0&apos;; i++) &#123; cout &lt;&lt; value[key]-&gt;name[i]; &#125; for(unsigned int i=0; i&lt;10; i++) &#123; cout &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; value[key]-&gt;phone; for(int i=0; i&lt;10; i++) &#123; cout &lt;&lt; &quot; &quot;; &#125; cout &lt;&lt; value[key]-&gt;address &lt;&lt; endl; &#125;&#125;void HashTable::Rafile()//随机生成文件，并将文件保存在new.txt文档中&#123; ofstream fout; fout.open(&quot;new.txt&quot;);//打开文件，等待写入 if(fout.fail()) &#123; cout &lt;&lt; &quot;文件打开失败！&quot; &lt;&lt; endl; exit(1); &#125; for(int j=0; j&lt;30; j++) &#123; string name = &quot;&quot;; for(int i=0; i&lt;20; i++)//随机生成长个字的名字 &#123; name += rand() % 26 + &apos;a&apos;;//名字是由个字母组成 &#125; fout &lt;&lt; name &lt;&lt; &quot; &quot;;//将名字写入文件 string phone = &quot;&quot;; for(int i=0; i&lt;11; i++)//随机生成长位的电话号码 &#123; phone += rand() % 10 + &apos;0&apos;;//电话号码是纯数字 &#125; fout &lt;&lt; phone &lt;&lt; &quot; &quot;;//将电话号码写入文件 string address = &quot;&quot;; for(int i=0; i&lt;29; i++)//随机生成长个字的名字 &#123; address += rand() % 26 + &apos;a&apos;;//地址是由个字母组成 &#125; address += &apos;,&apos;; fout &lt;&lt; address &lt;&lt; endl;//将地址写入文件 &#125; fout.close();&#125;void HashTable::Hash(char *fname, int n)//建立哈希表//fname是数据储存的文件的名称，用于输入数据，n是用户选择的查找方式//函数输入数据，并根据选择调用Hashname或Hashphone函数进行哈希表的建立&#123; ifstream fin; int i; fin.open(fname);//读文件流对象 if(fin.fail()) &#123; cout &lt;&lt; &quot;文件打开失败！&quot; &lt;&lt; endl; exit(1); &#125; while(!fin.eof())//按行读入数据 &#123; DataInfo *dataInfo = new DataInfo(); char* str = new char[100]; fin.getline(str, 100, &apos;\n&apos;);//读取一行数据 if(str[0] == &apos;*&apos;)//判断数据结束 &#123; break; &#125; i = 0;//记录字符串数组的下标 //a-z:97-122 A-Z:65-90 //本程序的姓名和地址都使用小写字母 while((str[i] &lt; 97) || (str[i] &gt; 122))//读入名字 &#123; i++; &#125; for(; str[i]!=&apos; &apos;; i++) &#123; dataInfo-&gt;name += str[i]; &#125; while(str[i] == &apos; &apos;) &#123; i++; &#125; for(int j=0; str[i]!=&apos; &apos;; j++,i++)//读入电话号码 &#123; dataInfo-&gt;phone += str[i]; &#125; while(str[i] == &apos; &apos;) &#123; i++; &#125; for(int j=0; str[i]!=&apos;,&apos;; j++,i++)//读入地址 &#123; dataInfo-&gt;address += str[i]; &#125; if(n == 1) &#123; Hashname(dataInfo); &#125; else &#123; Hashphone(dataInfo);//以电话为关键字 &#125; delete []str; delete dataInfo; &#125; fin.close();&#125;int HashTable::Findname(string name)//根据姓名查找哈希表中的记录对应的关键码&#123; int i = 0; int j = 1; int t; int key = 0; for(key=0, t=0; name[t] != &apos;\0&apos;; t++) &#123; key = key + name[t]; &#125; key = key % 42; while((value[key]-&gt;sign == &apos;1&apos;) &amp;&amp; (value[key]-&gt;name != name)) &#123; key = Random(key, i++); j++; if(j &gt;= length) return -1; &#125; return key;&#125;int HashTable::Findphone(string phone)//根据电话查找哈希表中的记录对应的关键码&#123; int key = 0; int t; for(t=0; phone[t] != &apos;\0&apos; ; t++) &#123; key = key + phone[t]; &#125; key = key % 42; int j = 1; while((value[key]-&gt;sign == &apos;1&apos;) &amp;&amp; (value[key]-&gt;phone != phone)) &#123; key = Rehash(key, phone); j++; if(j &gt;= length) &#123; return -1; &#125; &#125; return key;&#125;int main()&#123; //WriteToOldTxt(); int k; int ch; char *Fname; HashTable *ht = new HashTable; while(1) &#123; system(&quot;cls&quot;);//cls命令清除屏幕上所有的文字 cout &lt;&lt; &quot;欢迎使用本系统！&quot; &lt;&lt; endl &lt;&lt; endl; cout &lt;&lt; &quot;请选择数据&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.使用已有数据文件&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.随机生成数据文件&quot; &lt;&lt; endl; cout &lt;&lt; &quot;0.结束&quot; &lt;&lt; endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; k; switch(k) &#123; case 0: return 0; case 1: Fname = &quot;old.txt&quot;;//从数据文件old.txt(自己现行建好)中读入各项记录 break; case 2: ht-&gt;Rafile(); Fname = &quot;new.txt&quot;;//由系统随机产生各记录，并且把记录保存到new.txt文件中 break; default: cout &lt;&lt; &quot;输入序号有误，退出程序。&quot; &lt;&lt; endl; return 0; &#125; do &#123; system(&quot;cls&quot;); cout &lt;&lt; &quot; 请选择查找方式&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.通过姓名查找&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.通过电话查找&quot; &lt;&lt; endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; ch; if((ch != 1) &amp;&amp; (ch != 2)) cout &lt;&lt; &quot;输入序号有误！&quot; &lt;&lt; endl; &#125;while((ch != 1) &amp;&amp; (ch != 2)); ht-&gt;Hash(Fname, ch); while(ch == 1) &#123; int choice; cout &lt;&lt; endl &lt;&lt; &quot;请选择功能&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.输入姓名查找数据&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.显示哈希表&quot; &lt;&lt; endl; cout &lt;&lt; &quot;0.退出&quot;&lt;&lt;endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; choice; switch(choice) &#123; case 1: &#123;//注意此处应该加上大括号 int key1; string name; cout &lt;&lt; &quot;请输入姓名：&quot;; cin &gt;&gt; name; key1 = ht-&gt;Findname(name); ht-&gt;Outfile(name, key1); ht-&gt;Outhash(key1); &#125; break; case 2: &#123; for(int i=0; i&lt;HASH_MAXSIZE; i++) &#123; if(ht-&gt;value[i]-&gt;sign!=&apos;0&apos;) &#123; ht-&gt;Outhash(i); &#125; &#125; &#125; break; default: cout &lt;&lt; endl &lt;&lt; &quot;您的输入有误！&quot; &lt;&lt; endl; &#125; if(choice == 0) &#123; return 0; &#125; &#125; while(ch == 2) &#123; int choice; cout &lt;&lt; endl &lt;&lt; &quot;请选择功能&quot; &lt;&lt; endl; cout &lt;&lt; &quot;1.输入电话查找数据&quot; &lt;&lt; endl; cout &lt;&lt; &quot;2.显示哈希表&quot;&lt;&lt;endl; cout &lt;&lt; &quot;0.退出&quot;&lt;&lt;endl; cout &lt;&lt; &quot;输入相应序号选择功能：&quot;; cin &gt;&gt; choice; switch(choice) &#123; case 1: &#123; int key2; string phone; cout &lt;&lt; &quot;请输入11位的电话号码：&quot;; do &#123; cin &gt;&gt; phone; if(phone.length() != 11) &#123; cout &lt;&lt; &quot;电话号码应为11位！\n请重新输入：&quot;; &#125; &#125;while(phone.length() != 11); key2 = ht-&gt;Findphone(phone); ht-&gt;Outfile(phone, key2); ht-&gt;Outhash(key2); &#125; break; case 2: &#123; for(int i=0; i&lt;HASH_MAXSIZE; i++) &#123; if(ht-&gt;value[i]-&gt;sign != &apos;0&apos;) &#123; ht-&gt;Outhash(i); &#125; &#125; &#125; break; default: cout &lt;&lt; endl &lt;&lt; &quot;您的输入有误！&quot; &lt;&lt; endl; &#125; if(choice == 0) &#123; return 0; &#125; &#125; while((ch != 1) &amp;&amp; (ch != 2)) &#123; cout &lt;&lt; &quot;您的输入有误！请输入相应需要选择功能：&quot;; &#125; &#125; system(&quot;pause&quot;); return 0;&#125;]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种树]]></title>
    <url>%2F2018%2F03%2F27%2F%E5%90%84%E7%A7%8D%E6%A0%91%2F</url>
    <content type="text"><![CDATA[红黑树，AVL树简单来说都是用来搜索的呗。 AVL树：平衡二叉树，一般是用平衡因子差值决定并通过旋转来实现，左右子树树高差不超过1，那么和红黑树比较它是严格的平衡二叉树，平衡条件非常严格（树高差只有1），只要插入或删除不满足上面的条件就要通过旋转来保持平衡。由于旋转是非常耗费时间的。我们可以推出AVL树适合用于插入删除次数比较少，但查找多的情况。 红黑树：平衡二叉树，通过对任何一条从根到叶子的简单路径上各个节点的颜色进行约束，确保没有一条路径会比其他路径长2倍，因而是近似平衡的。所以相对于严格要求平衡的AVL树来说，它的旋转保持平衡次数较少。用于搜索时，插入删除次数多的情况下我们就用红黑树来取代AVL。（现在部分场景使用跳表来替换红黑树，可搜索“为啥 redis 使用跳表(skiplist)而不是使用 red-black？”） B树，B+树：它们特点是一样的，是多路查找树，一般用于数据库系统中，为什么，因为它们分支多层数少呗，都知道磁盘IO是非常耗时的，而像大量数据存储在磁盘中所以我们要有效的减少磁盘IO次数避免磁盘频繁的查找。B+树是B树的变种树，有n棵子树的节点中含有n个关键字，每个关键字不保存数据，只用来索引，数据都保存在叶子节点。是为文件系统而生的。b+树是b树的一个变种，只在leaf node存储数据，可以方便地遍历所有数据。b树相较于b+树可以把热点数据放在internal node中以便更快地查找。 B+树本来就是为 SQL 实现的，它比 B 树的优势在于范围查询更快，因为数据都在叶子节点上，所有的叶子节点又在同一底层上。 磁盘中的B+树以文件的形式将整体都存放磁盘当中，使用时只在内存中缓存部份结构。 先了解下相关的硬件知识，才能很好的了解为什么需要B~tree这种外存数据结构。 B-tree就是指的B树。 B+-tree的查询效率更加稳定 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 数据库索引采用B+树的主要原因是 B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。正是为了解决这个问题，B+树应运而生。B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）。 Trie树：又名单词查找树，一种树形结构，常用来操作字符串,比如在百度搜索时，会给出提示。它是不同字符串的相同前缀只保存一份。相对直接保存字符串肯定是节省空间的，但是它保存大量字符串时会很耗费内存（是内存）。类似的有前缀树(prefix tree)，后缀树(suffix tree)，radix tree(patricia tree, compact prefix tree)，crit-bit tree（解决耗费内存问题），以及前面说的double array trie。简单的补充下我了解应用前缀树：字符串快速检索，字符串排序，最长公共前缀，自动匹配前缀显示后缀。后缀树：查找字符串s1在s2中，字符串s1在s2中出现的次数，字符串s1,s2最长公共部分，最长回文串。radix tree：linux内核，nginx。]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机通过桥接模式上网（补充）]]></title>
    <url>%2F2018%2F03%2F24%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%80%9A%E8%BF%87%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%E4%B8%8A%E7%BD%91%EF%BC%88%E8%A1%A5%E5%85%85%EF%BC%89%2F</url>
    <content type="text"><![CDATA[虚拟机通过桥接模式上网（补充）（上次设置的桥接模式并不具备上外网的能力，这次重新梳理了一下过程） 通过brctl show命令可以看到原来已经有网桥br1，我想通过brctl delbr br1试着删除该网桥，但是提示不能删除，经过分析，原因可能有二，其一还有网卡挂在其上，其二，该网桥没有关闭，执行ifconfig br1 down命令关闭网桥,然后再进行删除。 重新建立一个网桥，brctl addbr br-ex（让linux知道网桥，首先告诉它，我们想要一个虚拟的以太网桥接口） 把物理网卡enp11s0挂载到网桥上，brctl addif br-ex enp11s0（以太网物理接口变成了网桥上的逻辑端口。那物理接口过去存在，未来也不会消失。） 此时，ifconfig发现网卡和网桥均有ip（不正常，上不去网） 执行删去网卡ip的命令id addr del dev enp11s0 192.168.1.50/24（为什么可以删去，因为物理网卡成了逻辑网桥设备的一部分了，所以不再需要IP地址。虽然不把原有的网卡地址释放掉，网桥也能工作！但是，为了更规范，或者说为了避免有什幺莫名其妙的问题，最好还是按要求做） 更改/etc/network/interface文件，添加配置，static模式 此时再ifconfig发现物理网卡已没有ip，只有br-ex有，此时可以上网。 登录到学校网关（如果登不上，可能DNS解析出现问题，去/etc/resolv.conf更改配置，加上nameserver 172.21.0.21 ，此为学校的DNS服务器） 此时一切完好，服务器设置已经完毕！这时虚拟机即可以通过桥接模式连接外网，但请注意，如果重启服务器的话，这些配置会消失，因为这些事通过命令行设置的，如果想永久生效的话，可能需要通过配置文件进行修改（我并没有尝试）注：ping 172.21.4.254可以检查是否可以访问外网。 下图显示的是一些配置网桥常用的命令 注意的问题： brctl show中有STP选项，这个其实是生成树协议！因为实验室目前只有一个路由器，是绝对不可能形成一个环的。可以关闭这个功能，这样也可以减少网络环境的数据包污染。 服务器可以上网但是ping百度不通，可能是由于很多网站在服务器都设置了阻止ping数据包，一是安全考虑，二是如果每天都有大量的ping数据包向服务器请求，那会给服务器带来很大负担，如果人家恶意向你的服务器发送大量这种数据包，你的服务器将会无暇顾及其他数据包，那你的网站别人将无法访问，或者打开非常慢，经过测试，确实是这样的！]]></content>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机通过代理上外网]]></title>
    <url>%2F2018%2F03%2F24%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%80%9A%E8%BF%87%E4%BB%A3%E7%90%86%E4%B8%8A%E5%A4%96%E7%BD%91%2F</url>
    <content type="text"><![CDATA[虚拟机通过代理连接外网 因为实验室的服务器没有连接外网，而如果又需要连网的需求，那么可以通过代理的方式，有一款软件CCProxy，需要有校园IP ，服务器的ip网段172.21.4.x，校园网的ip网段为172.21.6.x， 所以虚拟机可以通过有校园网IP的电脑作为Proxy。 下载CCproxy，主界面如下，点击账号管理。 新建一个用户 注意：输入用户名，勾选密码，自定义一个密码，取消勾选IP地址/IP地址段 回到主界面，点击设置，按如下方式设置，注意“请选择本机局域网IP地址默认为自动检测，如果虚拟机不能联网，可尝试手动修改其为本机当前IP地址” 在虚拟机中输入如下命令：export http_proxy=http://username:passwd@ip:port 之后就可以使用apt-get 等功能安装软件包，升级系统。注意：代理设置只在当前ssh连接有效，如果你断开过ssh连接，重新连接后，需要重新在ubuntu中通过命令设置代理。]]></content>
      <categories>
        <category>openstack</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell知识点]]></title>
    <url>%2F2018%2F03%2F18%2FShell%E7%9F%A5%E8%AF%86%E7%82%B9-1%2F</url>
    <content type="text"><![CDATA[使用read读取行 read可以一次读取所有的值到多个变量里，使用$IFS分割，比如应用于/etc/passwd文件。 12345#!/bin/bashwhile IFS=: read user pass uid gid fullname homedir Shelldo echo $userdone &lt; /etc/passwd 当到文件末尾时，read会以非0退出，终止while循环。可能会觉得把/etc/passwd的重定向放到末尾有些奇怪，不过这是必须的。如果这样写，就不会终止！因为每次循环，Shell都会打开/etc/passwd一次，且read只读取文件的第一行。 12345#!/bin/bashwhile IFS=: read user pass uid gid &lt; /etc/passwd fullname homedir Shelldo echo $userdone make 1&gt; results 2&gt; ERRS 该命令将标准错误输出到ERRS，将标准输出传给results。 命令替换：就是指Shell执行命令并将命令替换为执行该命令后的结果。可以用两个反引号，不过这种方式容易混淆，所以还有一种方式就是使用$(...) ,现在多用此。 1234567$# 传递到脚本的参数个数$* 以一个单字符串显示所有向脚本传递的参数$$ 脚本运行的当前进程ID号$! 后台运行的最后一个进程的ID号$@ 与$#相同，但是使用时加引号，并在引号中返回每个参数。$- 显示Shell使用的当前选项，与set命令功能相同。$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误]]></content>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机IP]]></title>
    <url>%2F2018%2F03%2F15%2F%E8%99%9A%E6%8B%9F%E6%9C%BAIP%2F</url>
    <content type="text"><![CDATA[如何不进去虚拟机看到其IP 在linux上玩过kvm的朋友基本都晓得，在宿主机上运行了虚拟主机以后，我们无法直接看到某一个虚拟主机IP地址。比如 如果我们想知道test这个虚拟机的IP地址，那么是无法直接看到的。但是我们可以通过一个小技巧间接得到其IP，也就是利用ARP。 编辑虚拟主机配置文件。查看虚拟机的配置文件test.xml，（或者通过virsh dumpxml test）找到MAC标签，可以得到该虚拟机的MAC地址，记录下mac后退出，然后通过arp -a判定虚拟机IP地址，由此可以发现此虚拟机IP为192.168.122.118，由此实现了不登陆虚拟机即可得到其IP。 (注意这里一定要加上-i 忽略大小写。不然因为大小写问题有可能查不到)说明：这里只根据通信缓存记录的mac 、IP地址手段做排查。也有可能找不到。最好的办法是自己写一个脚本跟网段内的所有服务器都ping一次，记录下mac、ip地址以后再查找就没问题,因为这个方法就根据ARP缓存得到的。 虚拟机指定固定IP 由于bridge模式默认创建虚拟机的时候用的DHCP方式，分配给虚拟机的IP可能会发生改变，有时候很麻烦。那么如何指定其IP呢？进去虚拟机，编辑/etc/network/interface文件，由变成然后输入 systemctl restart networking或者实在不行重启，即可更改为192.168.1.111的地址。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KVM配置虚拟机桥接（bridge）模式]]></title>
    <url>%2F2018%2F03%2F14%2FKVM%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A1%A5%E6%8E%A5%EF%BC%88bridge%EF%BC%89%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[主机：Ubuntu14.04 64bit虚拟机：Ubuntu14.04 64bitVMM:KVM 基础知识：默认创建的网桥virbr0用于NAT模式，如果想用brigde模式，需要自己创建一个br0。Bridge方式即虚拟网桥的网络连接方式，是客户机和子网里面的机器能够互相通信。可以使虚拟机成为网络中具有独立IP的主机。 桥接网络（也叫物理设备共享）被用作把一个物理设备复制到一台虚拟机。网桥多用作高级设置，特别是主机多个网络接口的情况。 修改网络配置文件 /etc/network/interfaces ，此处是DHCP方式，也可以static方式。（Ubuntu系统，centos在etc/sysconfig里）输入 brctl addbr br0 建立一个网桥br0，此时在Linux内核里创建虚拟网卡br0，enp11s0 是host主机的网卡。 重新启动网络服务便可重启计算机或者sudo systemctl restart networking / sudo systemctl restart network-manager，此时输入ifconfig，显示如图。（据说br0与enp11s0只能有一个有ip地址，此处不是很明白，但是目前并不影响使用。） 输入该命令，可以看到此时已有br0的网桥。 创建虚拟机时，指定—bridge=br0。（–bridge与—network只能二选一，不能同时指定） 1virt-install --virt-type kvm --name test2 --ram 1024 --vcpus 1 --bridge=br0 \ --cdrom=/home/lib206/vmimage/ubuntu-16.04.1-server-amd64.iso \--disk path=/home/lib206/vmimage/Test.img,size=20,format=raw --graphics vnc,port=5901 --os-type=linux --boot cdrom 创建成功后，如果启动虚拟机时出现不能引导Booting from No bootable device，按下图所示设置，可能是引导顺序的原因。 此时虚拟机即处于桥接模式，ip由路由器DHCP随即分配。通过以上步骤的设置KVM的桥接问题解决了，此时可以查看一下虚拟机网络IP地址，应该跟主机的IP地址处于同一个网段；但是还是有问题的， 无线网卡桥接是不成功的，默认的是有线网卡！ 如果想指定该虚拟机的ip地址，按另一篇文章设置。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell知识点]]></title>
    <url>%2F2018%2F03%2F11%2FShell%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[/dev/null 位桶（bit bucket）传送到此文件的数据会被丢掉,可以用来测试一个文件是否包含某个pattern。 1234if grep pattern myfile &gt; /dev/nullthen ... 找到模式else ...没找到模式fi Shell脚本的命令行参数超多9时，用数字框起来${10} ^$ 用来匹配空字符串或行列，cc -E foo.c | grep -v &#39;^$&#39;&gt; foo.out 用来排除空行 实时查看当前进程中使用的shell种类ps | grep $$ | awk &#39;{print $4}&#39; 正则表达式对于程序执行时的locale环境相当敏感；方括号表达式里的范围应避免使用，该用字符集，例如[[:alnum:]]比较好。 -k选项指定排序字段，-t选择字段界定符 12345678910sort -t_ -k1,1 -k2,2 &lt;&lt; EOF&gt; one_two&gt; one_two_three&gt; ont_two_four&gt; ont_two_five&gt; EOFone_twoone_two_threeont_two_fiveont_two_four 可以看出sort并不稳定，因为输入与输出不一致，但我们可以通过–stable选项补救该问题。 为什么看不到/etc/passwd,因为默认是隐藏的。 awk与cut是提取字段的好工具。 awk -F: &apos;{print $5}&apos; or cut -d: -f5 2&gt; /dev/null 是丢弃标准错误信息的输出 myvar=赋值并不会将myvar删除，只不过是将其设为null字符串，unset myvar则会完全删除它。 rm -fr /$MYPROGRAM 若MYPROGRAM未定义，就会有灾难发生！！！ POSIX标准化字符串长度运算符：返回字符长度。 12x=supercalifraglistcexpialidoucius 著名的特殊单词echo There are $&#123;#x&#125; characters in $x set命令 如果未給任何选项，会设置位置参数的值，并将之前存在的任何值丢弃。 12345678910111213141516171819202122232425262728293031323334[root@localhost ~]# set -- hello &quot;hi there&quot; greetings[root@localhost ~]# echo there are $# total arguments 计数there are 3 total arguments[root@localhost ~]# for i in $*&gt; do echo i is $i&gt; donei is hello 注意内嵌的空白已经消失i is hii is therei is greetings[root@localhost ~]# for i in $@ 没有双引号 $*和$@一样&gt; do echo i is $i&gt; donei is helloi is hii is therei is greetings[root@localhost ~]# for i in &quot;$*&quot;&gt; do echo i is $i&gt; donei is hello hi there greetings[root@localhost ~]# for i in &quot;$@&quot;; do echo i is $i; donei is helloi is hi therei is greetings[root@localhost ~]# shift 截去第一个参数[root@localhost ~]# echo there are now $# total argumentsthere are now 2 total arguments 证明消失[root@localhost ~]# for i in &quot;$@&quot;; do echo i is $i; donei is hi therei is greetings[root@localhost ~]# shift[root@localhost ~]# echo there are now $# total argumentsthere are now 1 total arguments 特殊变量$$ 可在编写脚本时用来建立具有唯一性的文件名，多半是临时的，根据Shell的进程编号建立文件名，不过，mktemp也能做。 set -e当命令以非零状态退出时，则退出shell。主要作用是，当脚本执行出现意料之外的情况时，立即退出，避免错误被忽略，导致最终结果不正确。说明set -e 选项对set.sh起作用。脚本作为一个进程去描述set -e选项的范围应该是：set -e选项只作用于当前进行，不作用于其创建的子进程。set -e 命令用法总结如下：1.当命令的返回值为非零状态时，则立即退出脚本的执行。2.作用范围只限于脚本执行的当前进行，不作用于其创建的子进程。3.另外，当想根据命令执行的返回值，输出对应的log时，最好不要采用set -e选项，而是通过配合exit 命令来达到输出log并退出执行的目的。 shell 脚本中set-x 与set+x的区别linux shell 脚本编写好要经过漫长的调试阶段，可以使用sh -x 执行。但是这种情况在远程调用脚本的时候，就有诸多不便。又想知道脚本内部执行的变量的值或执行结果，这个时候可以使用在脚本内部用 set -x 。set去追踪一段代码的显示情况，执行后在整个脚本有效，set -x 开启，set +x关闭，set -o 查看 shell if条件判断中的-z到-d的意思 123456789101112131415161718192021222324252627282930313233[ -a FILE ] 如果 FILE 存在则为真。[ -b FILE ] 如果 FILE 存在且是一个块特殊文件则为真。[ -c FILE ] 如果 FILE 存在且是一个字特殊文件则为真。[ -d FILE ] 如果 FILE 存在且是一个目录则为真。[ -e FILE ] 如果 FILE 存在则为真。[ -f FILE ] 如果 FILE 存在且是一个普通文件则为真。[ -g FILE ] 如果 FILE 存在且已经设置了SGID则为真。[ -h FILE ] 如果 FILE 存在且是一个符号连接则为真。[ -k FILE ] 如果 FILE 存在且已经设置了粘制位则为真。[ -p FILE ] 如果 FILE 存在且是一个名字管道(F如果O)则为真。[ -r FILE ] 如果 FILE 存在且是可读的则为真。[ -s FILE ] 如果 FILE 存在且大小不为0则为真。[ -t FD ] 如果文件描述符 FD 打开且指向一个终端则为真。[ -u FILE ] 如果 FILE 存在且设置了SUID (set user ID)则为真。[ -w FILE ] 如果 FILE 如果 FILE 存在且是可写的则为真。[ -x FILE ] 如果 FILE 存在且是可执行的则为真。[ -O FILE ] 如果 FILE 存在且属有效用户ID则为真。[ -G FILE ] 如果 FILE 存在且属有效用户组则为真。[ -L FILE ] 如果 FILE 存在且是一个符号连接则为真。[ -N FILE ] 如果 FILE 存在 and has been mod如果ied since it was last read则为真。[ -S FILE ] 如果 FILE 存在且是一个套接字则为真。[ FILE1 -nt FILE2 ] 如果 FILE1 has been changed more recently than FILE2, or 如果 FILE1 exists and FILE2 does not则为真。[ FILE1 -ot FILE2 ] 如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真。[ FILE1 -ef FILE2 ] 如果 FILE1 和 FILE2 指向相同的设备和节点号则为真。[ -o OPTIONNAME ] 如果 shell选项 “OPTIONNAME” 开启则为真。[ -z STRING ] “STRING” 的长度为零则为真。[ -n STRING ] or [ STRING ] “STRING” 的长度为非零 non-zero则为真。[ STRING1 == STRING2 ] 如果2个字符串相同。 “=” may be used instead of “==” for strict POSIX compliance则为真。[ STRING1 != STRING2 ] 如果字符串不相等则为真。[ STRING1 &lt; STRING2 ] 如果 “STRING1” sorts before “STRING2” lexicographically in the current locale则为真。[ STRING1 &gt; STRING2 ] 如果 “STRING1” sorts after “STRING2” lexicographically in the current locale则为真。[ ARG1 OP ARG2 ] “OP” is one of -eq, -ne, -lt, -le, -gt or -ge. These arithmetic binary operators return true if “ARG1” is equal to, not equal to, less than, less than or equal to, greater than, or greater than or equal to “ARG2”, respectively. “ARG1” and “ARG2” are integers. Shell变量表达式 举个栗子：12345678910111213#!/bin/bashstr=&quot;a b c d e f g h i j&quot;echo &quot;the source string is &quot;$&#123;str&#125; #源字符串echo &quot;the string length is &quot;$&#123;#str&#125; #字符串长度echo &quot;the 6th to last string is &quot;$&#123;str:5&#125; #截取从第五个后面开始到最后的字符echo &quot;the 6th to 8th string is &quot;$&#123;str:5:2&#125; #截取从第五个后面开始的2个字符echo &quot;after delete shortest string of start is &quot;$&#123;str#a*f&#125; #从开头删除a到f的字符echo &quot;after delete widest string of start is &quot;$&#123;str##a*&#125; #从开头删除a以后的字符echo &quot;after delete shortest string of end is &quot;$&#123;str%f*j&#125; #从结尾删除f到j的字符echo &quot;after delete widest string of end is &quot;$&#123;str%%*j&#125; #从结尾删除j前面的所有字]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qemu-kvm-io线程]]></title>
    <url>%2F2018%2F03%2F11%2Fqemu-kvm-io%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[qemu-kvm一般会有4个线程，主线程是io thread，还有一个vcpu thread，一个signal thread。对于io thread，可以从kvm_main_loop(qemu-kvm.c)开始看：两个pipe是比较重要的一点： 它调用qemu_eventfd创建一个event pipe，pipe read fd用qemu_set_fd _hadnler2注册一个read fd handler，也就是说如果fd read ready，io thread将通过某种机制调用这个handler，即io_thread_wakeup。换句话说，这个event pipe读的操作应该是在io_thread_wakeup()函数中，那么是由谁执行写操作的呢？这个还不是很清楚，只知道write fd记录到了全局变量io_thread_fd中，也就是说在qemu-kvm任何地方都可以引用io_thread_fd向pipe写东西。 它还调用qemu_signalfd创建一个signal thread，不过现在还不清楚为什么要单独创建一个这样的线程。qemu_signalfd中还会创建一个signal pipe，read fd同样用qemu_set_fd _hadnler2注册一个read fd handler——sigfd_handler，而write fd作为参数传递给signal thread执行函数，也就是说写操作应该是由signal thread负责的。为什么要创建一个signal thread和signal pipe呢？ 上面提到用qemu_set_fd_handler2注册的handler在fd ready时，io thread会通过某种机制调用相应地handler。这个机制是main_loop_wait函数实现的。main_loop_wait函数中将所有注册的r/w fd都加入到对应地r/w fd_set中，然后调用select系统调用，这个系统调用将检查相应fd_set中的fd是否有已ready的，如果没有一个ready，将使得调用线程阻塞直到超时，否则将返回，并将原来fd_set修改，将没有ready的fd从原fd_set中删除。返回后，通过遍历handler队列，检测其fd是否在fd_set中，并调用相应的handler。 我记得中说过，发送给这个qemu process的信号可以由process内任意的thread来处理， 但是每个线程都可以设置mask来选择是否处理某信号。那么为什么要单独设置一个signal thread来接受信号呢？实际上，用signal thread这种机制是将原本对指定信号的处理由异步方式改成同步方式。 默认异步方式时，信号发送给本qemu process后，内核将检测是否有pending signal，如果有内核将调用相应的handler，而这个执行实体可以是process中任意的thread。这样，thread有可能因为信号的到来，而被临时打断，去执行handler。 同步方式是这样的，首先sigprocmask系统调用屏蔽掉指定的signal，这样process将不再接受这个signal(当然，每个thread都有屏蔽码的，但是应该是调用pthread_sigmask，调用sigprocmask将使整个process不接受)。然后，创建一个signal thread，其执行代码调用sigwaitinfo函数，等待指定的信号，如果无信号则signal thread阻塞在这个系统调用中，否则返回，将siginfo_t写入signal pipe中。最后，io thread通过select系统调用检测到signal pipe read_fd ready，然后调用相应的read_fd handler，fd handler再调用相应的signal handler。 可以看到，同步方式虽然代价比异步方式大得多，需要多创建一个signal pipe和signal thread，但是它不会突然打断thread执行，对于程序响应性有利。这个跟interrupt和polling之间的比较类似，当外部事情来时，执行内核的中断服务例程，interrupt handler有可能发送一个信号给要处理事件的process。 之前发现一个很奇怪的现象：在我的电脑上跑的qemu-kvm有4个线程，而其他同学电脑上跑只有2个线程。我原本觉得奇怪，按照前面的论述，qemu-kvm至少得有3个线程才是，只有2个线程的话，那么signal thread去哪里了呢？带着这个问题，对两种情况的代码做了一下trace，结果发现是在qemu_signalfd (compatfd.c)函数中出现了差异—如果系统有定义CONFIG_SIGNALFD宏，那么就不会创建signal thread，否则就创建。不太理解的是，我的装的是32位CentOS，结果没有SIGNALFD，而其他装的是64位CentOS，是有SIGNALFD的。那么signalfd是什么呢？简单的说，就是一个线程可以创建一个signalfd，指定哪些signal可以由它来接受，当信号来时，就不是像原来那样去调用signal handler，而是将siginfo_t写入signalfd，线程通过read或select或poll就可以知道signalfd是否接受到了新的signal。这样，在由signalfd情况下，就没有必要创建signal thread了。这样，就减少了一点开销。原来是signal thread通过sigwaitinfo检测到signal，然后将siginfo_t写入signal pipe，io thread通过select检测到signal pipe read fd ready，然后读出siginfo_t，再调用handler；现在是，内核直接将siginfo_t写入signalfd，io thread通过select检测到signalfd ready，然后读出读出siginfo_t，再调用handler。很显然，省去了额外signal thread的开销。总之，只要先用sigprocmask将可能接受的signal block掉，再用select+signalfd或者是sigwaitinfo都可以讲异步signal转变为同步signal。]]></content>
      <categories>
        <category>KVM</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[helloworld]]></title>
    <url>%2F2018%2F03%2F09%2Fhelloworld%2F</url>
    <content type="text"><![CDATA[HelloWorld]]></content>
      <categories>
        <category>helloworld</category>
      </categories>
      <tags>
        <tag>helloworld</tag>
      </tags>
  </entry>
</search>
